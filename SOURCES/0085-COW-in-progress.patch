From 5b968e4fcca9e2b68f82d3750e49e1676a844f6a Mon Sep 17 00:00:00 2001
From: Ronan Abhamon <ronan.abhamon@vates.fr>
Date: Sat, 14 Dec 2024 00:20:02 +0100
Subject: [PATCH] COW in progress

Signed-off-by: Ronan Abhamon <ronan.abhamon@vates.tech>
---
 Makefile                                      |   7 +-
 drivers/02-vhdcleanup                         |   4 +-
 drivers/CephFSSR.py                           |   1 -
 drivers/EXTSR.py                              |   1 -
 drivers/FileSR.py                             | 219 +++--
 drivers/GlusterFSSR.py                        |   1 -
 drivers/LVMSR.py                              | 379 ++++----
 drivers/LVMoFCoESR.py                         |   2 +-
 drivers/LinstorSR.py                          | 245 ++---
 drivers/MooseFSSR.py                          |   1 -
 drivers/NFSSR.py                              |   1 -
 drivers/SMBSR.py                              |   1 -
 drivers/SR.py                                 |  21 +-
 drivers/VDI.py                                |   3 +-
 drivers/XFSSR.py                              |   1 -
 drivers/blktap2.py                            |  42 +-
 drivers/cbtutil.py                            |   2 +-
 drivers/cleanup.py                            | 332 +++----
 drivers/coalesce-leaf                         |   4 +-
 drivers/cowutil.py                            | 328 +++++++
 drivers/lcache.py                             |   6 +-
 drivers/linstor-manager                       |  83 +-
 .../{linstorvhdutil.py => linstorcowutil.py}  | 172 ++--
 drivers/lvhd-thin                             |   8 +-
 drivers/lvhdutil.py                           | 373 --------
 drivers/lvmanager.py                          |   1 -
 drivers/lvmcache.py                           |   9 +-
 drivers/lvmcowutil.py                         | 417 +++++++++
 drivers/lvutil.py                             |   3 +
 drivers/tapdisk-pause                         |  44 +-
 drivers/trim_util.py                          |   2 -
 drivers/vditype.py                            |   6 +-
 drivers/verifyVHDsOnSR.py                     |  24 +-
 drivers/vhdutil.py                            | 875 +++++++++---------
 mk/sm.spec.in                                 |   2 +-
 mocks/XenAPI/__init__.py                      |   4 +
 tests/test_FileSR.py                          | 119 +--
 tests/test_LVMSR.py                           | 189 +++-
 tests/test_cbt.py                             |   1 -
 tests/test_cleanup.py                         |  19 +-
 tests/test_on_slave.py                        |   5 +-
 tests/test_vhdutil.py                         |  68 +-
 42 files changed, 2318 insertions(+), 1707 deletions(-)
 create mode 100755 drivers/cowutil.py
 rename drivers/{linstorvhdutil.py => linstorcowutil.py} (79%)
 delete mode 100755 drivers/lvhdutil.py
 create mode 100755 drivers/lvmcowutil.py

diff --git a/Makefile b/Makefile
index 883df31f..db95b4e4 100755
--- a/Makefile
+++ b/Makefile
@@ -34,11 +34,12 @@ SM_LIBS += util
 SM_LIBS += verifyVHDsOnSR
 SM_LIBS += scsiutil
 SM_LIBS += scsi_host_rescan
+SM_LIBS += cowutil
 SM_LIBS += vhdutil
+SM_LIBS += linstorcowutil
 SM_LIBS += linstorjournaler
-SM_LIBS += linstorvhdutil
 SM_LIBS += linstorvolumemanager
-SM_LIBS += lvhdutil
+SM_LIBS += lvmcowutil
 SM_LIBS += cifutils
 SM_LIBS += xs_errors
 SM_LIBS += nfs
@@ -203,7 +204,7 @@ install: build
 	  ln -sf $$i"SR.py" $$i"SR"; \
 	done
 	rm $(SM_STAGING)$(SM_DEST)/SHMSR
-	cd $(SM_STAGING)$(SM_DEST) && rm -f LVMSR && ln -sf LVMSR.py LVHDSR
+	cd $(SM_STAGING)$(SM_DEST) && rm -f LVMSR && ln -sf LVMSR.py LVMSR
 	cd $(SM_STAGING)$(SM_DEST) && rm -f RawISCSISR && ln -sf RawISCSISR.py ISCSISR
 	cd $(SM_STAGING)$(SM_DEST) && rm -f LVMoISCSISR && ln -sf LVMoISCSISR.py LVMoISCSISR
 	cd $(SM_STAGING)$(SM_DEST) && rm -f LVMoHBASR && ln -sf LVMoHBASR.py LVMoHBASR
diff --git a/drivers/02-vhdcleanup b/drivers/02-vhdcleanup
index b291c1a0..aa273d30 100644
--- a/drivers/02-vhdcleanup
+++ b/drivers/02-vhdcleanup
@@ -21,7 +21,7 @@
 . /etc/init.d/functions
 
 CLEANUP_SCRIPT="/opt/xensource/sm/cleanup.py"
-LVHD_UTIL_SCRIPT="/opt/xensource/sm/lvhdutil.py"
+LVM_COW_UTIL_SCRIPT="/opt/xensource/sm/lvmcowutil.py"
 
 start() {
     echo -n $"Fixing refcounts on new master: "
@@ -31,7 +31,7 @@ start() {
         srUuids=`xe sr-list type=$type params=uuid --minimal | sed "s/,/ /g"`
         for uuid in $srUuids; do
             echo -n "Fixing $type"
-            python $LVHD_UTIL_SCRIPT fixrefcounts $uuid
+            python $LVM_COW_UTIL_SCRIPT fixrefcounts $uuid
         done
     done
 	echo -n $"OK"
diff --git a/drivers/CephFSSR.py b/drivers/CephFSSR.py
index 574190d6..8e7c173d 100644
--- a/drivers/CephFSSR.py
+++ b/drivers/CephFSSR.py
@@ -39,7 +39,6 @@ import VDI
 import cleanup
 import lock
 import util
-import vhdutil
 import xs_errors
 
 CAPABILITIES = ["SR_PROBE", "SR_UPDATE",
diff --git a/drivers/EXTSR.py b/drivers/EXTSR.py
index bdbdb01d..c342d5a1 100755
--- a/drivers/EXTSR.py
+++ b/drivers/EXTSR.py
@@ -31,7 +31,6 @@ import scsiutil
 import lock
 import os
 import xs_errors
-import vhdutil
 from constants import EXT_PREFIX
 
 CAPABILITIES = ["SR_PROBE", "SR_UPDATE", "SR_SUPPORTS_LOCAL_CACHING",
diff --git a/drivers/FileSR.py b/drivers/FileSR.py
index 95832ecd..8e97105d 100755
--- a/drivers/FileSR.py
+++ b/drivers/FileSR.py
@@ -24,7 +24,6 @@ import VDI
 import SRCommand
 import util
 import scsiutil
-import vhdutil
 import lock
 import os
 import errno
@@ -34,7 +33,8 @@ import blktap2
 import time
 import glob
 from uuid import uuid4
-from vditype import VdiType, VdiTypeExtension, VDI_TYPE_TO_EXTENSION
+from cowutil import CowImageInfo, CowUtil, ImageFormat, getCowUtil, getVdiTypeFromImageFormat
+from vditype import VdiType, VdiTypeExtension, VDI_COW_TYPES, VDI_TYPE_TO_EXTENSION
 import xmlrpc.client
 import XenAPI # pylint: disable=import-error
 from constants import CBTLOG_TAG
@@ -46,7 +46,10 @@ CAPABILITIES = ["SR_PROBE", "SR_UPDATE", \
                 "VDI_GENERATE_CONFIG", "ATOMIC_PAUSE", "VDI_CONFIG_CBT",
                 "VDI_ACTIVATE", "VDI_DEACTIVATE", "THIN_PROVISIONING"]
 
-CONFIGURATION = [['location', 'local directory path (required)']]
+CONFIGURATION = [
+    ['location', 'local directory path (required)'],
+    ['preferred-image-formats', 'list of preferred image formats to use (default: VHD)']
+]
 
 DRIVER_INFO = {
     'name': 'Local Path VHD',
@@ -91,6 +94,8 @@ class FileSR(SR.SR):
         # We call SR.SR.__init__ explicitly because
         # "super" sometimes failed due to circular imports
         SR.SR.__init__(self, srcmd, sr_uuid)
+        self.image_info = {}
+        self._init_preferred_image_formats()
         self._check_o_direct()
 
     @override
@@ -109,7 +114,7 @@ class FileSR(SR.SR):
 
     @override
     def create(self, sr_uuid, size) -> None:
-        """ Create the SR.  The path must not already exist, or if it does, 
+        """ Create the SR.  The path must not already exist, or if it does,
         it must be empty.  (This accounts for the case where the user has
         mounted a device onto a directory manually and want to use this as the
         root of a file-based SR.) """
@@ -277,26 +282,40 @@ class FileSR(SR.SR):
         if self.vdis:
             return
 
-        pattern = os.path.join(self.path, "*%s" % VdiTypeExtension.VHD)
-        try:
-            self.vhds = vhdutil.getAllVHDs(pattern, FileVDI.extractUuid)
-        except util.CommandException as inst:
-            raise xs_errors.XenError('SRScan', opterr="error VHD-scanning " \
-                    "path %s (%s)" % (self.path, inst))
-        try:
-            list_vhds = [FileVDI.extractUuid(v) for v in util.ioretry(lambda: glob.glob(pattern))]
-            if len(self.vhds) != len(list_vhds):
-                util.SMlog("VHD scan returns %d VHDs: %s" % (len(self.vhds), sorted(self.vhds)))
-                util.SMlog("VHD list returns %d VHDs: %s" % (len(list_vhds), sorted(list_vhds)))
-        except:
-            pass
-        for uuid in self.vhds.keys():
-            if self.vhds[uuid].error:
+        self.image_info = {}
+        for vdi_type in VDI_COW_TYPES:
+            extension = VDI_TYPE_TO_EXTENSION[vdi_type]
+
+            pattern = os.path.join(self.path, "*%s" % extension)
+            info = {}
+
+            cowutil = getCowUtil(vdi_type)
+            try:
+                info = cowutil.getAllInfoFromVG(pattern, FileVDI.extractUuid)
+            except util.CommandException as inst:
+                raise xs_errors.XenError('SRScan', opterr="error VDI-scanning " \
+                        "path %s (%s)" % (self.path, inst))
+            try:
+                vdi_uuids = [FileVDI.extractUuid(v) for v in util.ioretry(lambda: glob.glob(pattern))]
+                if len(info) != len(vdi_uuids):
+                    util.SMlog("VDI scan of %s returns %d VDIs: %s" % (extension, len(info), sorted(info)))
+                    util.SMlog("VDI list of %s returns %d VDIs: %s" % (extension, len(vdi_uuids), sorted(vdi_uuids)))
+            except:
+                pass
+
+            self.image_info.update(info)
+
+        for uuid in info.keys():
+            if info[uuid].error:
                 raise xs_errors.XenError('SRScan', opterr='uuid=%s' % uuid)
-            self.vdis[uuid] = self.vdi(uuid)
+
+            file_vdi = self.vdi(uuid)
+            file_vdi.cowutil = cowutil
+            self.vdis[uuid] = file_vdi
+
             # Get the key hash of any encrypted VDIs:
-            vhd_path = os.path.join(self.path, self.vhds[uuid].path)
-            key_hash = vhdutil.getKeyHash(vhd_path)
+            vdi_path = os.path.join(self.path, info[uuid].path)
+            key_hash = cowutil.getKeyHash(vdi_path)
             self.vdis[uuid].sm_config_override['key_hash'] = key_hash
 
         # raw VDIs and CBT log files
@@ -418,18 +437,18 @@ class FileSR(SR.SR):
         return True
 
 class FileVDI(VDI.VDI):
-    PARAM_VHD = "vhd"
     PARAM_RAW = "raw"
+    PARAM_VHD = "vhd"
     VDI_TYPE = {
-            PARAM_VHD: VdiType.VHD,
-            PARAM_RAW: VdiType.RAW
+            PARAM_RAW: VdiType.RAW,
+            PARAM_VHD: VdiType.VHD
     }
 
     def _find_path_with_retries(self, vdi_uuid, maxretry=5, period=2.0):
-        vhd_path = os.path.join(self.sr.path, "%s.%s" % \
-                                (vdi_uuid, self.PARAM_VHD))
         raw_path = os.path.join(self.sr.path, "%s.%s" % \
                                 (vdi_uuid, self.PARAM_RAW))
+        vhd_path = os.path.join(self.sr.path, "%s.%s" % \
+                                (vdi_uuid, self.PARAM_VHD))
         cbt_path = os.path.join(self.sr.path, "%s.%s" %
                                 (vdi_uuid, CBTLOG_TAG))
         found = False
@@ -451,8 +470,13 @@ class FileVDI(VDI.VDI):
                 self.hidden = False
                 found = True
 
-            if not found:
-                util.SMlog("VHD %s not found, retry %s of %s" % (vhd_path, tries, maxretry))
+            if found:
+                try:
+                    self.cowutil = getCowUtil(self.vdi_type)
+                except:
+                    pass
+            else:
+                util.SMlog("VDI %s not found, retry %s of %s" % (vdi_uuid, tries, maxretry))
                 time.sleep(period)
 
         return found
@@ -464,7 +488,6 @@ class FileVDI(VDI.VDI):
         self.sr.srcmd.params['o_direct'] = self.sr.o_direct
 
         if self.sr.srcmd.cmd == "vdi_create":
-            self.vdi_type = VdiType.VHD
             self.key_hash = None
             if "vdi_sm_config" in self.sr.srcmd.params:
                 if "key_hash" in self.sr.srcmd.params["vdi_sm_config"]:
@@ -476,6 +499,10 @@ class FileVDI(VDI.VDI):
                         raise xs_errors.XenError('VDIType',
                                 opterr='Invalid VDI type %s' % vdi_type)
                     self.vdi_type = self.VDI_TYPE[vdi_type]
+
+            if not self.vdi_type:
+                self.vdi_type = getVdiTypeFromImageFormat(self.sr.preferred_image_formats[0])
+            self.cowutil = getCowUtil(self.vdi_type)
             self.path = os.path.join(self.sr.path, "%s%s" %
                 (vdi_uuid, VDI_TYPE_TO_EXTENSION[self.vdi_type]))
         else:
@@ -483,25 +510,22 @@ class FileVDI(VDI.VDI):
             if not found:
                 if self.sr.srcmd.cmd == "vdi_delete":
                     # Could be delete for CBT log file
-                    self.path = os.path.join(self.sr.path, "%s.%s" %
-                                             (vdi_uuid, self.PARAM_VHD))
+                    self.path = os.path.join(self.sr.path, f"{vdi_uuid}.deleted")
                     return
                 if self.sr.srcmd.cmd == "vdi_attach_from_config":
                     return
                 raise xs_errors.XenError('VDIUnavailable',
                                          opterr="VDI %s not found" % vdi_uuid)
 
-
-        if VdiType.isCowImage(self.vdi_type) and \
-                self.sr.__dict__.get("vhds") and self.sr.vhds.get(vdi_uuid):
-            # VHD info already preloaded: use it instead of querying directly
-            vhdInfo = self.sr.vhds[vdi_uuid]
-            self.utilisation = vhdInfo.sizePhys
-            self.size = vhdInfo.sizeVirt
-            self.hidden = vhdInfo.hidden
+        image_info = VdiType.isCowImage(self.vdi_type) and self.sr.image_info.get(vdi_uuid)
+        if image_info:
+            # Image info already preloaded: use it instead of querying directly
+            self.utilisation = image_info.sizePhys
+            self.size = image_info.sizeVirt
+            self.hidden = image_info.hidden
             if self.hidden:
                 self.managed = False
-            self.parent = vhdInfo.parentUuid
+            self.parent = image_info.parentUuid
             if self.parent:
                 self.sm_config_override = {'vhd-parent': self.parent}
             else:
@@ -548,18 +572,16 @@ class FileVDI(VDI.VDI):
             try:
                 # The VDI might be activated in R/W mode so the VHD footer
                 # won't be valid, use the back-up one instead.
-                diskinfo = util.ioretry(
-                    lambda: self._query_info(self.path, True),
-                    errlist=[errno.EIO, errno.ENOENT])
+                image_info = self.cowutil.getInfo(self.path, FileVDI.extractUuid, useBackupFooter=True)
 
-                if 'parent' in diskinfo:
-                    self.parent = diskinfo['parent']
+                if image_info.parentUuid:
+                    self.parent = image_info.parentUuid
                     self.sm_config_override = {'vhd-parent': self.parent}
                 else:
+                    self.parent = ""
                     self.sm_config_override = {'vhd-parent': None}
-                    self.parent = ''
-                self.size = int(diskinfo['size']) * 1024 * 1024
-                self.hidden = int(diskinfo['hidden'])
+                self.size = image_info.sizeVirt
+                self.hidden = image_info.hidden
                 if self.hidden:
                     self.managed = False
                 self.exists = True
@@ -581,11 +603,9 @@ class FileVDI(VDI.VDI):
 
         if VdiType.isCowImage(self.vdi_type):
             try:
-                size = vhdutil.validate_and_round_vhd_size(int(size))
-                mb = 1024 * 1024
-                size_mb = size // mb
-                util.ioretry(lambda: self._create(str(size_mb), self.path))
-                self.size = util.ioretry(lambda: self._query_v(self.path))
+                size = self.cowutil.validateAndRoundImageSize(int(size))
+                util.ioretry(lambda: self._create(size, self.path))
+                self.size = self.cowutil.getSizeVirt(self.path)
             except util.CommandException as inst:
                 raise xs_errors.XenError('VDICreate',
                         opterr='error %d' % inst.code)
@@ -679,19 +699,19 @@ class FileVDI(VDI.VDI):
         if size == self.size:
             return VDI.VDI.get_params(self)
 
-        # We already checked it is a VHD
-        size = vhdutil.validate_and_round_vhd_size(int(size))
-        
+        # We already checked it is a cow image.
+        size = self.cowutil.validateAndRoundImageSize(int(size))
+
         jFile = JOURNAL_FILE_PREFIX + self.uuid
         try:
-            vhdutil.setSizeVirt(self.path, size, jFile)
+            self.cowutil.setSizeVirt(self.path, size, jFile)
         except:
             # Revert the operation
-            vhdutil.revert(self.path, jFile)
+            self.cowutil.revert(self.path, jFile)
             raise xs_errors.XenError('VDISize', opterr='resize operation failed')
 
         old_size = self.size
-        self.size = vhdutil.getSizeVirt(self.path)
+        self.size = self.cowutil.getSizeVirt(self.path)
         st = util.ioretry(lambda: os.stat(self.path))
         self.utilisation = int(st.st_size)
 
@@ -708,14 +728,12 @@ class FileVDI(VDI.VDI):
     def compose(self, sr_uuid, vdi1, vdi2) -> None:
         if not VdiType.isCowImage(self.vdi_type):
             raise xs_errors.XenError('Unimplemented')
-        parent_fn = vdi1 + VDI_TYPE_TO_EXTENSION[VdiType.VHD]
+        parent_fn = vdi1 + VDI_TYPE_TO_EXTENSION[self.vdi_type]
         parent_path = os.path.join(self.sr.path, parent_fn)
         assert(util.pathexists(parent_path))
-        vhdutil.setParent(self.path, parent_path, False)
-        vhdutil.setHidden(parent_path)
+        self.cowutil.setParent(self.path, parent_path, False)
+        self.cowutil.setHidden(parent_path)
         self.sr.session.xenapi.VDI.set_managed(self.sr.srcmd.params['args'][0], False)
-        util.pread2([vhdutil.VHD_UTIL, "modify", "-p", parent_path,
-            "-n", self.path])
         # Tell tapdisk the chain has changed
         if not blktap2.VDI.tap_refresh(self.session, sr_uuid, vdi2):
             raise util.SMException("failed to refresh VDI %s" % self.uuid)
@@ -726,11 +744,11 @@ class FileVDI(VDI.VDI):
             raise xs_errors.XenError('Unimplemented')
 
         # safety check
-        if not vhdutil.hasParent(self.path):
+        if not self.cowutil.hasParent(self.path):
             raise util.SMException("ERROR: VDI %s has no parent, " + \
                     "will not reset contents" % self.uuid)
 
-        vhdutil.killData(self.path)
+        self.cowutil.killData(self.path)
 
     @override
     def _do_snapshot(self, sr_uuid, vdi_uuid, snapType,
@@ -777,7 +795,7 @@ class FileVDI(VDI.VDI):
             self._rename(src, newsrc)
 
     def __fist_enospace(self):
-        raise util.CommandException(28, "vhd-util snapshot", reason="No space")
+        raise util.CommandException(28, "cowutil snapshot", reason="No space")
 
     def _snapshot(self, snap_type, cbtlog=None, cbt_consistency=None):
         util.SMlog("FileVDI._snapshot for %s (type %s)" % (self.uuid, snap_type))
@@ -789,25 +807,26 @@ class FileVDI(VDI.VDI):
 
         dest = None
         dst = None
+        extension = VDI_TYPE_TO_EXTENSION[self.vdi_type]
         if snap_type == VDI.SNAPSHOT_DOUBLE:
             dest = util.gen_uuid()
-            dst = os.path.join(self.sr.path, "%s.%s" % (dest, self.vdi_type))
+            dst = os.path.join(self.sr.path, "%s.%s" % (dest, extension))
             args.append(dest)
 
         if self.hidden:
             raise xs_errors.XenError('VDIClone', opterr='hidden VDI')
 
-        depth = vhdutil.getDepth(self.path)
+        depth = self.cowutil.getDepth(self.path)
         if depth == -1:
             raise xs_errors.XenError('VDIUnavailable', \
-                  opterr='failed to get VHD depth')
-        elif depth >= vhdutil.MAX_CHAIN_SIZE:
+                  opterr='failed to get image depth')
+        elif depth >= self.cowutil.getMaxChainLength():
             raise xs_errors.XenError('SnapshotChainTooLong')
 
         newuuid = util.gen_uuid()
         src = self.path
-        newsrc = os.path.join(self.sr.path, "%s.%s" % (newuuid, self.vdi_type))
-        newsrcname = "%s.%s" % (newuuid, self.vdi_type)
+        newsrc = os.path.join(self.sr.path, "%s%s" % (newuuid, extension))
+        newsrcname = "%s.%s" % (newuuid, extension)
 
         if not self._checkpath(src):
             raise xs_errors.XenError('VDIUnavailable', \
@@ -848,18 +867,18 @@ class FileVDI(VDI.VDI):
             #Verify parent locator field of both children and delete newsrc if unused
             introduce_parent = True
             try:
-                srcparent = util.ioretry(lambda: self._query_p_uuid(src))
+                srcparent = self.cowutil.getParent(src, FileVDI.extractUuid)
                 dstparent = None
                 if snap_type == VDI.SNAPSHOT_DOUBLE:
-                    dstparent = util.ioretry(lambda: self._query_p_uuid(dst))
+                    dstparent = self.cowutil.getParent(dst, FileVDI.extractUuid)
                 if srcparent != newuuid and \
                         (snap_type == VDI.SNAPSHOT_SINGLE or \
                         snap_type == VDI.SNAPSHOT_INTERNAL or \
                         dstparent != newuuid):
                     util.ioretry(lambda: self._unlink(newsrc))
                     introduce_parent = False
-            except:
-                pass
+            except Exception as e:
+                raise
 
             # Introduce the new VDI records
             leaf_vdi = None
@@ -891,8 +910,8 @@ class FileVDI(VDI.VDI):
                 base_vdi.size = self.size
                 base_vdi.utilisation = self.utilisation
                 base_vdi.sm_config = {}
-                grandparent = util.ioretry(lambda: self._query_p_uuid(newsrc))
-                if grandparent.find("no parent") == -1:
+                grandparent = self.cowutil.getParent(newsrc, FileVDI.extractUuid)
+                if grandparent:
                     base_vdi.sm_config['vhd-parent'] = grandparent
 
             try:
@@ -950,8 +969,7 @@ class FileVDI(VDI.VDI):
         return super(FileVDI, self).get_params()
 
     def _snap(self, child, parent):
-        cmd = [SR.TAPDISK_UTIL, "snapshot", VdiType.VHD, child, parent]
-        text = util.pread(cmd)
+        self.cowutil.snapshot(child, parent, self.vdi_type == VdiType.RAW)
 
     def _clonecleanup(self, src, dst, newsrc):
         try:
@@ -979,48 +997,21 @@ class FileVDI(VDI.VDI):
             raise xs_errors.XenError('EIO', \
                   opterr='IO error checking path %s' % path)
 
-    def _query_v(self, path):
-        cmd = [SR.TAPDISK_UTIL, "query", VdiType.VHD, "-v", path]
-        return int(util.pread(cmd)) * 1024 * 1024
-
-    def _query_p_uuid(self, path):
-        cmd = [SR.TAPDISK_UTIL, "query", VdiType.VHD, "-p", path]
-        parent = util.pread(cmd)
-        parent = parent[:-1]
-        ls = parent.split('/')
-        return ls[len(ls) - 1].replace(VdiTypeExtension.VHD, '')
-
-    def _query_info(self, path, use_bkp_footer=False):
-        diskinfo = {}
-        qopts = '-vpf'
-        if use_bkp_footer:
-            qopts += 'b'
-        cmd = [SR.TAPDISK_UTIL, "query", VdiType.VHD, qopts, path]
-        txt = util.pread(cmd).split('\n')
-        diskinfo['size'] = txt[0]
-        lst = [txt[1].split('/')[-1].replace(VdiTypeExtension.VHD, "")]
-        for val in filter(util.exactmatch_uuid, lst):
-            diskinfo['parent'] = val
-        diskinfo['hidden'] = txt[2].split()[1]
-        return diskinfo
-
     def _create(self, size, path):
-        cmd = [SR.TAPDISK_UTIL, "create", VdiType.VHD, size, path]
-        text = util.pread(cmd)
+        self.cowutil.create(path, size, False)
         if self.key_hash:
-            vhdutil.setKey(path, self.key_hash)
+            self.cowutil.setKey(path, self.key_hash)
 
     def _mark_hidden(self, path):
-        vhdutil.setHidden(path, True)
+        self.cowutil.setHidden(path, True)
         self.hidden = 1
 
     def _is_hidden(self, path):
-        return vhdutil.getHidden(path) == 1
+        return self.cowutil.getHidden(path) == 1
 
     def extractUuid(path):
         fileName = os.path.basename(path)
-        uuid = fileName.replace(VdiTypeExtension.VHD, "")
-        return uuid
+        return os.path.splitext(fileName)[0]
     extractUuid = staticmethod(extractUuid)
 
     @override
diff --git a/drivers/GlusterFSSR.py b/drivers/GlusterFSSR.py
index 1d8f8ab2..406d4064 100644
--- a/drivers/GlusterFSSR.py
+++ b/drivers/GlusterFSSR.py
@@ -35,7 +35,6 @@ import VDI
 import cleanup
 import lock
 import util
-import vhdutil
 import xs_errors
 
 CAPABILITIES = ["SR_PROBE", "SR_UPDATE",
diff --git a/drivers/LVMSR.py b/drivers/LVMSR.py
index cd9e007a..4b8a2bea 100755
--- a/drivers/LVMSR.py
+++ b/drivers/LVMSR.py
@@ -27,8 +27,6 @@ import SRCommand
 import util
 import lvutil
 import lvmcache
-import vhdutil
-import lvhdutil
 import scsiutil
 import lock
 import os
@@ -42,6 +40,8 @@ from journaler import Journaler
 from refcounter import RefCounter
 from ipc import IPCFlag
 from constants import NS_PREFIX_LVM, VG_LOCATION, VG_PREFIX
+from cowutil import CowUtil, getCowUtil, getVdiTypeFromImageFormat
+from lvmcowutil import LV_PREFIX, LvmCowUtil
 from lvmanager import LVActivator
 from vditype import VdiType
 import XenAPI # pylint: disable=import-error
@@ -79,8 +79,10 @@ DRIVER_INFO = {
     'configuration': CONFIGURATION
     }
 
-PARAM_VHD = "vhd"
-PARAM_RAW = "raw"
+CREATE_PARAM_TYPES = {
+    "raw": VdiType.RAW,
+    "vhd": VdiType.VHD
+}
 
 OPS_EXCLUSIVE = [
         "sr_create", "sr_delete", "sr_attach", "sr_detach", "sr_scan",
@@ -152,6 +154,10 @@ class LVMSR(SR.SR):
             return type == "ext"
         return type == LVMSR.DRIVER_TYPE
 
+    def __init__(self, srcmd, sr_uuid):
+        SR.SR.__init__(self, srcmd, sr_uuid)
+        self._init_preferred_image_formats()
+
     @override
     def load(self, sr_uuid) -> None:
         self.ops_exclusive = OPS_EXCLUSIVE
@@ -226,17 +232,11 @@ class LVMSR(SR.SR):
             type = None
             vdi = None
             if contains_uuid_regex.search(key) is not None:
-                if key.startswith(lvhdutil.LV_PREFIX[VdiType.VHD]):
-                    type = VdiType.VHD
-                    vdi = key[len(lvhdutil.LV_PREFIX[type]):]
-                elif key.startswith(lvhdutil.LV_PREFIX[VdiType.RAW]):
-                    type = VdiType.RAW
-                    vdi = key[len(lvhdutil.LV_PREFIX[type]):]
-                else:
-                    continue
-
-            if type is not None:
-                self.storageVDIs[vdi] = type
+                for vdi_type, prefix in LV_PREFIX.items():
+                    if key.startswith(prefix):
+                        vdi = key[len(prefix):]
+                        self.storageVDIs[vdi] = vdi_type
+                        break
 
         # check if metadata volume exists
         try:
@@ -563,7 +563,7 @@ class LVMSR(SR.SR):
 
         self._removeMetadataVolume()
         self.lvmCache.refresh()
-        if len(lvhdutil.getLVInfo(self.lvmCache)) > 0:
+        if LvmCowUtil.getVolumeInfo(self.lvmCache):
             raise xs_errors.XenError('SRNotEmpty')
 
         if not success:
@@ -598,9 +598,9 @@ class LVMSR(SR.SR):
                 self.session, self.sr_ref,
                 scsiutil.devlist_to_serialstring(self.dconf['device'].split(',')))
 
-        # Test Legacy Mode Flag and update if VHD volumes exist
+        # Test Legacy Mode Flag and update if COW volumes exist
         if self.isMaster and self.legacyMode:
-            vdiInfo = lvhdutil.getVDIInfo(self.lvmCache)
+            vdiInfo = LvmCowUtil.getVDIInfo(self.lvmCache)
             for uuid, info in vdiInfo.items():
                 if VdiType.isCowImage(info.vdiType):
                     self.legacyMode = False
@@ -721,33 +721,33 @@ class LVMSR(SR.SR):
                         vdi_type = info[vdi][VDI_TYPE_TAG]
                         sm_config = {}
                         sm_config['vdi_type'] = vdi_type
-                        lvname = "%s%s" % \
-                            (lvhdutil.LV_PREFIX[sm_config['vdi_type']], vdi_uuid)
+                        lvname = "%s%s" % (LV_PREFIX[sm_config['vdi_type']], vdi_uuid)
                         self.lvActivator.activate(
                             vdi_uuid, lvname, LVActivator.NORMAL)
                         activated_lvs.add(vdi_uuid)
                         lvPath = os.path.join(self.path, lvname)
 
                         if not VdiType.isCowImage(vdi_type):
-                            size = self.lvmCache.getSize( \
-                                lvhdutil.LV_PREFIX[vdi_type] + vdi_uuid)
+                            size = self.lvmCache.getSize(LV_PREFIX[vdi_type] + vdi_uuid)
                             utilisation = \
                                         util.roundup(lvutil.LVM_SIZE_INCREMENT,
                                                        int(size))
                         else:
-                            parent = \
-                                vhdutil._getVHDParentNoCheck(lvPath)
+                            cowutil = getCowUtil(vdi_type)
+                            lvmcowutil = LvmCowUtil(cowutil)
+
+                            parent = cowutil.getParentNoCheck(lvPath)
 
                             if parent is not None:
-                                sm_config['vhd-parent'] = parent[len( \
-                                    lvhdutil.LV_PREFIX[VdiType.VHD]):]
-                            size = vhdutil.getSizeVirt(lvPath)
+                                sm_config['vhd-parent'] = parent[parent.find('-') + 1:]
+                            size = cowutil.getSizeVirt(lvPath)
                             if self.provision == "thin":
-                                utilisation = \
-                                    util.roundup(lvutil.LVM_SIZE_INCREMENT,
-                                      vhdutil.calcOverheadEmpty(lvhdutil.MSIZE))
+                                utilisation = util.roundup(
+                                    lvutil.LVM_SIZE_INCREMENT,
+                                    cowutil.calcOverheadEmpty(max(size, cowutil.getDefaultPreallocationSizeVirt()))
+                                )
                             else:
-                                utilisation = lvhdutil.calcSizeVHDLV(int(size))
+                                utilisation = lvmcowutil.calcVolumeSize(int(size))
 
                         vdi_ref = self.session.xenapi.VDI.db_introduce(
                                         vdi_uuid,
@@ -872,7 +872,7 @@ class LVMSR(SR.SR):
 
     def _loadvdis(self):
         self.virtual_allocation = 0
-        self.vdiInfo = lvhdutil.getVDIInfo(self.lvmCache)
+        self.vdiInfo = LvmCowUtil.getVDIInfo(self.lvmCache)
         self.allVDIs = {}
 
         for uuid, info in self.vdiInfo.items():
@@ -925,12 +925,12 @@ class LVMSR(SR.SR):
 
     def _handleInterruptedCloneOp(self, origUuid, jval, forceUndo=False):
         """Either roll back or finalize the interrupted snapshot/clone
-        operation. Rolling back is unsafe if the leaf VHDs have already been
+        operation. Rolling back is unsafe if the leaf images have already been
         in use and written to. However, it is always safe to roll back while
         we're still in the context of the failed snapshot operation since the
         VBD is paused for the duration of the operation"""
         util.SMlog("*** INTERRUPTED CLONE OP: for %s (%s)" % (origUuid, jval))
-        lvs = lvhdutil.getLVInfo(self.lvmCache)
+        lvs = LvmCowUtil.getVolumeInfo(self.lvmCache)
         baseUuid, clonUuid = jval.split("_")
 
         # is there a "base copy" VDI?
@@ -942,48 +942,51 @@ class LVMSR(SR.SR):
             raise util.SMException("base copy %s not present, " \
                     "but no original %s found" % (baseUuid, origUuid))
 
+        vdis = LvmCowUtil.getVDIInfo(self.lvmCache)
+        base = vdis[baseUuid]
+        cowutil = getCowUtil(base.vdiType)
+
         if forceUndo:
             util.SMlog("Explicit revert")
-            self._undoCloneOp(lvs, origUuid, baseUuid, clonUuid)
+            self._undoCloneOp(cowutil, lvs, origUuid, baseUuid, clonUuid)
             return
 
         if not lvs.get(origUuid) or (clonUuid and not lvs.get(clonUuid)):
             util.SMlog("One or both leaves missing => revert")
-            self._undoCloneOp(lvs, origUuid, baseUuid, clonUuid)
+            self._undoCloneOp(cowutil, lvs, origUuid, baseUuid, clonUuid)
             return
 
-        vdis = lvhdutil.getVDIInfo(self.lvmCache)
         if vdis[origUuid].scanError or (clonUuid and vdis[clonUuid].scanError):
             util.SMlog("One or both leaves invalid => revert")
-            self._undoCloneOp(lvs, origUuid, baseUuid, clonUuid)
+            self._undoCloneOp(cowutil, lvs, origUuid, baseUuid, clonUuid)
             return
 
         orig = vdis[origUuid]
-        base = vdis[baseUuid]
         self.lvActivator.activate(baseUuid, base.lvName, False)
         self.lvActivator.activate(origUuid, orig.lvName, False)
         if orig.parentUuid != baseUuid:
             parent = vdis[orig.parentUuid]
             self.lvActivator.activate(parent.uuid, parent.lvName, False)
         origPath = os.path.join(self.path, orig.lvName)
-        if not vhdutil.check(origPath):
-            util.SMlog("Orig VHD invalid => revert")
-            self._undoCloneOp(lvs, origUuid, baseUuid, clonUuid)
+
+        if cowutil.check(origPath) != CowUtil.CheckResult.Success:
+            util.SMlog("Orig image invalid => revert")
+            self._undoCloneOp(cowutil, lvs, origUuid, baseUuid, clonUuid)
             return
 
         if clonUuid:
             clon = vdis[clonUuid]
             clonPath = os.path.join(self.path, clon.lvName)
             self.lvActivator.activate(clonUuid, clon.lvName, False)
-            if not vhdutil.check(clonPath):
-                util.SMlog("Clon VHD invalid => revert")
-                self._undoCloneOp(lvs, origUuid, baseUuid, clonUuid)
+            if cowutil.check(clonPath) != CowUtil.CheckResult.Success:
+                util.SMlog("Clon image invalid => revert")
+                self._undoCloneOp(cowutil, lvs, origUuid, baseUuid, clonUuid)
                 return
 
         util.SMlog("Snapshot appears valid, will not roll back")
-        self._completeCloneOp(vdis, origUuid, baseUuid, clonUuid)
+        self._completeCloneOp(cowutil, vdis, origUuid, baseUuid, clonUuid)
 
-    def _undoCloneOp(self, lvs, origUuid, baseUuid, clonUuid):
+    def _undoCloneOp(self, cowutil, lvs, origUuid, baseUuid, clonUuid):
         base = lvs[baseUuid]
         basePath = os.path.join(self.path, base.name)
 
@@ -999,16 +1002,16 @@ class LVMSR(SR.SR):
         if VdiType.isCowImage(base.vdiType):
             self.lvActivator.activate(baseUuid, base.name, False)
             origRefcountNormal = 1
-            vhdInfo = vhdutil.getVHDInfo(basePath, lvhdutil.extractUuid, False)
-            if vhdInfo.hidden:
-                vhdutil.setHidden(basePath, False)
+            imageInfo = cowutil.getInfo(basePath, LvmCowUtil.extractUuid, False)
+            if imageInfo.hidden:
+                cowutil.setHidden(basePath, False)
         elif base.hidden:
             self.lvmCache.setHidden(base.name, False)
 
         # remove the child nodes
         if clonUuid and lvs.get(clonUuid):
             if not VdiType.isCowImage(lvs[clonUuid].vdiType):
-                raise util.SMException("clone %s not VHD" % clonUuid)
+                raise util.SMException("clone %s not a COW image" % clonUuid)
             self.lvmCache.remove(lvs[clonUuid].name)
             if self.lvActivator.get(clonUuid, False):
                 self.lvActivator.remove(clonUuid, False)
@@ -1017,11 +1020,12 @@ class LVMSR(SR.SR):
 
         # inflate the parent to fully-allocated size
         if VdiType.isCowImage(base.vdiType):
-            fullSize = lvhdutil.calcSizeVHDLV(vhdInfo.sizeVirt)
-            lvhdutil.inflate(self.journaler, self.uuid, baseUuid, fullSize)
+            lvmcowutil = LvmCowUtil(cowutil)
+            fullSize = lvmcowutil.calcVolumeSize(imageInfo.sizeVirt)
+            lvmcowutil.inflate(self.journaler, self.uuid, baseUuid, base.vdiType, fullSize)
 
         # rename back
-        origLV = lvhdutil.LV_PREFIX[base.vdiType] + origUuid
+        origLV = LV_PREFIX[base.vdiType] + origUuid
         self.lvmCache.rename(base.name, origLV)
         RefCounter.reset(baseUuid, ns)
         if self.lvActivator.get(baseUuid, False):
@@ -1035,12 +1039,12 @@ class LVMSR(SR.SR):
 
         # update LVM metadata on slaves
         slaves = util.get_slaves_attached_on(self.session, [origUuid])
-        lvhdutil.lvRefreshOnSlaves(self.session, self.uuid, self.vgname,
+        LvmCowUtil.refreshVolumeOnSlaves(self.session, self.uuid, self.vgname,
                 origLV, origUuid, slaves)
 
         util.SMlog("*** INTERRUPTED CLONE OP: rollback success")
 
-    def _completeCloneOp(self, vdis, origUuid, baseUuid, clonUuid):
+    def _completeCloneOp(self, cowutil, vdis, origUuid, baseUuid, clonUuid):
         """Finalize the interrupted snapshot/clone operation. This must not be
         called from the live snapshot op context because we attempt to pause/
         unpause the VBD here (the VBD is already paused during snapshot, so it
@@ -1058,7 +1062,7 @@ class LVMSR(SR.SR):
                 self.lvmCache.setHidden(base.lvName)
             else:
                 basePath = os.path.join(self.path, base.lvName)
-                vhdutil.setHidden(basePath)
+                cowutil.setHidden(basePath)
         if not base.lvReadonly:
             self.lvmCache.setReadonly(base.lvName, True)
 
@@ -1071,7 +1075,7 @@ class LVMSR(SR.SR):
             vdi_ref = self.session.xenapi.VDI.get_by_uuid(origUuid)
             sm_config = self.session.xenapi.VDI.get_sm_config(vdi_ref)
             type = self.session.xenapi.VDI.get_type(vdi_ref)
-            sm_config["vdi_type"] = VdiType.VHD
+            sm_config["vdi_type"] = vdis[origUuid].vdiType
             sm_config['vhd-parent'] = baseUuid
             self.session.xenapi.VDI.set_sm_config(vdi_ref, sm_config)
         except XenAPI.Failure:
@@ -1085,7 +1089,7 @@ class LVMSR(SR.SR):
                 clon_vdi.location = clonUuid
                 clon_vdi.utilisation = clon.sizeLV
                 clon_vdi.sm_config = {
-                        "vdi_type": VdiType.VHD,
+                        "vdi_type": clon.vdiType,
                         "vhd-parent": baseUuid}
 
                 if not self.legacyMode:
@@ -1124,7 +1128,7 @@ class LVMSR(SR.SR):
             base_vdi.utilisation = base.sizeLV
             base_vdi.managed = False
             base_vdi.sm_config = {
-                    "vdi_type": VdiType.VHD,
+                    "vdi_type": base.vdiType,
                     "vhd-parent": baseUuid}
 
             if not self.legacyMode:
@@ -1155,14 +1159,14 @@ class LVMSR(SR.SR):
         util.SMlog("*** INTERRUPTED CLONE OP: complete")
 
     def _undoAllJournals(self):
-        """Undo all VHD & SM interrupted journaled operations. This call must
+        """Undo all COW image & SM interrupted journaled operations. This call must
         be serialized with respect to all operations that create journals"""
-        # undoing interrupted inflates must be done first, since undoing VHD
+        # undoing interrupted inflates must be done first, since undoing COW images
         # ops might require inflations
         self.lock.acquire()
         try:
             self._undoAllInflateJournals()
-            self._undoAllVHDJournals()
+            self._undoAllCowJournals()
             self._handleInterruptedCloneOps()
             self._handleInterruptedCoalesceLeaf()
         finally:
@@ -1170,7 +1174,7 @@ class LVMSR(SR.SR):
             self.cleanup()
 
     def _undoAllInflateJournals(self):
-        entries = self.journaler.getAll(lvhdutil.JRN_INFLATE)
+        entries = self.journaler.getAll(LvmCowUtil.JOURNAL_INFLATE)
         if len(entries) == 0:
             return
         self._loadvdis()
@@ -1183,45 +1187,57 @@ class LVMSR(SR.SR):
                     self.lvmCache.setReadonly(vdi.lvname, False)
                 self.lvActivator.activate(uuid, vdi.lvname, False)
                 currSizeLV = self.lvmCache.getSize(vdi.lvname)
-                util.zeroOut(vdi.path, currSizeLV - vhdutil.VHD_FOOTER_SIZE,
-                        vhdutil.VHD_FOOTER_SIZE)
-                lvhdutil.deflate(self.lvmCache, vdi.lvname, int(val))
+
+                cowutil = getCowUtil(vdi.vdi_type)
+                lvmcowutil = LvmCowUtil(cowutil)
+
+                footer_size = cowutil.getFooterSize()
+                util.zeroOut(vdi.path, currSizeLV - footer_size, footer_size)
+                lvmcowutil.deflate(self.lvmCache, vdi.lvname, int(val))
                 if vdi.readonly:
                     self.lvmCache.setReadonly(vdi.lvname, True)
                 if "true" == self.session.xenapi.SR.get_shared(self.sr_ref):
-                    lvhdutil.lvRefreshOnAllSlaves(self.session, self.uuid,
-                            self.vgname, vdi.lvname, uuid)
-            self.journaler.remove(lvhdutil.JRN_INFLATE, uuid)
+                    LvmCowUtil.refreshVolumeOnAllSlaves(
+                        self.session, self.uuid, self.vgname, vdi.lvname, uuid
+                    )
+            self.journaler.remove(LvmCowUtil.JOURNAL_INFLATE, uuid)
         delattr(self, "vdiInfo")
         delattr(self, "allVDIs")
 
-    def _undoAllVHDJournals(self):
-        """check if there are VHD journals in existence and revert them"""
-        journals = lvhdutil.getAllVHDJournals(self.lvmCache)
+    def _undoAllCowJournals(self):
+        """
+        Check if there are COW journals in existence and revert them.
+        """
+        journals = LvmCowUtil.getAllResizeJournals(self.lvmCache)
         if len(journals) == 0:
             return
         self._loadvdis()
+
         for uuid, jlvName in journals:
             vdi = self.vdis[uuid]
-            util.SMlog("Found VHD journal %s, reverting %s" % (uuid, vdi.path))
+            util.SMlog("Found COW journal %s, reverting %s" % (uuid, vdi.path))
+            cowutil = getCowUtil(vdi.vdi_type)
+            lvmcowutil = LvmCowUtil(cowutil)
+
             self.lvActivator.activate(uuid, vdi.lvname, False)
             self.lvmCache.activateNoRefcount(jlvName)
-            fullSize = lvhdutil.calcSizeVHDLV(vdi.size)
-            lvhdutil.inflate(self.journaler, self.uuid, vdi.uuid, fullSize)
+            fullSize = lvmcowutil.calcVolumeSize(vdi.size)
+            lvmcowutil.inflate(self.journaler, self.uuid, vdi.uuid, vdi.vdi_type, fullSize)
             try:
                 jFile = os.path.join(self.path, jlvName)
-                vhdutil.revert(vdi.path, jFile)
+                cowutil.revert(vdi.path, jFile)
             except util.CommandException:
-                util.logException("VHD journal revert")
-                vhdutil.check(vdi.path)
-                util.SMlog("VHD revert failed but VHD ok: removing journal")
+                util.logException("COW journal revert")
+                cowutil.check(vdi.path)
+                util.SMlog("COW image revert failed but COW image ok: removing journal")
             # Attempt to reclaim unused space
-            vhdInfo = vhdutil.getVHDInfo(vdi.path, lvhdutil.extractUuid, False)
-            NewSize = lvhdutil.calcSizeVHDLV(vhdInfo.sizeVirt)
+
+
+            imageInfo = cowutil.getInfo(vdi.path, LvmCowUtil.extractUuid, False)
+            NewSize = lvmcowutil.calcVolumeSize(imageInfo.sizeVirt)
             if NewSize < fullSize:
-                lvhdutil.deflate(self.lvmCache, vdi.lvname, int(NewSize))
-            lvhdutil.lvRefreshOnAllSlaves(self.session, self.uuid,
-                    self.vgname, vdi.lvname, uuid)
+                lvmcowutil.deflate(self.lvmCache, vdi.lvname, int(NewSize))
+            LvmCowUtil.refreshVolumeOnAllSlaves(self.session, self.uuid, self.vgname, vdi.lvname, uuid)
             self.lvmCache.remove(jlvName)
         delattr(self, "vdiInfo")
         delattr(self, "allVDIs")
@@ -1334,9 +1350,8 @@ class LVMVDI(VDI.VDI):
         self.lock = self.sr.lock
         self.lvActivator = self.sr.lvActivator
         self.loaded = False
-        self.vdi_type = VdiType.VHD
         if self.sr.legacyMode or util.fistpoint.is_active("xenrt_default_vdi_type_legacy"):
-            self.vdi_type = VdiType.RAW
+            self._setType(VdiType.RAW)
         self.uuid = vdi_uuid
         self.location = self.uuid
         self.exists = True
@@ -1358,16 +1373,18 @@ class LVMVDI(VDI.VDI):
         if "vdi_sm_config" in self.sr.srcmd.params and \
                 "type" in self.sr.srcmd.params["vdi_sm_config"]:
             type = self.sr.srcmd.params["vdi_sm_config"]["type"]
-            if type == PARAM_RAW:
-                self.vdi_type = VdiType.RAW
-            elif type == PARAM_VHD:
-                self.vdi_type = VdiType.VHD
-                if self.sr.cmd == 'vdi_create' and self.sr.legacyMode:
-                    raise xs_errors.XenError('VDICreate', \
-                        opterr='Cannot create VHD type disk in legacy mode')
-            else:
+
+            try:
+                self._setType(CREATE_PARAM_TYPES[type])
+            except:
                 raise xs_errors.XenError('VDICreate', opterr='bad type')
-        self.lvname = "%s%s" % (lvhdutil.LV_PREFIX[self.vdi_type], vdi_uuid)
+            if self.sr.legacyMode and self.sr.cmd == 'vdi_create' and VdiType.isCowImage(self.vdi_type):
+                raise xs_errors.XenError('VDICreate', opterr='Cannot create COW type disk in legacy mode')
+
+        if not self.vdi_type:
+            self._setType(getVdiTypeFromImageFormat(self.sr.preferred_image_formats[0]))
+
+        self.lvname = "%s%s" % (LV_PREFIX[self.vdi_type], vdi_uuid)
         self.path = os.path.join(self.sr.path, self.lvname)
 
     @override
@@ -1378,7 +1395,7 @@ class LVMVDI(VDI.VDI):
         if self.exists:
             raise xs_errors.XenError('VDIExists')
 
-        size = vhdutil.validate_and_round_vhd_size(int(size))
+        size = self.cowutil.validateAndRoundImageSize(int(size))
 
         util.SMlog("LVMVDI.create: type = %s, %s (size=%s)" % \
                 (self.vdi_type, self.path, size))
@@ -1388,10 +1405,12 @@ class LVMVDI(VDI.VDI):
             lvSize = util.roundup(lvutil.LVM_SIZE_INCREMENT, int(size))
         else:
             if self.sr.provision == "thin":
-                lvSize = util.roundup(lvutil.LVM_SIZE_INCREMENT,
-                        vhdutil.calcOverheadEmpty(lvhdutil.MSIZE))
+                lvSize = util.roundup(
+                    lvutil.LVM_SIZE_INCREMENT,
+                    self.cowutil.calcOverheadEmpty(max(size, self.cowutil.getDefaultPreallocationSizeVirt()))
+                )
             elif self.sr.provision == "thick":
-                lvSize = lvhdutil.calcSizeVHDLV(int(size))
+                lvSize = self.lvmcowutil.calcVolumeSize(int(size))
 
         self.sr._ensureSpaceAvailable(lvSize)
 
@@ -1400,8 +1419,10 @@ class LVMVDI(VDI.VDI):
             if not VdiType.isCowImage(self.vdi_type):
                 self.size = self.sr.lvmCache.getSize(self.lvname)
             else:
-                vhdutil.create(self.path, int(size), False, lvhdutil.MSIZE_MB)
-                self.size = vhdutil.getSizeVirt(self.path)
+                self.cowutil.create(
+                    self.path, int(size), False, self.cowutil.getDefaultPreallocationSizeVirt()
+                )
+                self.size = self.cowutil.getSizeVirt(self.path)
             self.sr.lvmCache.deactivateNoRefcount(self.lvname)
         except util.CommandException as e:
             util.SMlog("Unable to create VDI")
@@ -1496,12 +1517,12 @@ class LVMVDI(VDI.VDI):
             needInflate = False
         else:
             self._loadThis()
-            if self.utilisation >= lvhdutil.calcSizeVHDLV(self.size):
+            if self.utilisation >= self.lvmcowutil.calcVolumeSize(self.size):
                 needInflate = False
 
         if needInflate:
             try:
-                self._prepareThin(True)
+                self._prepareThin(True, self.vdi_type)
             except:
                 util.logException("attach")
                 raise xs_errors.XenError('LVMProvisionAttach')
@@ -1517,7 +1538,7 @@ class LVMVDI(VDI.VDI):
         util.SMlog("LVMVDI.detach for %s" % self.uuid)
         self._loadThis()
         already_deflated = (self.utilisation < \
-                lvhdutil.calcSizeVHDLV(self.size))
+                self.lvmcowutil.calcVolumeSize(self.size))
         needDeflate = True
         if not VdiType.isCowImage(self.vdi_type) or already_deflated:
             needDeflate = False
@@ -1532,7 +1553,7 @@ class LVMVDI(VDI.VDI):
 
         if needDeflate:
             try:
-                self._prepareThin(False)
+                self._prepareThin(False, self.vdi_type)
             except:
                 util.logException("_prepareThin")
                 raise xs_errors.XenError('VDIUnavailable', opterr='deflate')
@@ -1559,7 +1580,7 @@ class LVMVDI(VDI.VDI):
                     '(current size: %d, new size: %d)' % (self.size, size))
             raise xs_errors.XenError('VDISize', opterr='shrinking not allowed')
 
-        size = vhdutil.validate_and_round_vhd_size(int(size))
+        size = self.cowutil.validateAndRoundImageSize(int(size))
 
         if size == self.size:
             return VDI.VDI.get_params(self)
@@ -1569,7 +1590,7 @@ class LVMVDI(VDI.VDI):
             lvSizeNew = util.roundup(lvutil.LVM_SIZE_INCREMENT, size)
         else:
             lvSizeOld = self.utilisation
-            lvSizeNew = lvhdutil.calcSizeVHDLV(size)
+            lvSizeNew = self.lvmcowutil.calcVolumeSize(size)
             if self.sr.provision == "thin":
                 # VDI is currently deflated, so keep it deflated
                 lvSizeNew = lvSizeOld
@@ -1584,10 +1605,9 @@ class LVMVDI(VDI.VDI):
             self.utilisation = self.size
         else:
             if lvSizeNew != lvSizeOld:
-                lvhdutil.inflate(self.sr.journaler, self.sr.uuid, self.uuid,
-                        lvSizeNew)
-            vhdutil.setSizeVirtFast(self.path, size)
-            self.size = vhdutil.getSizeVirt(self.path)
+                self.lvmcowutil.inflate(self.sr.journaler, self.sr.uuid, self.uuid, self.vdi_type, lvSizeNew)
+            self.cowutil.setSizeVirtFast(self.path, size)
+            self.size = self.cowutil.getSizeVirt(self.path)
             self.utilisation = self.sr.lvmCache.getSize(self.lvname)
 
         vdi_ref = self.sr.srcmd.params['vdi_ref']
@@ -1610,15 +1630,15 @@ class LVMVDI(VDI.VDI):
             raise xs_errors.XenError('Unimplemented')
 
         parent_uuid = vdi1
-        parent_lvname = lvhdutil.LV_PREFIX[VdiType.VHD] + parent_uuid
+        parent_lvname = LV_PREFIX[self.vdi_type] + parent_uuid
         assert(self.sr.lvmCache.checkLV(parent_lvname))
         parent_path = os.path.join(self.sr.path, parent_lvname)
 
         self.sr.lvActivator.activate(self.uuid, self.lvname, False)
         self.sr.lvActivator.activate(parent_uuid, parent_lvname, False)
 
-        vhdutil.setParent(self.path, parent_path, False)
-        vhdutil.setHidden(parent_path)
+        self.cowutil.setParent(self.path, parent_path, False)
+        self.cowutil.setHidden(parent_path)
         self.sr.session.xenapi.VDI.set_managed(self.sr.srcmd.params['args'][0], False)
 
         if not blktap2.VDI.tap_refresh(self.session, self.sr.uuid, self.uuid,
@@ -1635,11 +1655,11 @@ class LVMVDI(VDI.VDI):
         self.sr.lvActivator.activate(self.uuid, self.lvname, False)
 
         # safety check
-        if not vhdutil.hasParent(self.path):
+        if not self.cowutil.hasParent(self.path):
             raise util.SMException("ERROR: VDI %s has no parent, " + \
                     "will not reset contents" % self.uuid)
 
-        vhdutil.killData(self.path)
+        self.cowutil.killData(self.path)
 
     def _attach(self):
         self._chainSetActive(True, True, True)
@@ -1713,6 +1733,8 @@ class LVMVDI(VDI.VDI):
         if self.hidden:
             raise xs_errors.XenError('VDISnapshot', opterr='hidden VDI')
 
+        snapVdiType = self.sr._get_snap_vdi_type(self.vdi_type, self.size)
+
         self.sm_config = self.session.xenapi.VDI.get_sm_config( \
                 self.sr.srcmd.params['vdi_ref'])
         if "type" in self.sm_config and self.sm_config['type'] == 'raw':
@@ -1720,27 +1742,29 @@ class LVMVDI(VDI.VDI):
                 raise xs_errors.XenError('Unimplemented', \
                         opterr='Raw VDI, snapshot or clone not permitted')
 
-        # we must activate the entire VHD chain because the real parent could
-        # theoretically be anywhere in the chain if all VHDs under it are empty
+        # we must activate the entire image chain because the real parent could
+        # theoretically be anywhere in the chain if all images under it are empty
         self._chainSetActive(True, False)
         if not util.pathexists(self.path):
             raise xs_errors.XenError('VDIUnavailable', \
                     opterr='VDI unavailable: %s' % (self.path))
 
         if VdiType.isCowImage(self.vdi_type):
-            depth = vhdutil.getDepth(self.path)
+            depth = self.cowutil.getDepth(self.path)
             if depth == -1:
                 raise xs_errors.XenError('VDIUnavailable', \
-                        opterr='failed to get VHD depth')
-            elif depth >= vhdutil.MAX_CHAIN_SIZE:
+                        opterr='failed to get COW depth')
+            elif depth >= self.cowutil.getMaxChainLength():
                 raise xs_errors.XenError('SnapshotChainTooLong')
 
         self.issnap = self.session.xenapi.VDI.get_is_a_snapshot( \
                                                 self.sr.srcmd.params['vdi_ref'])
 
-        fullpr = lvhdutil.calcSizeVHDLV(self.size)
-        thinpr = util.roundup(lvutil.LVM_SIZE_INCREMENT, \
-                vhdutil.calcOverheadEmpty(lvhdutil.MSIZE))
+        fullpr = self.lvmcowutil.calcVolumeSize(self.size)
+        thinpr = util.roundup(
+            lvutil.LVM_SIZE_INCREMENT,
+            self.cowutil.calcOverheadEmpty(max(self.size, self.cowutil.getDefaultPreallocationSizeVirt()))
+        )
         lvSizeOrig = thinpr
         lvSizeClon = thinpr
 
@@ -1764,8 +1788,7 @@ class LVMVDI(VDI.VDI):
         size_req = lvSizeOrig + lvSizeClon + 2 * self.sr.journaler.LV_SIZE
         lvSizeBase = self.size
         if VdiType.isCowImage(self.vdi_type):
-            lvSizeBase = util.roundup(lvutil.LVM_SIZE_INCREMENT,
-                    vhdutil.getSizePhys(self.path))
+            lvSizeBase = util.roundup(lvutil.LVM_SIZE_INCREMENT, self.cowutil.getSizePhys(self.path))
             size_req -= (self.utilisation - lvSizeBase)
         self.sr._ensureSpaceAvailable(size_req)
 
@@ -1784,7 +1807,7 @@ class LVMVDI(VDI.VDI):
         try:
             # self becomes the "base vdi"
             origOldLV = self.lvname
-            baseLV = lvhdutil.LV_PREFIX[self.vdi_type] + baseUuid
+            baseLV = LV_PREFIX[self.vdi_type] + baseUuid
             self.sr.lvmCache.rename(self.lvname, baseLV)
             self.sr.lvActivator.replace(self.uuid, baseUuid, baseLV, False)
             RefCounter.set(baseUuid, 1, 0, NS_PREFIX_LVM + self.sr.uuid)
@@ -1799,15 +1822,15 @@ class LVMVDI(VDI.VDI):
             # shrink the base copy to the minimum - we do it before creating
             # the snapshot volumes to avoid requiring double the space
             if VdiType.isCowImage(self.vdi_type):
-                lvhdutil.deflate(self.sr.lvmCache, self.lvname, lvSizeBase)
+                self.lvmcowutil.deflate(self.sr.lvmCache, self.lvname, lvSizeBase)
                 self.utilisation = lvSizeBase
             util.fistpoint.activate("LVHDRT_clone_vdi_after_shrink_parent", self.sr.uuid)
 
-            snapVDI = self._createSnap(origUuid, lvSizeOrig, False)
+            snapVDI = self._createSnap(origUuid, snapVdiType, lvSizeOrig, False)
             util.fistpoint.activate("LVHDRT_clone_vdi_after_first_snap", self.sr.uuid)
             snapVDI2 = None
             if snapType == VDI.SNAPSHOT_DOUBLE:
-                snapVDI2 = self._createSnap(clonUuid, lvSizeClon, True)
+                snapVDI2 = self._createSnap(clonUuid, snapVdiType, lvSizeClon, True)
                 # If we have CBT enabled on the VDI,
                 # set CBT status for the new snapshot disk
                 if cbtlog:
@@ -1815,13 +1838,13 @@ class LVMVDI(VDI.VDI):
             util.fistpoint.activate("LVHDRT_clone_vdi_after_second_snap", self.sr.uuid)
 
             # note: it is important to mark the parent hidden only AFTER the
-            # new VHD children have been created, which are referencing it;
+            # new image children have been created, which are referencing it;
             # otherwise we would introduce a race with GC that could reclaim
             # the parent before we snapshot it
             if not VdiType.isCowImage(self.vdi_type):
                 self.sr.lvmCache.setHidden(self.lvname)
             else:
-                vhdutil.setHidden(self.path)
+                self.cowutil.setHidden(self.path)
             util.fistpoint.activate("LVHDRT_clone_vdi_after_parent_hidden", self.sr.uuid)
 
             # set the base copy to ReadOnly
@@ -1855,9 +1878,10 @@ class LVMVDI(VDI.VDI):
 
         return self._finishSnapshot(snapVDI, snapVDI2, hostRefs, cloneOp, snapType)
 
-    def _createSnap(self, snapUuid, snapSizeLV, isNew):
+    def _createSnap(self, snapUuid, snapVdiType, snapSizeLV, isNew):
         """Snapshot self and return the snapshot VDI object"""
-        snapLV = lvhdutil.LV_PREFIX[VdiType.VHD] + snapUuid
+
+        snapLV = LV_PREFIX[snapVdiType] + snapUuid
         snapPath = os.path.join(self.sr.path, snapLV)
         self.sr.lvmCache.create(snapLV, int(snapSizeLV))
         util.fistpoint.activate("LVHDRT_clone_vdi_after_lvcreate", self.sr.uuid)
@@ -1865,8 +1889,10 @@ class LVMVDI(VDI.VDI):
             RefCounter.set(snapUuid, 1, 0, NS_PREFIX_LVM + self.sr.uuid)
         self.sr.lvActivator.add(snapUuid, snapLV, False)
         parentRaw = (self.vdi_type == VdiType.RAW)
-        vhdutil.snapshot(snapPath, self.path, parentRaw, lvhdutil.MSIZE_MB)
-        snapParent = vhdutil.getParent(snapPath, lvhdutil.extractUuid)
+        self.cowutil.snapshot(
+            snapPath, self.path, parentRaw, max(self.size, self.cowutil.getDefaultPreallocationSizeVirt())
+        )
+        snapParent = self.cowutil.getParent(snapPath, LvmCowUtil.extractUuid)
 
         snapVDI = LVMVDI(self.sr, snapUuid)
         snapVDI.read_only = False
@@ -1879,7 +1905,7 @@ class LVMVDI(VDI.VDI):
                     "type", "vdi_type", "vhd-parent", "paused", "relinking", "activating"] and \
                     not key.startswith("host_"):
                 snapVDI.sm_config[key] = val
-        snapVDI.sm_config["vdi_type"] = VdiType.VHD
+        snapVDI.sm_config["vdi_type"] = snapVdiType
         snapVDI.sm_config["vhd-parent"] = snapParent
         snapVDI.lvname = snapLV
         return snapVDI
@@ -1911,7 +1937,7 @@ class LVMVDI(VDI.VDI):
             # for leaf nodes). The normal refcount of the child is not
             # transferred to to the base VDI because normal refcounts are
             # incremented and decremented individually, and not based on the
-            # VHD chain (i.e., the child's normal refcount will be decremented
+            # image chain (i.e., the child's normal refcount will be decremented
             # independently of its parent situation). Add 1 for this clone op.
             # Note that we do not need to do protect the refcount operations
             # below with per-VDI locking like we do in lvutil because at this
@@ -2010,14 +2036,19 @@ class LVMVDI(VDI.VDI):
             if not basePresent:
                 # a single-snapshot of an empty VDI will be a noop, resulting
                 # in no new VDIs, so return the existing one. The GC wouldn't
-                # normally try to single-snapshot an empty VHD of course, but
+                # normally try to single-snapshot an empty image of course, but
                 # if an external snapshot operation manages to sneak in right
                 # before a snapshot-coalesce phase, we would get here
                 snap = snapVDI
         return snap.get_params()
 
+    def _setType(self, vdiType: str) -> None:
+        self.vdi_type = vdiType
+        self.cowutil = getCowUtil(self.vdi_type)
+        self.lvmcowutil = LvmCowUtil(self.cowutil)
+
     def _initFromVDIInfo(self, vdiInfo):
-        self.vdi_type = vdiInfo.vdiType
+        self._setType(vdiInfo.vdiType)
         self.lvname = vdiInfo.lvName
         self.size = vdiInfo.sizeVirt
         self.utilisation = vdiInfo.sizeLV
@@ -2035,7 +2066,7 @@ class LVMVDI(VDI.VDI):
         self.loaded = True
 
     def _initFromLVInfo(self, lvInfo):
-        self.vdi_type = lvInfo.vdiType
+        self._setType(lvInfo.vdiType)
         self.lvname = lvInfo.name
         self.size = lvInfo.size
         self.utilisation = lvInfo.size
@@ -2051,20 +2082,22 @@ class LVMVDI(VDI.VDI):
         if not VdiType.isCowImage(self.vdi_type):
             self.loaded = True
 
-    def _initFromVHDInfo(self, vhdInfo):
-        self.size = vhdInfo.sizeVirt
-        self.parent = vhdInfo.parentUuid
-        self.hidden = vhdInfo.hidden
+    def _initFromImageInfo(self, imageInfo):
+        self.size = imageInfo.sizeVirt
+        self.parent = imageInfo.parentUuid
+        self.hidden = imageInfo.hidden
         self.loaded = True
 
     def _determineType(self):
-        """Determine whether this is a raw or a VHD VDI"""
+        """
+        Determine whether this is a RAW or a COW VDI.
+        """
         if "vdi_ref" in self.sr.srcmd.params:
             vdi_ref = self.sr.srcmd.params["vdi_ref"]
             sm_config = self.session.xenapi.VDI.get_sm_config(vdi_ref)
             if sm_config.get("vdi_type"):
-                self.vdi_type = sm_config["vdi_type"]
-                prefix = lvhdutil.LV_PREFIX[self.vdi_type]
+                self._setType(sm_config["vdi_type"])
+                prefix = LV_PREFIX[self.vdi_type]
                 self.lvname = "%s%s" % (prefix, self.uuid)
                 self.path = os.path.join(self.sr.path, self.lvname)
                 self.sm_config_override = sm_config
@@ -2073,15 +2106,15 @@ class LVMVDI(VDI.VDI):
         # LVM commands can be costly, so check the file directly first in case
         # the LV is active
         found = False
-        for t in lvhdutil.VDI_TYPES:
-            lvname = "%s%s" % (lvhdutil.LV_PREFIX[t], self.uuid)
+        for vdi_type, prefix in LV_PREFIX.items():
+            lvname = "%s%s" % (prefix, self.uuid)
             path = os.path.join(self.sr.path, lvname)
             if util.pathexists(path):
                 if found:
                     raise xs_errors.XenError('VDILoad',
                             opterr="multiple VDI's: uuid %s" % self.uuid)
                 found = True
-                self.vdi_type = t
+                self._setType(vdi_type)
                 self.lvname = lvname
                 self.path = path
         if found:
@@ -2092,21 +2125,23 @@ class LVMVDI(VDI.VDI):
             # when doing attach_from_config, the VG won't be there yet
             return False
 
-        lvs = lvhdutil.getLVInfo(self.sr.lvmCache)
+        lvs = LvmCowUtil.getVolumeInfo(self.sr.lvmCache)
         if lvs.get(self.uuid):
             self._initFromLVInfo(lvs[self.uuid])
             return True
         return False
 
     def _loadThis(self):
-        """Load VDI info for this VDI and activate the LV if it's VHD. We
-        don't do it in VDI.load() because not all VDI operations need it."""
+        """
+        Load VDI info for this VDI and activate the LV if it's COW. We
+        don't do it in VDI.load() because not all VDI operations need it.
+        """
         if self.loaded:
             if VdiType.isCowImage(self.vdi_type):
                 self.sr.lvActivator.activate(self.uuid, self.lvname, False)
             return
         try:
-            lvs = lvhdutil.getLVInfo(self.sr.lvmCache, self.lvname)
+            lvs = LvmCowUtil.getVolumeInfo(self.sr.lvmCache, self.lvname)
         except util.CommandException as e:
             raise xs_errors.XenError('VDIUnavailable',
                     opterr='%s (LV scan error)' % os.strerror(abs(e.code)))
@@ -2115,11 +2150,10 @@ class LVMVDI(VDI.VDI):
         self._initFromLVInfo(lvs[self.uuid])
         if VdiType.isCowImage(self.vdi_type):
             self.sr.lvActivator.activate(self.uuid, self.lvname, False)
-            vhdInfo = vhdutil.getVHDInfo(self.path, lvhdutil.extractUuid, False)
-            if not vhdInfo:
-                raise xs_errors.XenError('VDIUnavailable', \
-                        opterr='getVHDInfo failed')
-            self._initFromVHDInfo(vhdInfo)
+            imageInfo = self.cowutil.getInfo(self.path, LvmCowUtil.extractUuid, False)
+            if not imageInfo:
+                raise xs_errors.XenError('VDIUnavailable', opterr='getInfo failed')
+            self._initFromImageInfo(imageInfo)
         self.loaded = True
 
     def _chainSetActive(self, active, binary, persistent=False):
@@ -2131,8 +2165,7 @@ class LVMVDI(VDI.VDI):
 
         vdiList = {self.uuid: self.lvname}
         if VdiType.isCowImage(self.vdi_type):
-            vdiList = vhdutil.getParentChain(self.lvname,
-                    lvhdutil.extractUuid, self.sr.vgname)
+            vdiList = self.cowutil.getParentChain(self.lvname, LvmCowUtil.extractUuid, self.sr.vgname)
         for uuid, lvName in vdiList.items():
             binaryParam = binary
             if uuid != self.uuid:
@@ -2159,18 +2192,17 @@ class LVMVDI(VDI.VDI):
         if not VdiType.isCowImage(self.vdi_type):
             self.sr.lvmCache.setHidden(self.lvname)
         else:
-            vhdutil.setHidden(self.path)
+            self.cowutil.setHidden(self.path)
         self.hidden = 1
 
-    def _prepareThin(self, attach):
+    def _prepareThin(self, attach, vdiType):
         origUtilisation = self.sr.lvmCache.getSize(self.lvname)
         if self.sr.isMaster:
             # the master can prepare the VDI locally
             if attach:
-                lvhdutil.attachThin(self.sr.journaler, self.sr.uuid, self.uuid)
+                self.lvmcowutil.attachThin(self.sr.journaler, self.sr.uuid, self.uuid, self.vdi_type)
             else:
-                lvhdutil.detachThin(self.session, self.sr.lvmCache,
-                        self.sr.uuid, self.uuid)
+                self.lvmcowutil.detachThin(self.session, self.sr.lvmCache, self.sr.uuid, self.uuid, self.vdi_type)
         else:
             fn = "attach"
             if not attach:
@@ -2178,8 +2210,15 @@ class LVMVDI(VDI.VDI):
             pools = self.session.xenapi.pool.get_all()
             master = self.session.xenapi.pool.get_master(pools[0])
             rv = self.session.xenapi.host.call_plugin(
-                    master, self.sr.THIN_PLUGIN, fn,
-                    {"srUuid": self.sr.uuid, "vdiUuid": self.uuid})
+                master,
+                self.sr.THIN_PLUGIN,
+                fn,
+                {
+                    "srUuid": self.sr.uuid,
+                    "vdiUuid": self.uuid,
+                    "vdiType": vdiType
+                }
+            )
             util.SMlog("call-plugin returned: %s" % rv)
             if not rv:
                 raise Exception('plugin %s failed' % self.sr.THIN_PLUGIN)
diff --git a/drivers/LVMoFCoESR.py b/drivers/LVMoFCoESR.py
index 988b216c..0f136043 100755
--- a/drivers/LVMoFCoESR.py
+++ b/drivers/LVMoFCoESR.py
@@ -42,7 +42,7 @@ CONFIGURATION = [['SCSIid', 'The scsi_id of the destination LUN'],
 
 DRIVER_INFO = {
     'name': 'LVM over FCoE',
-    'description': 'SR plugin which represents disks as VHDs and QCOW2 on Logical \
+    'description': 'SR plugin which represents disks as VHDs on Logical \
     Volumes within a Volume Group created on a FCoE LUN',
     'vendor': 'Citrix Systems Inc',
     'copyright': '(C) 2015 Citrix Systems Inc',
diff --git a/drivers/LinstorSR.py b/drivers/LinstorSR.py
index 5a213482..dd6a5e74 100755
--- a/drivers/LinstorSR.py
+++ b/drivers/LinstorSR.py
@@ -14,13 +14,13 @@
 # You should have received a copy of the GNU General Public License
 # along with this program.  If not, see <https://www.gnu.org/licenses/>.
 
-from sm_typing import Optional, override
+from sm_typing import Any, Optional, override
 
 from constants import CBTLOG_TAG
 
 try:
+    from linstorcowutil import LinstorCowUtil
     from linstorjournaler import LinstorJournaler
-    from linstorvhdutil import LinstorVhdUtil
     from linstorvolumemanager import get_controller_uri
     from linstorvolumemanager import get_controller_node_name
     from linstorvolumemanager import LinstorVolumeManager
@@ -52,11 +52,11 @@ import time
 import traceback
 import util
 import VDI
-import vhdutil
 import xml.etree.ElementTree as xml_parser
 import xmlrpc.client
 import xs_errors
 
+from cowutil import CowUtil, getVdiTypeFromImageFormat
 from srmetadata import \
     NAME_LABEL_TAG, NAME_DESCRIPTION_TAG, IS_A_SNAPSHOT_TAG, SNAPSHOT_OF_TAG, \
     TYPE_TAG, VDI_TYPE_TAG, READ_ONLY_TAG, SNAPSHOT_TIME_TAG, \
@@ -79,13 +79,21 @@ USE_HTTP_NBD_SERVERS = True
 # Useful flag to trace calls using cProfile.
 TRACE_PERFS = False
 
-# Enable/Disable VHD key hash support.
+# Enable/Disable COW key hash support.
 USE_KEY_HASH = False
 
 # Special volumes.
 HA_VOLUME_NAME = PERSISTENT_PREFIX + 'ha-statefile'
 REDO_LOG_VOLUME_NAME = PERSISTENT_PREFIX + 'redo-log'
 
+# TODO: Simplify with File SR and LVM SR
+# Warning: Not the same values than VdiType.*.
+# These values represents the types given on the command line.
+CREATE_PARAM_TYPES = {
+    "raw": VdiType.RAW,
+    "vhd": VdiType.VHD
+}
+
 # ==============================================================================
 
 # TODO: Supports 'VDI_INTRODUCE', 'VDI_RESET_ON_BOOT/2', 'SR_TRIM',
@@ -141,32 +149,31 @@ OPS_EXCLUSIVE = [
 
 def attach_thin(session, journaler, linstor, sr_uuid, vdi_uuid):
     volume_metadata = linstor.get_volume_metadata(vdi_uuid)
-    image_type = volume_metadata.get(VDI_TYPE_TAG)
-    if not VdiType.isCowImage(image_type):
+    vdi_type = volume_metadata.get(VDI_TYPE_TAG)
+    if not VdiType.isCowImage(vdi_type):
         return
 
     device_path = linstor.get_device_path(vdi_uuid)
 
-    # If the virtual VHD size is lower than the LINSTOR volume size,
+    linstorcowutil = LinstorCowUtil(session, linstor, vdi_type)
+
+    # If the virtual COW size is lower than the LINSTOR volume size,
     # there is nothing to do.
-    vhd_size = LinstorVhdUtil.compute_volume_size(
-        LinstorVhdUtil(session, linstor).get_size_virt(vdi_uuid),
-        image_type
+    cow_size = linstorcowutil.compute_volume_size(
+        linstorcowutil.get_size_virt(vdi_uuid)
     )
 
     volume_info = linstor.get_volume_info(vdi_uuid)
     volume_size = volume_info.virtual_size
 
-    if vhd_size > volume_size:
-        LinstorVhdUtil(session, linstor).inflate(
-            journaler, vdi_uuid, device_path, vhd_size, volume_size
-        )
+    if cow_size > volume_size:
+        linstorcowutil.inflate(journaler, vdi_uuid, device_path, cow_size, volume_size)
 
 
 def detach_thin_impl(session, linstor, sr_uuid, vdi_uuid):
     volume_metadata = linstor.get_volume_metadata(vdi_uuid)
-    image_type = volume_metadata.get(VDI_TYPE_TAG)
-    if not VdiType.isCowImage(image_type):
+    vdi_type = volume_metadata.get(VDI_TYPE_TAG)
+    if not VdiType.isCowImage(vdi_type):
         return
 
     def check_vbd_count():
@@ -191,14 +198,14 @@ def detach_thin_impl(session, linstor, sr_uuid, vdi_uuid):
     util.retry(check_vbd_count, maxretry=10, period=1)
 
     device_path = linstor.get_device_path(vdi_uuid)
-    vhdutil_inst = LinstorVhdUtil(session, linstor)
+    linstorcowutil = LinstorCowUtil(session, linstor, vdi_type)
     new_volume_size = LinstorVolumeManager.round_up_volume_size(
-        vhdutil_inst.get_size_phys(vdi_uuid)
+        linstorcowutil.get_size_phys(vdi_uuid)
     )
 
     volume_info = linstor.get_volume_info(vdi_uuid)
     old_volume_size = volume_info.virtual_size
-    vhdutil_inst.deflate(device_path, new_volume_size, old_volume_size)
+    linstorcowutil.deflate(device_path, new_volume_size, old_volume_size)
 
 
 def detach_thin(session, linstor, sr_uuid, vdi_uuid):
@@ -301,11 +308,17 @@ class LinstorSR(SR.SR):
     # SR methods.
     # --------------------------------------------------------------------------
 
+    _linstor: Optional[LinstorVolumeManager] = None
+
     @override
     @staticmethod
     def handles(type) -> bool:
         return type == LinstorSR.DRIVER_TYPE
 
+    def __init__(self, srcmd, sr_uuid):
+        SR.SR.__init__(self, srcmd, sr_uuid)
+        self._init_preferred_image_formats()
+
     @override
     def load(self, sr_uuid) -> None:
         if not LINSTOR_AVAILABLE:
@@ -363,6 +376,17 @@ class LinstorSR(SR.SR):
         self._linstor = None  # Ensure that LINSTOR attribute exists.
         self._journaler = None
 
+        # Used to handle reconnect calls on LINSTOR object attached to the SR.
+        class LinstorProxy:
+            def __init__(self, sr: LinstorSR) -> None:
+                self.sr = sr
+
+            def __getattr__(self, attr: str) -> Any:
+                assert self.sr, "Cannot use `LinstorProxy` without valid `LinstorVolumeManager` instance"
+                return getattr(self.sr._linstor, attr)
+
+        self._linstor_proxy = LinstorProxy(self)
+
         self._group_name = self.dconf['group-name']
 
         self._vdi_shared_time = 0
@@ -401,9 +425,6 @@ class LinstorSR(SR.SR):
                             logger=util.SMlog,
                             attempt_count=attempt_count
                         )
-                        # Only required if we are attaching from config using a non-special VDI.
-                        # I.e. not an HA volume.
-                        self._vhdutil = LinstorVhdUtil(self.session, self._linstor)
 
                     controller_uri = get_controller_uri()
                     if controller_uri:
@@ -432,10 +453,6 @@ class LinstorSR(SR.SR):
                         controller_uri, self._group_name, logger=util.SMlog
                     )
 
-                if self.srcmd.cmd is None:
-                    # Only useful on on-slave plugin (is_open).
-                    self._vhdutil = LinstorVhdUtil(self.session, self._linstor)
-
                 return wrapped_method(self, *args, **kwargs)
 
             if not self.is_master():
@@ -471,7 +488,7 @@ class LinstorSR(SR.SR):
                 if hosts:
                     util.SMlog('Failed to join node(s): {}'.format(hosts))
 
-                # Ensure we use a non-locked volume when vhdutil is called.
+                # Ensure we use a non-locked volume when cowutil is called.
                 if (
                     self.is_master() and self.cmd.startswith('vdi_') and
                     self.cmd != 'vdi_create'
@@ -618,7 +635,6 @@ class LinstorSR(SR.SR):
                 auto_quorum=self._monitor_db_quorum,
                 logger=util.SMlog
             )
-            self._vhdutil = LinstorVhdUtil(self.session, self._linstor)
 
             util.SMlog(
                 "Finishing SR creation, enable drbd-reactor on all hosts..."
@@ -1141,10 +1157,10 @@ class LinstorSR(SR.SR):
                 if not VdiType.isCowImage(vdi_type):
                     managed = not volume_metadata.get(HIDDEN_TAG)
                 else:
-                    vhd_info = self._vhdutil.get_vhd_info(vdi_uuid)
-                    managed = not vhd_info.hidden
-                    if vhd_info.parentUuid:
-                        sm_config['vhd-parent'] = vhd_info.parentUuid
+                    image_info = LinstorCowUtil(self.session, self._linstor, vdi_type).get_info(vdi_uuid)
+                    managed = not image_info.hidden
+                    if image_info.parentUuid:
+                        sm_config['vhd-parent'] = image_info.parentUuid
 
                 util.SMlog(
                     'Introducing VDI {} '.format(vdi_uuid) +
@@ -1194,7 +1210,7 @@ class LinstorSR(SR.SR):
             self.vdis[vdi_uuid] = vdi
 
             if USE_KEY_HASH and VdiType.isCowImage(vdi.vdi_type):
-                vdi.sm_config_override['key_hash'] = self._vhdutil.get_key_hash(vdi_uuid)
+                vdi.sm_config_override['key_hash'] = vdi.linstorcowutil.get_key_hash(vdi_uuid)
 
             # 4.c. Update CBT status of disks either just added
             # or already in XAPI.
@@ -1278,13 +1294,14 @@ class LinstorSR(SR.SR):
             if not VdiType.isCowImage(vdi_type):
                 return (device_path, None)
 
-            # Otherwise it's a VHD and a parent can exist.
-            if not self._vhdutil.check(vdi_uuid):
+            # Otherwise it's a COW and a parent can exist.
+            linstorcowutil = LinstorCowUtil(self.session, self._linstor, vdi_type)
+            if linstorcowutil.check(vdi_uuid) != CowUtil.CheckResult.Success:
                 return (None, None)
 
-            vhd_info = self._vhdutil.get_vhd_info(vdi_uuid)
-            if vhd_info:
-                return (device_path, vhd_info.parentUuid)
+            image_info = linstorcowutil.get_info(vdi_uuid)
+            if image_info:
+                return (device_path, image_info.parentUuid)
         except Exception as e:
             util.SMlog(
                 'Failed to get VDI path and parent, ignoring: {}'
@@ -1330,7 +1347,7 @@ class LinstorSR(SR.SR):
 
         current_size = volume_info.virtual_size
         assert current_size > 0
-        self._vhdutil.force_deflate(vdi.path, old_size, current_size, zeroize=True)
+        vdi.linstorcowutil.force_deflate(vdi.path, old_size, current_size, zeroize=True)
 
     def _handle_interrupted_clone(
         self, vdi_uuid, clone_info, force_undo=False
@@ -1394,12 +1411,14 @@ class LinstorSR(SR.SR):
             util.SMlog('*** INTERRUPTED CLONE OP: rollback fail')
             return
 
+        linstorcowutil = LinstorCowUtil(self.session, self._linstor, base_type)
+
         # Un-hide the parent.
         self._linstor.update_volume_metadata(base_uuid, {READ_ONLY_TAG: False})
         if VdiType.isCowImage(base_type):
-            vhd_info = self._vhdutil.get_vhd_info(base_uuid, False)
-            if vhd_info.hidden:
-                self._vhdutil.set_hidden(base_path, False)
+            image_info = linstorcowutil.get_info(base_uuid, False)
+            if image_info.hidden:
+                linstorcowutil.set_hidden(base_path, False)
         elif base_metadata.get(HIDDEN_TAG):
             self._linstor.update_volume_metadata(
                 base_uuid, {HIDDEN_TAG: False}
@@ -1441,8 +1460,9 @@ class LinstorSR(SR.SR):
         # Inflate to the right size.
         if VdiType.isCowImage(base_type):
             vdi = self.vdi(vdi_uuid)
-            volume_size = LinstorVhdUtil.compute_volume_size(vdi.size, vdi.vdi_type)
-            self._vhdutil.inflate(
+            linstorcowutil = LinstorCowUtil(self.session, self._linstor, vdi.vdi_type)
+            volume_size = linstorcowutil.compute_volume_size(vdi.size)
+            linstorcowutil.inflate(
                 self._journaler, vdi_uuid, vdi.path,
                 volume_size, vdi.capacity
             )
@@ -1510,7 +1530,6 @@ class LinstorSR(SR.SR):
             ),
             logger=util.SMlog
         )
-        self._vhdutil = LinstorVhdUtil(self.session, self._linstor)
 
     def _ensure_space_available(self, amount_needed):
         space_available = self._linstor.max_volume_size_allowed
@@ -1532,16 +1551,6 @@ class LinstorSR(SR.SR):
 
 
 class LinstorVDI(VDI.VDI):
-    # Warning: Not the same values than VdiType.*.
-    # These values represents the types given on the command line.
-    TYPE_RAW = 'raw'
-    TYPE_VHD = 'vhd'
-
-    # Metadata size given to the "S" param of vhd-util create.
-    # "-S size (MB) for metadata preallocation".
-    # Increase the performance when resize is called.
-    MAX_METADATA_VIRT_SIZE = 2 * 1024 * 1024
-
     # --------------------------------------------------------------------------
     # VDI methods.
     # --------------------------------------------------------------------------
@@ -1571,7 +1580,7 @@ class LinstorVDI(VDI.VDI):
                 self.sr.srcmd.cmd == 'vdi_attach_from_config' or
                 self.sr.srcmd.cmd == 'vdi_detach_from_config'
             ):
-                self.vdi_type = VdiType.RAW
+                self._set_type(VdiType.RAW)
                 self.path = self.sr.srcmd.params['vdi_path']
             else:
                 self._determine_type_and_path()
@@ -1589,27 +1598,23 @@ class LinstorVDI(VDI.VDI):
 
             # 2. Or maybe a creation.
             if self.sr.srcmd.cmd == 'vdi_create':
-                # Set type attribute of VDI parent class.
-                # We use VHD by default.
-                self.vdi_type = VdiType.VHD
                 self._key_hash = None  # Only used in create.
 
                 self._exists = False
                 vdi_sm_config = self.sr.srcmd.params.get('vdi_sm_config')
                 if vdi_sm_config is not None:
                     type = vdi_sm_config.get('type')
-                    if type is not None:
-                        if type == self.TYPE_RAW:
-                            self.vdi_type = VdiType.RAW
-                        elif type == self.TYPE_VHD:
-                            self.vdi_type = VdiType.VHD
-                        else:
-                            raise xs_errors.XenError(
-                                'VDICreate',
-                                opterr='Invalid VDI type {}'.format(type)
-                            )
-                    if VdiType.isCowImage(self.vdi_type):
-                        self._key_hash = vdi_sm_config.get('key_hash')
+
+                    try:
+                        self._set_type(CREATE_PARAM_TYPES[type])
+                    except:
+                        raise xs_errors.XenError('VDICreate', opterr='bad type')
+
+                if not self.vdi_type:
+                    self._set_type(getVdiTypeFromImageFormat(self.sr.preferred_image_formats[0]))
+
+                if VdiType.isCowImage(self.vdi_type):
+                    self._key_hash = vdi_sm_config.get('key_hash')
 
                 # For the moment we don't have a path.
                 self._update_device_name(None)
@@ -1634,10 +1639,10 @@ class LinstorVDI(VDI.VDI):
         assert self.vdi_type
 
         # 2. Compute size and check space available.
-        size = vhdutil.validate_and_round_vhd_size(int(size))
-        volume_size = LinstorVhdUtil.compute_volume_size(size, self.vdi_type)
+        size = self.linstorcowutil.cowutil.validateAndRoundImageSize(int(size))
+        volume_size = self.linstorcowutil.compute_volume_size(size)
         util.SMlog(
-            'LinstorVDI.create: type={}, vhd-size={}, volume-size={}'
+            'LinstorVDI.create: type={}, cow-size={}, volume-size={}'
             .format(self.vdi_type, size, volume_size)
         )
         self.sr._ensure_space_available(volume_size)
@@ -1668,15 +1673,15 @@ class LinstorVDI(VDI.VDI):
             if not VdiType.isCowImage(self.vdi_type):
                 self.size = volume_info.virtual_size
             else:
-                self.sr._vhdutil.create(
-                    self.path, size, False, self.MAX_METADATA_VIRT_SIZE
+                self.linstorcowutil.create(
+                    self.path, size, False, self.linstorcowutil.cowutil.getDefaultPreallocationSizeVirt()
                 )
-                self.size = self.sr._vhdutil.get_size_virt(self.uuid)
+                self.size = self.linstorcowutil.get_size_virt(self.uuid)
 
             if self._key_hash:
-                self.sr._vhdutil.set_key(self.path, self._key_hash)
+                self.linstorcowutil.set_key(self.path, self._key_hash)
 
-            # Because vhdutil commands modify the volume data,
+            # Because cowutil commands modify the volume data,
             # we must retrieve a new time the utilization size.
             volume_info = self._linstor.get_volume_info(self.uuid)
 
@@ -1793,13 +1798,13 @@ class LinstorVDI(VDI.VDI):
 
         if not attach_from_config or self.sr.is_master():
             # We need to inflate the volume if we don't have enough place
-            # to mount the VHD image. I.e. the volume capacity must be greater
-            # than the VHD size + bitmap size.
+            # to mount the COW image. I.e. the volume capacity must be greater
+            # than the COW size + bitmap size.
             need_inflate = True
             if (
                 not VdiType.isCowImage(self.vdi_type) or
                 not writable or
-                self.capacity >= LinstorVhdUtil.compute_volume_size(self.size, self.vdi_type)
+                self.capacity >= self.linstorcowutil.compute_volume_size(self.size)
             ):
                 need_inflate = False
 
@@ -1825,7 +1830,7 @@ class LinstorVDI(VDI.VDI):
             return self._attach_using_http_nbd()
 
         # Ensure we have a path...
-        self.sr._vhdutil.create_chain_paths(self.uuid, readonly=not writable)
+        self.linstorcowutil.create_chain_paths(self.uuid, readonly=not writable)
 
         self.attached = True
         return VDI.VDI.attach(self, self.sr.uuid, self.uuid)
@@ -1842,9 +1847,9 @@ class LinstorVDI(VDI.VDI):
         if not VdiType.isCowImage(self.vdi_type):
             return
 
-        # The VDI is already deflated if the VHD image size + metadata is
+        # The VDI is already deflated if the COW image size + metadata is
         # equal to the LINSTOR volume size.
-        volume_size = LinstorVhdUtil.compute_volume_size(self.size, self.vdi_type)
+        volume_size = self.linstorcowutil.compute_volume_size(self.size)
         already_deflated = self.capacity <= volume_size
 
         if already_deflated:
@@ -1880,7 +1885,7 @@ class LinstorVDI(VDI.VDI):
         while vdi_uuid:
             try:
                 path = self._linstor.build_device_path(self._linstor.get_volume_name(vdi_uuid))
-                parent_vdi_uuid = self.sr._vhdutil.get_vhd_info(vdi_uuid).parentUuid
+                parent_vdi_uuid = self.sr.linstorcowutil.get_info(vdi_uuid).parentUuid
             except Exception:
                 break
 
@@ -1905,11 +1910,11 @@ class LinstorVDI(VDI.VDI):
         if self.hidden:
             raise xs_errors.XenError('VDIUnavailable', opterr='hidden VDI')
 
-        # Compute the virtual VHD and DRBD volume size.
-        size = vhdutil.validate_and_round_vhd_size(int(size))
-        volume_size = LinstorVhdUtil.compute_volume_size(size, self.vdi_type)
+        # Compute the virtual COW and DRBD volume size.
+        size = self.linstorcowutil.cowutil.validateAndRoundImageSize(int(size))
+        volume_size = self.linstorcowutil.compute_volume_size(size)
         util.SMlog(
-            'LinstorVDI.resize: type={}, vhd-size={}, volume-size={}'
+            'LinstorVDI.resize: type={}, cow-size={}, volume-size={}'
             .format(self.vdi_type, size, volume_size)
         )
 
@@ -1932,7 +1937,7 @@ class LinstorVDI(VDI.VDI):
                 # VDI is currently deflated, so keep it deflated.
                 new_volume_size = old_volume_size
             else:
-                new_volume_size = LinstorVhdUtil.compute_volume_size(size, self.vdi_type)
+                new_volume_size = self.linstorcowutil.compute_volume_size(size)
         assert new_volume_size >= old_volume_size
 
         space_needed = new_volume_size - old_volume_size
@@ -1943,11 +1948,11 @@ class LinstorVDI(VDI.VDI):
             self._linstor.resize(self.uuid, new_volume_size)
         else:
             if new_volume_size != old_volume_size:
-                self.sr._vhdutil.inflate(
+                self.sr.linstorcowutil.inflate(
                     self.sr._journaler, self.uuid, self.path,
                     new_volume_size, old_volume_size
                 )
-            self.sr._vhdutil.set_size_virt_fast(self.path, size)
+            self.sr.linstorcowutil.set_size_virt_fast(self.path, size)
 
         # Reload size attributes.
         self._load_this()
@@ -1981,8 +1986,8 @@ class LinstorVDI(VDI.VDI):
         if not blktap2.VDI.tap_pause(self.session, self.sr.uuid, self.uuid):
             raise util.SMException('Failed to pause VDI {}'.format(self.uuid))
         try:
-            self.sr._vhdutil.set_parent(self.path, parent_path, False)
-            self.sr._vhdutil.set_hidden(parent_path)
+            self.sr.linstorcowutil.set_parent(self.path, parent_path, False)
+            self.sr.linstorcowutil.set_hidden(parent_path)
             self.sr.session.xenapi.VDI.set_managed(
                 self.sr.srcmd.params['args'][0], False
             )
@@ -2071,13 +2076,13 @@ class LinstorVDI(VDI.VDI):
         if not VdiType.isCowImage(self.vdi_type):
             raise xs_errors.XenError('Unimplemented')
 
-        if not self.sr._vhdutil.has_parent(self.uuid):
+        if not self.linstorcowutil.has_parent(self.uuid):
             raise util.SMException(
                 'ERROR: VDI {} has no parent, will not reset contents'
                 .format(self.uuid)
             )
 
-        self.sr._vhdutil.kill_data(self.path)
+        self.linstorcowutil.kill_data(self.path)
 
     def _load_this(self):
         volume_metadata = None
@@ -2106,10 +2111,10 @@ class LinstorVDI(VDI.VDI):
             self.size = volume_info.virtual_size
             self.parent = ''
         else:
-            vhd_info = self.sr._vhdutil.get_vhd_info(self.uuid)
-            self.hidden = vhd_info.hidden
-            self.size = vhd_info.sizeVirt
-            self.parent = vhd_info.parentUuid
+            image_info = self.sr.linstorcowutil.get_info(self.uuid)
+            self.hidden = image_info.hidden
+            self.size = image_info.sizeVirt
+            self.parent = image_info.parentUuid
 
         if self.hidden:
             self.managed = False
@@ -2125,7 +2130,7 @@ class LinstorVDI(VDI.VDI):
             return
 
         if VdiType.isCowImage(self.vdi_type):
-            self.sr._vhdutil.set_hidden(self.path, hidden)
+            self.linstorcowutil.set_hidden(self.path, hidden)
         else:
             self._linstor.update_volume_metadata(self.uuid, {
                 HIDDEN_TAG: hidden
@@ -2205,9 +2210,13 @@ class LinstorVDI(VDI.VDI):
     # Generic helpers.
     # --------------------------------------------------------------------------
 
+    def _set_type(self, vdi_type: str) -> None:
+        self.vdi_type = vdi_type
+        self.linstorcowutil = LinstorCowUtil(self.session, self.sr._linstor_proxy, self.vdi_type)
+
     def _determine_type_and_path(self):
         """
-        Determine whether this is a RAW or a VHD VDI.
+        Determine whether this is a RAW or a COW VDI.
         """
 
         # 1. Check vdi_ref and vdi_type in config.
@@ -2218,7 +2227,7 @@ class LinstorVDI(VDI.VDI):
                 vdi_type = sm_config.get('vdi_type')
                 if vdi_type:
                     # Update parent fields.
-                    self.vdi_type = vdi_type
+                    self._set_type(vdi_type)
                     self.sm_config_override = sm_config
                     self._update_device_name(
                         self._linstor.get_volume_name(self.uuid)
@@ -2230,7 +2239,7 @@ class LinstorVDI(VDI.VDI):
         # 2. Otherwise use the LINSTOR volume manager directly.
         # It's probably a new VDI created via snapshot.
         volume_metadata = self._linstor.get_volume_metadata(self.uuid)
-        self.vdi_type = volume_metadata.get(VDI_TYPE_TAG)
+        self._set_type(volume_metadata.get(VDI_TYPE_TAG))
         if not self.vdi_type:
             raise xs_errors.XenError(
                 'VDIUnavailable',
@@ -2247,7 +2256,7 @@ class LinstorVDI(VDI.VDI):
         else:
             self.path = None
 
-    def _create_snapshot(self, snap_uuid, snap_of_uuid=None):
+    def _create_snapshot(self, snap_vdi_type, snap_uuid, snap_of_uuid=None):
         """
         Snapshot self and return the snapshot VDI object.
         """
@@ -2259,12 +2268,12 @@ class LinstorVDI(VDI.VDI):
 
         # 2. Write the snapshot content.
         is_raw = (self.vdi_type == VdiType.RAW)
-        self.sr._vhdutil.snapshot(
-            snap_path, self.path, is_raw, self.MAX_METADATA_VIRT_SIZE
+        self.linstorcowutil.snapshot(
+            snap_path, self.path, is_raw, max(self.size, self.linstorcowutil.cowutil.getDefaultPreallocationSizeVirt())
         )
 
         # 3. Get snapshot parent.
-        snap_parent = self.sr._vhdutil.get_parent(snap_uuid)
+        snap_parent = self.linstorcowutil.get_parent(snap_uuid)
 
         # 4. Update metadata.
         util.SMlog('Set VDI {} metadata of snapshot'.format(snap_uuid))
@@ -2275,7 +2284,7 @@ class LinstorVDI(VDI.VDI):
             SNAPSHOT_OF_TAG: snap_of_uuid,
             SNAPSHOT_TIME_TAG: '',
             TYPE_TAG: self.ty,
-            VDI_TYPE_TAG: VdiType.VHD,
+            VDI_TYPE_TAG: snap_vdi_type,
             READ_ONLY_TAG: False,
             METADATA_OF_POOL_TAG: ''
         }
@@ -2288,7 +2297,7 @@ class LinstorVDI(VDI.VDI):
 
         volume_info = self._linstor.get_volume_info(snap_uuid)
 
-        snap_vdi.size = self.sr._vhdutil.get_size_virt(snap_uuid)
+        snap_vdi.size = self.linstorcowutil.get_size_virt(snap_uuid)
         snap_vdi.utilisation = volume_info.allocated_size
 
         # 6. Update sm config.
@@ -2352,17 +2361,19 @@ class LinstorVDI(VDI.VDI):
         if self.hidden:
             raise xs_errors.XenError('VDIClone', opterr='hidden VDI')
 
-        depth = self.sr._vhdutil.get_depth(self.uuid)
+        snap_vdi_type = self.sr._get_snap_vdi_type(self.vdi_type, self.size)
+
+        depth = self.linstorcowutil.get_depth(self.uuid)
         if depth == -1:
             raise xs_errors.XenError(
                 'VDIUnavailable',
-                opterr='failed to get VHD depth'
+                opterr='failed to get COW depth'
             )
-        elif depth >= vhdutil.MAX_CHAIN_SIZE:
+        elif depth >= self.linstorcowutil.cowutil.getMaxChainLength():
             raise xs_errors.XenError('SnapshotChainTooLong')
 
         # Ensure we have a valid path if we don't have a local diskful.
-        self.sr._vhdutil.create_chain_paths(self.uuid, readonly=True)
+        self.linstorcowutil.create_chain_paths(self.uuid, readonly=True)
 
         volume_path = self.path
         if not util.pathexists(volume_path):
@@ -2395,11 +2406,11 @@ class LinstorVDI(VDI.VDI):
             self.managed = False
 
             # 4. Create snapshots (new active and snap).
-            active_vdi = self._create_snapshot(active_uuid)
+            active_vdi = self._create_snapshot(snap_vdi_type, active_uuid)
 
             snap_vdi = None
             if snap_type == VDI.SNAPSHOT_DOUBLE:
-                snap_vdi = self._create_snapshot(snap_uuid, active_uuid)
+                snap_vdi = self._create_snapshot(snap_vdi_type, snap_uuid, active_uuid)
 
             self.label = 'base copy'
             self.description = ''
diff --git a/drivers/MooseFSSR.py b/drivers/MooseFSSR.py
index f4703ddb..ac7f320b 100755
--- a/drivers/MooseFSSR.py
+++ b/drivers/MooseFSSR.py
@@ -38,7 +38,6 @@ import VDI
 import cleanup
 import lock
 import util
-import vhdutil
 import xs_errors
 
 CAPABILITIES = ["SR_PROBE", "SR_UPDATE",
diff --git a/drivers/NFSSR.py b/drivers/NFSSR.py
index 54687f6c..c6f42455 100755
--- a/drivers/NFSSR.py
+++ b/drivers/NFSSR.py
@@ -33,7 +33,6 @@ import xmlrpc.client
 import xs_errors
 import lock
 import nfs
-import vhdutil
 import cleanup
 
 CAPABILITIES = ["SR_PROBE", "SR_UPDATE", "SR_CACHING",
diff --git a/drivers/SMBSR.py b/drivers/SMBSR.py
index 2183dfcb..2318de48 100755
--- a/drivers/SMBSR.py
+++ b/drivers/SMBSR.py
@@ -29,7 +29,6 @@ import os
 import xmlrpc.client
 import xs_errors
 import lock
-import vhdutil
 import cleanup
 import cifutils
 
diff --git a/drivers/SR.py b/drivers/SR.py
index fb2798ea..3a2bbb4f 100755
--- a/drivers/SR.py
+++ b/drivers/SR.py
@@ -28,14 +28,17 @@ import copy
 import os
 import traceback
 
+from cowutil import ImageFormat, getCowUtilFromImageFormat, getVdiTypeFromImageFormat, parseImageFormats
+from vditype import VdiType
+
 MOUNT_BASE = '/var/run/sr-mount'
-DEFAULT_TAP = 'vhd'
-TAPDISK_UTIL = '/usr/sbin/td-util'
+DEFAULT_TAP = "vhd"
 MASTER_LVM_CONF = '/etc/lvm/master'
 
 # LUN per VDI key for XenCenter
 LUNPERVDI = "LUNperVDI"
 
+DEFAULT_IMAGE_FORMATS = [ImageFormat.VHD]
 
 
 
@@ -518,6 +521,20 @@ class SR(object):
 
         return missing_keys
 
+    def _init_preferred_image_formats(self) -> None:
+        self.preferred_image_formats = parseImageFormats(
+            self.dconf and self.dconf.get('preferred-image-formats'),
+            DEFAULT_IMAGE_FORMATS
+        )
+
+    def _get_snap_vdi_type(self, vdi_type: str, size: int) -> str:
+        if VdiType.isCowImage(vdi_type):
+            return vdi_type
+        if vdi_type == VdiType.RAW:
+            for image_format in self.preferred_image_formats:
+                if getCowUtilFromImageFormat(image_format).canSnapshotRaw(size):
+                    return getVdiTypeFromImageFormat(image_format)
+        raise xs_errors.XenError('VDISnapshot', opterr=f"cannot snap from `{vdi_type}`")
 
 class ScanRecord:
     def __init__(self, sr):
diff --git a/drivers/VDI.py b/drivers/VDI.py
index 21f51154..b100aa52 100755
--- a/drivers/VDI.py
+++ b/drivers/VDI.py
@@ -23,7 +23,6 @@ import SR
 import xmlrpc.client
 import xs_errors
 import util
-import vhdutil
 import cbtutil
 import os
 import base64
@@ -622,7 +621,7 @@ class VDI(object):
     def data_destroy(self, sr_uuid, vdi_uuid):
         """Delete the data associated with a CBT enabled snapshot
 
-        Can only be called for a snapshot VDI on a VHD chain that has
+        Can only be called for a snapshot VDI on a COW chain that has
         had CBT enabled on it at some point. The latter is enforced
         by upper layers
         """
diff --git a/drivers/XFSSR.py b/drivers/XFSSR.py
index 1f3eb791..8d54f6cc 100755
--- a/drivers/XFSSR.py
+++ b/drivers/XFSSR.py
@@ -32,7 +32,6 @@ import scsiutil
 import lock
 import os
 import xs_errors
-import vhdutil
 from constants import EXT_PREFIX
 
 CAPABILITIES = ["SR_PROBE", "SR_UPDATE", "SR_SUPPORTS_LOCAL_CACHING", \
diff --git a/drivers/blktap2.py b/drivers/blktap2.py
index 68cad566..3accedb3 100755
--- a/drivers/blktap2.py
+++ b/drivers/blktap2.py
@@ -48,11 +48,11 @@ from vditype import VdiType
 import nfs
 
 import resetvdis
-import vhdutil
-import lvhdutil
 
 import VDI as sm
 
+from cowutil import getCowUtil
+
 # For RRDD Plugin Registration
 from xmlrpc.client import ServerProxy, Transport
 from socket import socket, AF_UNIX, SOCK_STREAM
@@ -1114,7 +1114,7 @@ class VDI(object):
 
     VDI_PLUG_TYPE = {'phy': 'phy',  # for NETAPP
                       'raw': 'phy',
-                      'aio': 'tap',  # for LVHD raw nodes
+                      'aio': 'tap',  # for LVM raw nodes
                       'iso': 'tap',  # for ISOSR
                       'file': 'tap',
                       'vhd': 'tap'}
@@ -1934,8 +1934,11 @@ class VDI(object):
         from lock import Lock
         from FileSR import FileVDI
 
-        parent_uuid = vhdutil.getParent(self.target.vdi.path,
-                FileVDI.extractUuid)
+        vdi_type = self.target.get_vdi_type()
+        tap_type = VDI._tap_type(vdi_type)
+        cowutil = getCowUtil(vdi_type)
+
+        parent_uuid = cowutil.getParent(self.target.vdi.path, FileVDI.extractUuid)
         if not parent_uuid:
             util.SMlog("ERROR: VDI %s has no parent, not enabling" % \
                     self.target.vdi.uuid)
@@ -1963,14 +1966,14 @@ class VDI(object):
                     read_cache_path)
         else:
             try:
-                vhdutil.snapshot(read_cache_path, shared_target.path, False)
+                cowutil.snapshot(read_cache_path, shared_target.path, False)
             except util.CommandException as e:
                 util.SMlog("Error creating parent cache: %s" % e)
                 self.alert_no_cache(session, vdi_uuid, local_sr_uuid, e.code)
                 return None
 
         # local write node
-        leaf_size = vhdutil.getSizeVirt(self.target.vdi.path)
+        leaf_size = cowutil.getSizeVirt(self.target.vdi.path)
         local_leaf_path = "%s/%s.vhdcache" % \
                 (local_sr.path, self.target.vdi.uuid)
         if util.pathexists(local_leaf_path):
@@ -1978,20 +1981,18 @@ class VDI(object):
                     local_leaf_path)
             os.unlink(local_leaf_path)
         try:
-            vhdutil.snapshot(local_leaf_path, read_cache_path, False,
-                    msize=leaf_size // 1024 // 1024, checkEmpty=False)
+            cowutil.snapshot(local_leaf_path, read_cache_path, False,
+                    msize=leaf_size, checkEmpty=False)
         except util.CommandException as e:
             util.SMlog("Error creating leaf cache: %s" % e)
             self.alert_no_cache(session, vdi_uuid, local_sr_uuid, e.code)
             return None
 
-        local_leaf_size = vhdutil.getSizeVirt(local_leaf_path)
+        local_leaf_size = cowutil.getSizeVirt(local_leaf_path)
         if leaf_size > local_leaf_size:
             util.SMlog("Leaf size %d > local leaf cache size %d, resizing" %
                     (leaf_size, local_leaf_size))
-            vhdutil.setSizeVirtFast(local_leaf_path, leaf_size)
-
-        vdi_type = self.target.get_vdi_type()
+            cowutil.setSizeVirtFast(local_leaf_path, leaf_size)
 
         prt_tapdisk = Tapdisk.find_by_path(read_cache_path)
         if not prt_tapdisk:
@@ -2004,15 +2005,12 @@ class VDI(object):
                 blktap.set_pool_name("lcache-parent-pool-%s" % blktap.minor)
                 # no need to change pool_size since each parent tapdisk is in
                 # its own pool
-                prt_tapdisk = \
-                    Tapdisk.launch_on_tap(blktap, read_cache_path,
-                            'vhd', parent_options)
+                prt_tapdisk = Tapdisk.launch_on_tap(blktap, read_cache_path, tap_type, parent_options)
             except:
                 blktap.free()
                 raise
 
-        secondary = "%s:%s" % (self.target.get_vdi_type(),
-                self.PhyLink.from_uuid(sr_uuid, vdi_uuid).readlink())
+        secondary = "%s:%s" % (vdi_type, self.PhyLink.from_uuid(sr_uuid, vdi_uuid).readlink())
 
         util.SMlog("Parent tapdisk: %s" % prt_tapdisk)
         leaf_tapdisk = Tapdisk.find_by_path(local_leaf_path)
@@ -2025,9 +2023,7 @@ class VDI(object):
             child_options["secondary"] = secondary
             child_options["standby"] = scratch_mode
             try:
-                leaf_tapdisk = \
-                    Tapdisk.launch_on_tap(blktap, local_leaf_path,
-                            'vhd', child_options)
+                leaf_tapdisk = Tapdisk.launch_on_tap(blktap, local_leaf_path, tap_type, child_options)
             except:
                 blktap.free()
                 raise
@@ -2081,8 +2077,8 @@ class VDI(object):
         from lock import Lock
         from FileSR import FileVDI
 
-        parent_uuid = vhdutil.getParent(self.target.vdi.path,
-                FileVDI.extractUuid)
+        vdi_type = self.target.get_vdi_type()
+        parent_uuid = getCowUtil(vdi_type).getParent(self.target.vdi.path, FileVDI.extractUuid)
         if not parent_uuid:
             util.SMlog("ERROR: No parent for VDI %s, ignore" % \
                     self.target.vdi.uuid)
diff --git a/drivers/cbtutil.py b/drivers/cbtutil.py
index 545f702e..87f6dba5 100644
--- a/drivers/cbtutil.py
+++ b/drivers/cbtutil.py
@@ -14,7 +14,7 @@
 # along with this program; if not, write to the Free Software Foundation, Inc.,
 # 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
 #
-# Helper functions pertaining to VHD operations
+# Helper functions pertaining to COW image operations
 #
 
 import util
diff --git a/drivers/cleanup.py b/drivers/cleanup.py
index 3d22ef8d..6cc7292c 100755
--- a/drivers/cleanup.py
+++ b/drivers/cleanup.py
@@ -15,10 +15,10 @@
 # along with this program; if not, write to the Free Software Foundation, Inc.,
 # 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
 #
-# Script to coalesce and garbage collect VHD-based SR's in the background
+# Script to coalesce and garbage collect COW-based SR's in the background
 #
 
-from sm_typing import Optional, override
+from sm_typing import Any, Optional, List, override
 
 import os
 import os.path
@@ -37,8 +37,6 @@ import stat
 import XenAPI # pylint: disable=import-error
 import util
 import lvutil
-import vhdutil
-import lvhdutil
 import lvmcache
 import journaler
 import fjournaler
@@ -51,13 +49,15 @@ from lvmanager import LVActivator
 from srmetadata import LVMMetadataHandler, VDI_TYPE_TAG
 from functools import reduce
 from time import monotonic as _time
-from vditype import VdiType, VdiTypeExtension, VDI_TYPE_TO_EXTENSION
 
 from constants import NS_PREFIX_LVM, VG_LOCATION, VG_PREFIX
+from cowutil import CowImageInfo, CowUtil, getCowUtil
+from lvmcowutil import LV_PREFIX, LvmCowUtil
+from vditype import VdiType, VdiTypeExtension, VDI_COW_TYPES, VDI_TYPE_TO_EXTENSION
 
 try:
+    from linstorcowutil import LinstorCowUtil
     from linstorjournaler import LinstorJournaler
-    from linstorvhdutil import LinstorVhdUtil
     from linstorvolumemanager import get_controller_uri
     from linstorvolumemanager import LinstorVolumeManager
     from linstorvolumemanager import LinstorVolumeManagerError
@@ -500,7 +500,7 @@ class XAPI:
 #  VDI
 #
 class VDI(object):
-    """Object representing a VDI of a VHD-based SR"""
+    """Object representing a VDI of a COW-based SR"""
 
     POLL_INTERVAL = 1
     POLL_TIMEOUT = 30
@@ -567,6 +567,7 @@ class VDI(object):
         self.parent = None
         self.children = []
         self._vdiRef = None
+        self.cowutil = getCowUtil(vdi_type)
         self._clearRef()
 
     @staticmethod
@@ -767,7 +768,7 @@ class VDI(object):
         return leaves
 
     def updateBlockInfo(self) -> Optional[str]:
-        val = base64.b64encode(self._queryVHDBlocks()).decode()
+        val = base64.b64encode(self._queryCowBlocks()).decode()
         self.setConfig(VDI.DB_VDI_BLOCKS, val)
         return val
 
@@ -789,10 +790,10 @@ class VDI(object):
         self._clear()
 
     def getParent(self) -> str:
-        return vhdutil.getParent(self.path, lambda x: x.strip())
+        return self.cowutil.getParent(self.path, lambda x: x.strip())
 
     def repair(self, parent) -> None:
-        vhdutil.repair(parent)
+        self.cowutil.repair(parent)
 
     @override
     def __str__(self) -> str:
@@ -817,8 +818,8 @@ class VDI(object):
                 strSizePhys, strSizeAllocated, strType)
 
     def validate(self, fast=False) -> None:
-        if not vhdutil.check(self.path, fast=fast):
-            raise util.SMException("VHD %s corrupted" % self)
+        if self.cowutil.check(self.path, fast=fast) != CowUtil.CheckResult.Success:
+            raise util.SMException("COW image %s corrupted" % self)
 
     def _clear(self):
         self.uuid = ""
@@ -832,7 +833,7 @@ class VDI(object):
 
     def _doCoalesce(self) -> None:
         """Coalesce self onto parent. Only perform the actual coalescing of
-        VHD, but not the subsequent relinking. We'll do that as the next step,
+        an image, but not the subsequent relinking. We'll do that as the next step,
         after reloading the entire SR in case things have changed while we
         were coalescing"""
         self.validate()
@@ -913,8 +914,7 @@ class VDI(object):
             xapi.message.create(msg_name, "3", "SR", vdi.sr.uuid, msg_body)
 
     def coalesce(self) -> int:
-        # size is returned in sectors
-        return vhdutil.coalesce(self.path) * 512
+        return self.cowutil.coalesce(self.path)
 
     @staticmethod
     def _doCoalesceCowImage(vdi):
@@ -945,7 +945,7 @@ class VDI(object):
         return self.sr.vdis[uuid].vdi_type == VdiType.RAW
 
     def _coalesceCowImage(self, timeOut):
-        Util.log("  Running VHD coalesce on %s" % self)
+        Util.log("  Running COW coalesce on %s" % self)
         abortTest = lambda: IPCFlag(self.sr.uuid).test(FLAG_TYPE_ABORT)
         try:
             util.fistpoint.activate_custom_fn(
@@ -954,8 +954,8 @@ class VDI(object):
             Util.runAbortable(lambda: VDI._doCoalesceCowImage(self), None,
                     self.sr.uuid, abortTest, VDI.POLL_INTERVAL, timeOut)
         except:
-            #exception at this phase could indicate a failure in vhd coalesce
-            # or a kill of vhd coalesce by runAbortable due to  timeOut
+            # Exception at this phase could indicate a failure in COW coalesce
+            # or a kill of COW coalesce by runAbortable due to timeOut
             # Try a repair and reraise the exception
             parent = ""
             try:
@@ -987,7 +987,7 @@ class VDI(object):
 
     def _reloadChildren(self, vdiSkip):
         """Pause & unpause all VDIs in the subtree to cause blktap to reload
-        the VHD metadata for this file in any online VDI"""
+        the COW image metadata for this file in any online VDI"""
         abortFlag = IPCFlag(self.sr.uuid)
         for child in self.children:
             if child == vdiSkip:
@@ -998,7 +998,7 @@ class VDI(object):
             child._reload()
 
     def _reload(self):
-        """Pause & unpause to cause blktap to reload the VHD metadata"""
+        """Pause & unpause to cause blktap to reload the image metadata"""
         for child in self.children:
             child._reload()
 
@@ -1040,12 +1040,12 @@ class VDI(object):
             child._tagChildrenForRelink()
 
     def _loadInfoParent(self):
-        ret = vhdutil.getParent(self.path, lvhdutil.extractUuid)
+        ret = self.cowutil.getParent(self.path, LvmCowUtil.extractUuid)
         if ret:
             self.parentUuid = ret
 
     def _setParent(self, parent) -> None:
-        vhdutil.setParent(self.path, parent.path, False)
+        self.cowutil.setParent(self.path, parent.path, False)
         self.parent = parent
         self.parentUuid = parent.uuid
         parent.children.append(self)
@@ -1058,28 +1058,28 @@ class VDI(object):
                      (self.uuid, self.parentUuid))
 
     def _loadInfoHidden(self) -> None:
-        hidden = vhdutil.getHidden(self.path)
+        hidden = self.cowutil.getHidden(self.path)
         self.hidden = (hidden != 0)
 
     def _setHidden(self, hidden=True) -> None:
-        vhdutil.setHidden(self.path, hidden)
+        self.cowutil.setHidden(self.path, hidden)
         self.hidden = hidden
 
     def _increaseSizeVirt(self, size, atomic=True) -> None:
         """ensure the virtual size of 'self' is at least 'size'. Note that
-        resizing a VHD must always be offline and atomically: the file must
+        resizing a COW image must always be offline and atomically: the file must
         not be open by anyone and no concurrent operations may take place.
         Thus we use the Agent API call for performing paused atomic
         operations. If the caller is already in the atomic context, it must
         call with atomic = False"""
         if self.sizeVirt >= size:
             return
-        Util.log("  Expanding VHD virt size for VDI %s: %s -> %s" % \
+        Util.log("  Expanding COW image virt size for VDI %s: %s -> %s" % \
                 (self, Util.num2str(self.sizeVirt), Util.num2str(size)))
 
-        msize = vhdutil.getMaxResizeSize(self.path) * 1024 * 1024
+        msize = self.cowutil.getMaxResizeSize(self.path)
         if (size <= msize):
-            vhdutil.setSizeVirtFast(self.path, size)
+            self.cowutil.setSizeVirtFast(self.path, size)
         else:
             if atomic:
                 vdiList = self._getAllSubtree()
@@ -1095,22 +1095,22 @@ class VDI(object):
             else:
                 self._setSizeVirt(size)
 
-        self.sizeVirt = vhdutil.getSizeVirt(self.path)
+        self.sizeVirt = self.cowutil.getSizeVirt(self.path)
 
     def _setSizeVirt(self, size) -> None:
         """WARNING: do not call this method directly unless all VDIs in the
         subtree are guaranteed to be unplugged (and remain so for the duration
-        of the operation): this operation is only safe for offline VHDs"""
+        of the operation): this operation is only safe for offline COW images"""
         jFile = os.path.join(self.sr.path, self.uuid)
-        vhdutil.setSizeVirt(self.path, size, jFile)
+        self.cowutil.setSizeVirt(self.path, size, jFile)
 
-    def _queryVHDBlocks(self) -> bytes:
-        return vhdutil.getBlockBitmap(self.path)
+    def _queryCowBlocks(self) -> bytes:
+        return self.cowutil.getBlockBitmap(self.path)
 
     def _getCoalescedSizeData(self):
-        """Get the data size of the resulting VHD if we coalesce self onto
-        parent. We calculate the actual size by using the VHD block allocation
-        information (as opposed to just adding up the two VHD sizes to get an
+        """Get the data size of the resulting image if we coalesce self onto
+        parent. We calculate the actual size by using the image block allocation
+        information (as opposed to just adding up the two image sizes to get an
         upper bound)"""
         # make sure we don't use stale BAT info from vdi_rec since the child
         # was writable all this time
@@ -1119,14 +1119,14 @@ class VDI(object):
         blocksParent = self.parent.getVDIBlocks()
         numBlocks = Util.countBits(blocksChild, blocksParent)
         Util.log("Num combined blocks = %d" % numBlocks)
-        sizeData = numBlocks * vhdutil.VHD_BLOCK_SIZE
+        sizeData = numBlocks * self.cowutil.getBlockSize(self.path)
         assert(sizeData <= self.sizeVirt)
         return sizeData
 
     def _calcExtraSpaceForCoalescing(self) -> int:
         sizeData = self._getCoalescedSizeData()
-        sizeCoalesced = sizeData + vhdutil.calcOverheadBitmap(sizeData) + \
-                vhdutil.calcOverheadEmpty(self.sizeVirt)
+        sizeCoalesced = sizeData + self.cowutil.calcOverheadBitmap(sizeData) + \
+                self.cowutil.calcOverheadEmpty(self.sizeVirt)
         Util.log("Coalesced size = %s" % Util.num2str(sizeCoalesced))
         return sizeCoalesced - self.parent.getSizePhys()
 
@@ -1140,7 +1140,7 @@ class VDI(object):
         """How much extra space in the SR will be required to
         snapshot-coalesce this VDI"""
         return self._calcExtraSpaceForCoalescing() + \
-                vhdutil.calcOverheadEmpty(self.sizeVirt)  # extra snap leaf
+                self.cowutil.calcOverheadEmpty(self.sizeVirt)  # extra snap leaf
 
     def _getAllSubtree(self):
         """Get self and all VDIs in the subtree of self as a flat list"""
@@ -1156,14 +1156,8 @@ class FileVDI(VDI):
     @override
     @staticmethod
     def extractUuid(path):
-        path = os.path.basename(path.strip())
-        if not (path.endswith(VdiTypeExtension.VHD) or \
-                path.endswith(VdiTypeExtension.RAW)):
-            return None
-        uuid = path.replace(VdiTypeExtension.VHD, "").replace( \
-                VdiTypeExtension.RAW, "")
-        # TODO: validate UUID format
-        return uuid
+        fileName = os.path.basename(path)
+        return os.path.splitext(fileName)[0]
 
     def __init__(self, sr, uuid, vdi_type):
         VDI.__init__(self, sr, uuid, vdi_type)
@@ -1175,9 +1169,9 @@ class FileVDI(VDI):
             if not util.pathexists(self.path):
                 raise util.SMException("%s not found" % self.path)
             try:
-                info = vhdutil.getVHDInfo(self.path, self.extractUuid)
+                info = self.cowutil.getInfo(self.path, self.extractUuid)
             except util.SMException:
-                Util.log(" [VDI %s: failed to read VHD metadata]" % self.uuid)
+                Util.log(" [VDI %s: failed to read COW image metadata]" % self.uuid)
                 return
         self.parent = None
         self.children = []
@@ -1188,13 +1182,13 @@ class FileVDI(VDI):
         self.hidden = info.hidden
         self.scanError = False
         self.path = os.path.join(self.sr.path, "%s%s" % \
-                (self.uuid, VdiTypeExtension.VHD))
+                (self.uuid, VDI_TYPE_TO_EXTENSION[self.vdi_type]))
 
     @override
     def rename(self, uuid) -> None:
         oldPath = self.path
         VDI.rename(self, uuid)
-        self.fileName = "%s%s" % (self.uuid, VdiTypeExtension.VHD)
+        self.fileName = "%s%s" % (self.uuid, VDI_TYPE_TO_EXTENSION[self.vdi_type])
         self.path = os.path.join(self.sr.path, self.fileName)
         assert(not util.pathexists(self.path))
         Util.log("Renaming %s -> %s" % (oldPath, self.path))
@@ -1219,12 +1213,12 @@ class FileVDI(VDI):
     @override
     def getAllocatedSize(self) -> int:
         if self._sizeAllocated == -1:
-            self._sizeAllocated = vhdutil.getAllocatedSize(self.path)
+            self._sizeAllocated = self.cowutil.getAllocatedSize(self.path)
         return self._sizeAllocated
 
 
 class LVMVDI(VDI):
-    """Object representing a VDI in an LVHD SR"""
+    """Object representing a VDI in an LVM SR"""
 
     JRN_ZERO = "zero"  # journal entry type for zeroing out end of parent
 
@@ -1246,20 +1240,21 @@ class LVMVDI(VDI):
         self.hidden = info.hidden
         self.parentUuid = info.parentUuid
         self.path = os.path.join(self.sr.path, self.fileName)
+        self.lvmcowutil = LvmCowUtil(self.cowutil)
 
     @override
     @staticmethod
     def extractUuid(path):
-        return lvhdutil.extractUuid(path)
+        return LvmCowUtil.extractUuid(path)
 
     def inflate(self, size):
-        """inflate the LV containing the VHD to 'size'"""
+        """inflate the LV containing the COW image to 'size'"""
         if not VdiType.isCowImage(self.vdi_type):
             return
         self._activate()
         self.sr.lock()
         try:
-            lvhdutil.inflate(self.sr.journaler, self.sr.uuid, self.uuid, size)
+            self.lvmcowutil.inflate(self.sr.journaler, self.sr.uuid, self.uuid, self.vdi_type, size)
             util.fistpoint.activate("LVHDRT_inflating_the_parent", self.sr.uuid)
         finally:
             self.sr.unlock()
@@ -1268,13 +1263,13 @@ class LVMVDI(VDI):
         self._sizeAllocated = -1
 
     def deflate(self):
-        """deflate the LV containing the VHD to minimum"""
+        """deflate the LV containing the image to minimum"""
         if not VdiType.isCowImage(self.vdi_type):
             return
         self._activate()
         self.sr.lock()
         try:
-            lvhdutil.deflate(self.sr.lvmCache, self.fileName, self.getSizePhys())
+            self.lvmcowutil.deflate(self.sr.lvmCache, self.fileName, self.getSizePhys())
         finally:
             self.sr.unlock()
         self.sizeLV = self.sr.lvmCache.getSize(self.fileName)
@@ -1282,7 +1277,7 @@ class LVMVDI(VDI):
         self._sizeAllocated = -1
 
     def inflateFully(self):
-        self.inflate(lvhdutil.calcSizeVHDLV(self.sizeVirt))
+        self.inflate(self.lvmcowutil.calcVolumeSize(self.sizeVirt))
 
     def inflateParentForCoalesce(self):
         """Inflate the parent only as much as needed for the purposes of
@@ -1305,7 +1300,7 @@ class LVMVDI(VDI):
         oldUuid = self.uuid
         oldLVName = self.fileName
         VDI.rename(self, uuid)
-        self.fileName = lvhdutil.LV_PREFIX[self.vdi_type] + self.uuid
+        self.fileName = LV_PREFIX[self.vdi_type] + self.uuid
         self.path = os.path.join(self.sr.path, self.fileName)
         assert(not self.sr.lvmCache.checkLV(self.fileName))
 
@@ -1339,14 +1334,14 @@ class LVMVDI(VDI):
         return self._sizePhys
 
     def _loadInfoSizePhys(self):
-        """Get the physical utilization of the VHD file. We do it individually
-        (and not using the VHD batch scanner) as an optimization: this info is
+        """Get the physical utilization of the COW image file. We do it individually
+        (and not using the COW batch scanner) as an optimization: this info is
         relatively expensive and we need it only for VDI's involved in
         coalescing."""
         if not VdiType.isCowImage(self.vdi_type):
             return
         self._activate()
-        self._sizePhys = vhdutil.getSizePhys(self.path)
+        self._sizePhys = self.cowutil.getSizePhys(self.path)
         if self._sizePhys <= 0:
             raise util.SMException("phys size of %s = %d" % \
                     (self, self._sizePhys))
@@ -1359,12 +1354,12 @@ class LVMVDI(VDI):
 
     def _loadInfoSizeAllocated(self):
         """
-        Get the allocated size of the VHD volume.
+        Get the allocated size of the COW volume.
         """
         if not VdiType.isCowImage(self.vdi_type):
             return
         self._activate()
-        self._sizeAllocated = vhdutil.getAllocatedSize(self.path)
+        self._sizeAllocated = self.cowutil.getAllocatedSize(self.path)
 
     @override
     def _loadInfoHidden(self) -> None:
@@ -1411,7 +1406,7 @@ class LVMVDI(VDI):
 
     @override
     def _doCoalesce(self) -> None:
-        """LVHD parents must first be activated, inflated, and made writable"""
+        """LVMVDI parents must first be activated, inflated, and made writable"""
         try:
             self._activateChain()
             self.sr.lvmCache.setReadonly(self.parent.fileName, False)
@@ -1430,7 +1425,7 @@ class LVMVDI(VDI):
             self.sr.lvmCache.setReadonly(self.fileName, False)
 
         try:
-            vhdutil.setParent(self.path, parent.path, parent.vdi_type == VdiType.RAW)
+            self.cowutil.setParent(self.path, parent.path, parent.vdi_type == VdiType.RAW)
         finally:
             if self.lvReadonly:
                 self.sr.lvmCache.setReadonly(self.fileName, True)
@@ -1440,10 +1435,10 @@ class LVMVDI(VDI):
         parent.children.append(self)
         try:
             self.setConfig(self.DB_VDI_PARENT, self.parentUuid)
-            Util.log("Updated the vhd-parent field for child %s with %s" % \
+            Util.log("Updated the VDI-parent field for child %s with %s" % \
                      (self.uuid, self.parentUuid))
         except:
-            Util.log("Failed to update the vhd-parent with %s for child %s" % \
+            Util.log("Failed to update the VDI-parent with %s for child %s" % \
                      (self.parentUuid, self.uuid))
 
     def _activate(self):
@@ -1499,26 +1494,24 @@ class LVMVDI(VDI):
     def _setSizeVirt(self, size) -> None:
         """WARNING: do not call this method directly unless all VDIs in the
         subtree are guaranteed to be unplugged (and remain so for the duration
-        of the operation): this operation is only safe for offline VHDs"""
+        of the operation): this operation is only safe for offline COW images."""
         self._activate()
-        jFile = lvhdutil.createVHDJournalLV(self.sr.lvmCache, self.uuid,
-                vhdutil.MAX_VHD_JOURNAL_SIZE)
+        jFile = self.lvmcowutil.createResizeJournal(self.sr.lvmCache, self.uuid)
         try:
-            lvhdutil.setSizeVirt(self.sr.journaler, self.sr.uuid, self.uuid,
-                    size, jFile)
+            self.lvmcowutil.setSizeVirt(self.sr.journaler, self.sr.uuid, self.uuid, self.vdi_type, size, jFile)
         finally:
-            lvhdutil.deleteVHDJournalLV(self.sr.lvmCache, self.uuid)
+            self.lvmcowutil.destroyResizeJournal(self.sr.lvmCache, self.uuid)
 
     @override
-    def _queryVHDBlocks(self) -> bytes:
+    def _queryCowBlocks(self) -> bytes:
         self._activate()
-        return VDI._queryVHDBlocks(self)
+        return VDI._queryCowBlocks(self)
 
     @override
     def _calcExtraSpaceForCoalescing(self) -> int:
         if not VdiType.isCowImage(self.parent.vdi_type):
             return 0  # raw parents are never deflated in the first place
-        sizeCoalesced = lvhdutil.calcSizeVHDLV(self._getCoalescedSizeData())
+        sizeCoalesced = self.lvmcowutil.calcVolumeSize(self._getCoalescedSizeData())
         Util.log("Coalesced size = %s" % Util.num2str(sizeCoalesced))
         return sizeCoalesced - self.parent.sizeLV
 
@@ -1527,13 +1520,13 @@ class LVMVDI(VDI):
         """How much extra space in the SR will be required to
         [live-]leaf-coalesce this VDI"""
         # we can deflate the leaf to minimize the space requirements
-        deflateDiff = self.sizeLV - lvhdutil.calcSizeLV(self.getSizePhys())
+        deflateDiff = self.sizeLV - lvutil.calcSizeLV(self.getSizePhys())
         return self._calcExtraSpaceForCoalescing() - deflateDiff
 
     @override
     def _calcExtraSpaceForSnapshotCoalescing(self) -> int:
         return self._calcExtraSpaceForCoalescing() + \
-                lvhdutil.calcSizeLV(self.getSizePhys())
+                lvutil.calcSizeLV(self.getSizePhys())
 
 
 class LinstorVDI(VDI):
@@ -1550,13 +1543,14 @@ class LinstorVDI(VDI):
 
         self.fileName = self.sr._linstor.get_volume_name(self.uuid)
         self.path = self.sr._linstor.build_device_path(self.fileName)
+        self.linstorcowutil = LinstorCowUtil(self.sr.xapi.session, self.sr._linstor, info.vdiType)
 
         if not info:
             try:
-                info = self.sr._vhdutil.get_vhd_info(self.uuid)
+                info = self.linstorcowutil.get_info(self.uuid)
             except util.SMException:
                 Util.log(
-                    ' [VDI {}: failed to read VHD metadata]'.format(self.uuid)
+                    ' [VDI {}: failed to read COW image metadata]'.format(self.uuid)
                 )
                 return
 
@@ -1567,24 +1561,23 @@ class LinstorVDI(VDI):
         self.drbd_size = -1
         self.hidden = info.hidden
         self.scanError = False
-        self.vdi_type = VdiType.VHD
 
     @override
     def getSizePhys(self, fetch=False) -> int:
         if self._sizePhys < 0 or fetch:
-            self._sizePhys = self.sr._vhdutil.get_size_phys(self.uuid)
+            self._sizePhys = self.linstorcowutil.get_size_phys(self.uuid)
         return self._sizePhys
 
     def getDrbdSize(self, fetch=False):
         if self.drbd_size < 0 or fetch:
-            self.drbd_size = self.sr._vhdutil.get_drbd_size(self.uuid)
+            self.drbd_size = self.linstorcowutil.get_drbd_size(self.uuid)
         return self.drbd_size
 
     @override
     def getAllocatedSize(self) -> int:
         if self._sizeAllocated == -1:
             if VdiType.isCowImage(self.vdi_type):
-                self._sizeAllocated = self.sr._vhdutil.get_allocated_size(self.uuid)
+                self._sizeAllocated = self.linstorcowutil.get_allocated_size(self.uuid)
         return self._sizeAllocated
 
     def inflate(self, size):
@@ -1595,7 +1588,7 @@ class LinstorVDI(VDI):
             # Ensure we use the real DRBD size and not the cached one.
             # Why? Because this attribute can be changed if volume is resized by user.
             self.drbd_size = self.getDrbdSize(fetch=True)
-            self.sr._vhdutil.inflate(self.sr.journaler, self.uuid, self.path, size, self.drbd_size)
+            self.linstorcowutil.inflate(self.sr.journaler, self.uuid, self.path, size, self.drbd_size)
         finally:
             self.sr.unlock()
         self.drbd_size = -1
@@ -1610,7 +1603,7 @@ class LinstorVDI(VDI):
             # Ensure we use the real sizes and not the cached info.
             self.drbd_size = self.getDrbdSize(fetch=True)
             self._sizePhys = self.getSizePhys(fetch=True)
-            self.sr._vhdutil.force_deflate(self.path, self._sizePhys, self.drbd_size, zeroize=False)
+            self.linstorcowutil.force_deflate(self.path, self._sizePhys, self.drbd_size, zeroize=False)
         finally:
             self.sr.unlock()
         self.drbd_size = -1
@@ -1619,7 +1612,7 @@ class LinstorVDI(VDI):
 
     def inflateFully(self):
         if VdiType.isCowImage(self.vdi_type):
-            self.inflate(LinstorVhdUtil.compute_volume_size(self.sizeVirt, self.vdi_type))
+            self.inflate(self.linstorcowutil.compute_volume_size(self.sizeVirt))
 
     @override
     def rename(self, uuid) -> None:
@@ -1645,8 +1638,8 @@ class LinstorVDI(VDI):
 
     @override
     def validate(self, fast=False) -> None:
-        if VdiType.isCowImage(self.vdi_type) and not self.sr._vhdutil.check(self.uuid, fast=fast):
-            raise util.SMException('VHD {} corrupted'.format(self))
+        if VdiType.isCowImage(self.vdi_type) and self.linstorcowutil.check(self.uuid, fast=fast) != CowUtil.CheckResult.Success:
+            raise util.SMException('COW image {} corrupted'.format(self))
 
     @override
     def pause(self, failfast=False) -> None:
@@ -1659,17 +1652,17 @@ class LinstorVDI(VDI):
     def coalesce(self) -> int:
         # Note: We raise `SMException` here to skip the current coalesce in case of failure.
         # Using another exception we can't execute the next coalesce calls.
-        return self.sr._vhdutil.force_coalesce(self.path) * 512
+        return self.linstorcowutil.force_coalesce(self.path)
 
     @override
     def getParent(self) -> str:
-        return self.sr._vhdutil.get_parent(
+        return self.linstorcowutil.get_parent(
             self.sr._linstor.get_volume_uuid_from_device_path(self.path)
         )
 
     @override
     def repair(self, parent_uuid) -> None:
-        self.sr._vhdutil.force_repair(
+        self.linstorcowutil.force_repair(
             self.sr._linstor.get_device_path(parent_uuid)
         )
 
@@ -1701,7 +1694,7 @@ class LinstorVDI(VDI):
     @override
     def _setParent(self, parent) -> None:
         self.sr._linstor.get_device_path(self.uuid)
-        self.sr._vhdutil.force_parent(self.path, parent.path)
+        self.linstorcowutil.force_parent(self.path, parent.path)
         self.parent = parent
         self.parentUuid = parent.uuid
         parent.children.append(self)
@@ -1778,12 +1771,12 @@ class LinstorVDI(VDI):
 
         if self.sizeVirt >= size:
             return
-        Util.log("  Expanding VHD virt size for VDI %s: %s -> %s" % \
+        Util.log("  Expanding COW image virt size for VDI %s: %s -> %s" % \
                 (self, Util.num2str(self.sizeVirt), Util.num2str(size)))
 
-        msize = self.sr._vhdutil.get_max_resize_size(self.uuid) * 1024 * 1024
+        msize = self.linstorcowutil.get_max_resize_size(self.uuid) * 1024 * 1024
         if (size <= msize):
-            self.sr._vhdutil.set_size_virt_fast(self.path, size)
+            self.linstorcowutil.set_size_virt_fast(self.path, size)
         else:
             if atomic:
                 vdiList = self._getAllSubtree()
@@ -1799,17 +1792,17 @@ class LinstorVDI(VDI):
             else:
                 self._setSizeVirt(size)
 
-        self.sizeVirt = self.sr._vhdutil.get_size_virt(self.uuid)
+        self.sizeVirt = self.linstorcowutil.get_size_virt(self.uuid)
 
     @override
     def _setSizeVirt(self, size) -> None:
         jfile = self.uuid + '-jvhd'
         self.sr._linstor.create_volume(
-            jfile, vhdutil.MAX_VHD_JOURNAL_SIZE, persistent=False, volume_name=jfile
+            jfile, self.cowutil.getResizeJournalSize(), persistent=False, volume_name=jfile
         )
         try:
-            self.inflate(LinstorVhdUtil.compute_volume_size(size, self.vdi_type))
-            self.sr._vhdutil.set_size_virt(size, jfile)
+            self.inflate(self.linstorcowutil.compute_volume_size(size))
+            self.linstorcowutil.set_size_virt(self.path, size, jfile)
         finally:
             try:
                 self.sr._linstor.destroy_volume(jfile)
@@ -1818,8 +1811,8 @@ class LinstorVDI(VDI):
                 pass
 
     @override
-    def _queryVHDBlocks(self) -> bytes:
-        return self.sr._vhdutil.get_block_bitmap(self.uuid)
+    def _queryCowBlocks(self) -> bytes:
+        return self.linstorcowutil.get_block_bitmap(self.uuid)
 
     def _inflateParentForCoalesce(self):
         if not VdiType.isCowImage(self.parent.vdi_type):
@@ -1832,9 +1825,7 @@ class LinstorVDI(VDI):
     def _calcExtraSpaceForCoalescing(self) -> int:
         if not VdiType.isCowImage(self.parent.vdi_type):
             return 0
-        size_coalesced = LinstorVhdUtil.compute_volume_size(
-            self._getCoalescedSizeData(), self.vdi_type
-        )
+        size_coalesced = self.linstorcowutil.compute_volume_size(self._getCoalescedSizeData())
         Util.log("Coalesced size = %s" % Util.num2str(size_coalesced))
         return size_coalesced - self.parent.getDrbdSize()
 
@@ -1877,12 +1868,12 @@ class SR(object):
                 if not self.currState.get(uuid):
                     changes += "Tree %s gone\n" % uuid
 
-            result = "SR %s (%d VDIs in %d VHD trees): " % \
+            result = "SR %s (%d VDIs in %d COW trees): " % \
                     (self.sr, len(self.sr.vdis), len(self.sr.vdiTrees))
 
             if len(changes) > 0:
                 if self.stateLogged:
-                    result += "showing only VHD trees that changed:"
+                    result += "showing only COW trees that changed:"
                 result += "\n%s" % changes
             else:
                 result += "no changes"
@@ -2128,7 +2119,7 @@ class SR(object):
                                        "Leaf-coalesce disabled for this SR"))
 
     def findLeafCoalesceable(self):
-        """Find leaf-coalesceable VDIs in each VHD tree"""
+        """Find leaf-coalesceable VDIs in each COW tree"""
 
         candidates = []
         if self.leafCoalesceForbidden():
@@ -2378,7 +2369,7 @@ class SR(object):
         else:
             # JRN_COALESCE is used to check which VDI is being coalesced in
             # order to decide whether to abort the coalesce. We remove the
-            # journal as soon as the VHD coalesce step is done, because we
+            # journal as soon as the COW coalesce step is done, because we
             # don't expect the rest of the process to take long
             self.journaler.create(vdi.JRN_COALESCE, vdi.uuid, "1")
             vdi._doCoalesce()
@@ -2759,7 +2750,7 @@ class SR(object):
                 del self.vdis[uuid]
 
     def _handleInterruptedCoalesceLeaf(self) -> None:
-        """An interrupted leaf-coalesce operation may leave the VHD tree in an
+        """An interrupted leaf-coalesce operation may leave the COW tree in an
         inconsistent state. If the old-leaf VDI is still present, we revert the
         operation (in case the original error is persistent); otherwise we must
         finish the operation"""
@@ -2805,15 +2796,20 @@ class FileSR(SR):
     def scan(self, force=False) -> None:
         if not util.pathexists(self.path):
             raise util.SMException("directory %s not found!" % self.uuid)
-        vhds = self._scan(force)
-        for uuid, vhdInfo in vhds.items():
-            vdi = self.getVDI(uuid)
-            if not vdi:
-                self.logFilter.logNewVDI(uuid)
-                vdi = FileVDI(self, uuid, VdiType.VHD)
-                self.vdis[uuid] = vdi
-            vdi.load(vhdInfo)
-        uuidsPresent = list(vhds.keys())
+
+        uuidsPresent: List[str] = []
+
+        for vdi_type in VDI_COW_TYPES:
+            scan_result = self._scan(vdi_type, force)
+            for uuid, image_info in scan_result.items():
+                vdi = self.getVDI(uuid)
+                if not vdi:
+                    self.logFilter.logNewVDI(uuid)
+                    vdi = FileVDI(self, uuid, vdi_type)
+                    self.vdis[uuid] = vdi
+                vdi.load(image_info)
+            uuidsPresent.extend(scan_result.keys())
+
         rawList = [x for x in os.listdir(self.path) if x.endswith(VdiTypeExtension.RAW)]
         for rawName in rawList:
             uuid = FileVDI.extractUuid(rawName)
@@ -2917,20 +2913,20 @@ class FileSR(SR):
         return (len(name) == Util.UUID_LEN + len(self.CACHE_FILE_EXT)) and \
                 name.endswith(self.CACHE_FILE_EXT)
 
-    def _scan(self, force):
+    def _scan(self, vdi_type, force):
         for i in range(SR.SCAN_RETRY_ATTEMPTS):
             error = False
-            pattern = os.path.join(self.path, "*%s" % VdiTypeExtension.VHD)
-            vhds = vhdutil.getAllVHDs(pattern, FileVDI.extractUuid)
-            for uuid, vhdInfo in vhds.items():
-                if vhdInfo.error:
+            pattern = os.path.join(self.path, "*%s" % VDI_TYPE_TO_EXTENSION[vdi_type])
+            scan_result = getCowUtil(vdi_type).getAllInfoFromVG(pattern, FileVDI.extractUuid)
+            for uuid, vdiInfo in scan_result.items():
+                if vdiInfo.error:
                     error = True
                     break
             if not error:
-                return vhds
+                return scan_result
             Util.log("Scan error on attempt %d" % i)
         if force:
-            return vhds
+            return scan_result
         raise util.SMException("Scan error")
 
     @override
@@ -3000,7 +2996,7 @@ class FileSR(SR):
             child.rename(childUuid)
             Util.log("Updating the VDI record")
             child.setConfig(VDI.DB_VDI_PARENT, parentUuid)
-            child.setConfig(VDI.DB_VDI_TYPE, VdiType.VHD)
+            child.setConfig(VDI.DB_VDI_TYPE, child.vdi_type)
             util.fistpoint.activate("LVHDRT_coaleaf_undo_after_rename2", self.uuid)
 
         if child.hidden:
@@ -3111,7 +3107,7 @@ class LVMSR(SR):
         for i in range(SR.SCAN_RETRY_ATTEMPTS):
             error = False
             self.lvmCache.refresh()
-            vdis = lvhdutil.getVDIInfo(self.lvmCache)
+            vdis = LvmCowUtil.getVDIInfo(self.lvmCache)
             for uuid, vdiInfo in vdis.items():
                 if vdiInfo.scanError:
                     error = True
@@ -3176,20 +3172,27 @@ class LVMSR(SR):
 
     @override
     def _calcExtraSpaceNeeded(self, child, parent) -> int:
-        return lvhdutil.calcSizeVHDLV(parent.sizeVirt) - parent.sizeLV
+        return parent.lvmcowutil.calcVolumeSize(parent.sizeVirt) - parent.sizeLV
 
     @override
     def _handleInterruptedCoalesceLeaf(self) -> None:
         entries = self.journaler.getAll(VDI.JRN_LEAF)
         for uuid, parentUuid in entries.items():
-            childLV = lvhdutil.LV_PREFIX[VdiType.VHD] + uuid
-            tmpChildLV = lvhdutil.LV_PREFIX[VdiType.VHD] + \
-                    self.TMP_RENAME_PREFIX + uuid
-            parentLV1 = lvhdutil.LV_PREFIX[VdiType.VHD] + parentUuid
-            parentLV2 = lvhdutil.LV_PREFIX[VdiType.RAW] + parentUuid
-            parentPresent = (self.lvmCache.checkLV(parentLV1) or \
-                    self.lvmCache.checkLV(parentLV2))
-            if parentPresent or self.lvmCache.checkLV(tmpChildLV):
+            undo = False
+            for prefix in LV_PREFIX.values():
+                parentLV = prefix + parentUuid
+                undo = self.lvmCache.checkLV(parentLV)
+                if undo:
+                    break
+
+            if not undo:
+                for prefix in LV_PREFIX.values():
+                    tmpChildLV = prefix + uuid
+                    undo = self.lvmCache.checkLV(tmpChildLV)
+                    if undo:
+                        break
+
+            if undo:
                 self._undoInterruptedCoalesceLeaf(uuid, parentUuid)
             else:
                 self._finishInterruptedCoalesceLeaf(uuid, parentUuid)
@@ -3220,7 +3223,7 @@ class LVMSR(SR):
             child.rename(childUuid)
             Util.log("Updating the VDI record")
             child.setConfig(VDI.DB_VDI_PARENT, parentUuid)
-            child.setConfig(VDI.DB_VDI_TYPE, VdiType.VHD)
+            child.setConfig(VDI.DB_VDI_TYPE, child.vdi_type)
             util.fistpoint.activate("LVHDRT_coaleaf_undo_after_rename2", self.uuid)
 
             # refcount (best effort - assume that it had succeeded if the
@@ -3298,8 +3301,7 @@ class LVMSR(SR):
                     child)
             return
 
-        tmpName = lvhdutil.LV_PREFIX[VdiType.VHD] + \
-                self.TMP_RENAME_PREFIX + child.uuid
+        tmpName = child.vdi_type + self.TMP_RENAME_PREFIX + child.uuid
         args = {"vgName": self.vgName,
                 "action1": "deactivateNoRefcount",
                 "lvName1": tmpName,
@@ -3347,7 +3349,7 @@ class LVMSR(SR):
         if not slaves:
             util.SMlog("Update-on-resize: %s not attached on any slave" % vdi)
             return
-        lvhdutil.lvRefreshOnSlaves(self.xapi.session, self.uuid, self.vgName,
+        LvmCowUtil.refreshVolumeOnSlaves(self.xapi.session, self.uuid, self.vgName,
                 vdi.fileName, vdi.uuid, slaves)
 
 
@@ -3362,6 +3364,16 @@ class LinstorSR(SR):
 
         SR.__init__(self, uuid, xapi, createLock, force)
         self.path = LinstorVolumeManager.DEV_ROOT_PATH
+
+        class LinstorProxy:
+            def __init__(self, sr: LinstorSR) -> None:
+                self.sr = sr
+
+            def __getattr__(self, attr: str) -> Any:
+                assert self.sr, "Cannot use `LinstorProxy` without valid `LinstorVolumeManager` instance"
+                return getattr(self.sr._linstor, attr)
+
+        self._linstor_proxy = LinstorProxy(self)
         self._reloadLinstor(journaler_only=True)
 
     @override
@@ -3381,7 +3393,7 @@ class LinstorSR(SR):
             vdi = self.getVDI(uuid)
             if not vdi:
                 self.logFilter.logNewVDI(uuid)
-                vdi = LinstorVDI(self, uuid, VdiType.VHD if vdiInfo else VdiType.RAW)
+                vdi = LinstorVDI(self, uuid, vdiInfo.vdiType)
                 self.vdis[uuid] = vdi
             if vdiInfo:
                 vdi.load(vdiInfo)
@@ -3423,7 +3435,6 @@ class LinstorSR(SR):
             repair=True,
             logger=util.SMlog
         )
-        self._vhdutil = LinstorVhdUtil(session, self._linstor)
 
     def _scan(self, force):
         for i in range(SR.SCAN_RETRY_ATTEMPTS):
@@ -3460,7 +3471,7 @@ class LinstorSR(SR):
                     continue  # Ignore it, probably deleted.
 
                 if vdi_uuid.startswith('DELETED_'):
-                    # Assume it's really a RAW volume of a failed snap without VHD header/footer.
+                    # Assume it's really a RAW volume of a failed snap without COW header/footer.
                     # We must remove this VDI now without adding it in the VDI list.
                     # Otherwise `Relinking` calls and other actions can be launched on it.
                     # We don't want that...
@@ -3485,17 +3496,18 @@ class LinstorSR(SR):
                     # Always RAW!
                     info = None
                 elif VdiType.isCowImage(vdi_type):
-                    info = self._vhdutil.get_vhd_info(vdi_uuid)
+                    info = LinstorCowUtil(self.xapi.session, self._linstor, vdi_type).get_info(vdi_uuid)
                 else:
-                    # Ensure it's not a VHD...
+                    # Ensure it's not a COW image...
+                    linstorcowutil = LinstorCowUtil(self.xapi.session, self._linstor, vdi_type)
                     try:
-                        info = self._vhdutil.get_vhd_info(vdi_uuid)
+                        info = linstorcowutil.get_info(vdi_uuid)
                     except:
                         try:
-                            self._vhdutil.force_repair(
+                            linstorcowutil.force_repair(
                                 self._linstor.get_device_path(vdi_uuid)
                             )
-                            info = self._vhdutil.get_vhd_info(vdi_uuid)
+                            info = linstorcowutil.get_info(vdi_uuid)
                         except:
                             info = None
 
@@ -3504,7 +3516,7 @@ class LinstorSR(SR):
                     ' [VDI {}: failed to load VDI info]: {}'
                     .format(vdi_uuid, e)
                 )
-                info = vhdutil.VHDInfo(vdi_uuid)
+                info = CowImageInfo(vdi_uuid)
                 info.error = 1
 
             all_vdi_info[vdi_uuid] = info
@@ -3526,7 +3538,9 @@ class LinstorSR(SR):
 
     @override
     def _calcExtraSpaceNeeded(self, child, parent) -> int:
-        return LinstorVhdUtil.compute_volume_size(parent.sizeVirt, parent.vdi_type) - parent.getDrbdSize()
+        return LinstorCowUtil(
+            self.xapi.session, self._linstor, parent.vdi_type
+        ).compute_volume_size(parent.sizeVirt) - parent.getDrbdSize()
 
     def _hasValidDevicePath(self, uuid):
         try:
@@ -3588,7 +3602,7 @@ class LinstorSR(SR):
             child.rename(childUuid)
             Util.log('Updating the VDI record')
             child.setConfig(VDI.DB_VDI_PARENT, parentUuid)
-            child.setConfig(VDI.DB_VDI_TYPE, VdiType.VHD)
+            child.setConfig(VDI.DB_VDI_TYPE, child.vdi_type)
 
         # TODO: Maybe deflate here.
 
@@ -3907,7 +3921,7 @@ class LockActive:
 
 
 def usage():
-    output = """Garbage collect and/or coalesce VHDs in a VHD-based SR
+    output = """Garbage collect and/or coalesce COW images in a COW-based SR
 
 Parameters:
     -u --uuid UUID   SR UUID
@@ -3923,8 +3937,8 @@ Parameters:
 
 Options:
     -b --background  run in background (return immediately) (valid for -g only)
-    -f --force       continue in the presence of VHDs with errors (when doing
-                     GC, this might cause removal of any such VHDs) (only valid
+    -f --force       continue in the presence of COW images with errors (when doing
+                     GC, this might cause removal of any such images) (only valid
                      for -G) (DANGEROUS)
 
 Debug:
@@ -4059,7 +4073,7 @@ def gc_force(session, srUuid, force=False, dryRun=False, lockSR=False):
         Util.log("Nothing was running, clear to proceed")
 
     if force:
-        Util.log("FORCED: will continue even if there are VHD errors")
+        Util.log("FORCED: will continue even if there are COW image errors")
     sr.scanLocked(force)
     sr.cleanupCoalesceJournals()
 
diff --git a/drivers/coalesce-leaf b/drivers/coalesce-leaf
index f45e2480..334e4ae4 100755
--- a/drivers/coalesce-leaf
+++ b/drivers/coalesce-leaf
@@ -33,8 +33,8 @@ import atexit
 USAGE_STRING = \
     """Usage: %s -u/--uuid <UUID of VM whose VDIs should be leaf-coalesced>
 This will coalesce each VDI attached to the given VM that consists of a pair
-of VHD files into a single VHD file.
-Only LVM SRs will be considered, and only VDIs whose VHD chain length equals 2.
+of COW files into a single COW file.
+Only LVM SRs will be considered, and only VDIs whose COW chain length equals 2.
 Note that the VM will be suspended during the operation. DO NOT
 start/resume/unpause the VM during the operation."""
 
diff --git a/drivers/cowutil.py b/drivers/cowutil.py
new file mode 100755
index 00000000..42cc8273
--- /dev/null
+++ b/drivers/cowutil.py
@@ -0,0 +1,328 @@
+#!/usr/bin/env python3
+#
+# Copyright (C) 2024  Vates SAS
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU General Public License for more details.
+#
+# You should have received a copy of the GNU General Public License
+# along with this program.  If not, see <https://www.gnu.org/licenses/>.
+
+from sm_typing import Any, Callable, Dict, Final, List, Optional, Sequence, Union, override
+
+from abc import ABC, abstractmethod
+from enum import IntEnum
+
+import errno
+import time
+
+import util
+
+from vditype import VdiType
+
+# ------------------------------------------------------------------------------
+
+IMAGE_FORMAT_COW_FLAG: Final = 1 << 8
+
+class ImageFormat(IntEnum):
+    RAW   = 1
+    VHD   = 2 | IMAGE_FORMAT_COW_FLAG
+
+IMAGE_FORMAT_TO_STR: Final = {
+    ImageFormat.RAW:   "raw",
+    ImageFormat.VHD:   "vhd"
+}
+
+STR_TO_IMAGE_FORMAT: Final = {v: k for k, v in IMAGE_FORMAT_TO_STR.items()}
+
+# ------------------------------------------------------------------------------
+
+def parseImageFormats(str_formats: Optional[str], default_formats: List[ImageFormat]) -> List[ImageFormat]:
+    if not str_formats:
+        return default_formats
+
+    entries = [entry.strip() for entry in str_formats.split(",")]
+
+    image_formats: List[ImageFormat] = []
+    for entry in entries:
+        image_format = STR_TO_IMAGE_FORMAT.get(entry)
+        if image_format:
+          image_formats.append(image_format)
+
+    if image_formats:
+        return image_formats
+
+    return default_formats
+
+# ------------------------------------------------------------------------------
+
+class CowImageInfo(object):
+    uuid = ""
+    path = ""
+    sizeVirt = -1
+    sizePhys = -1
+    sizeAllocated = -1
+    hidden = False
+    parentUuid = ""
+    parentPath = ""
+    error: Any = 0
+
+    def __init__(self, uuid):
+        self.uuid = uuid
+
+# ------------------------------------------------------------------------------
+
+class CowUtil(ABC):
+    class CheckResult(IntEnum):
+        Success = 0
+        Fail = 1
+        Unavailable = 2
+
+    @abstractmethod
+    def getMinImageSize(self) -> int:
+        pass
+
+    @abstractmethod
+    def getMaxImageSize(self) -> int:
+        pass
+
+    @abstractmethod
+    def getBlockSize(self, path: str) -> int:
+        pass
+
+    @abstractmethod
+    def getFooterSize(self) -> int:
+        pass
+
+    @abstractmethod
+    def getDefaultPreallocationSizeVirt(self) -> int:
+        pass
+
+    @abstractmethod
+    def getMaxChainLength(self) -> int:
+        pass
+
+    @abstractmethod
+    def calcOverheadEmpty(self, virtual_size: int) -> int:
+        pass
+
+    @abstractmethod
+    def calcOverheadBitmap(self, virtual_size: int) -> int:
+        pass
+
+    @abstractmethod
+    def getInfo(
+        self,
+        path: str,
+        extractUuidFunction: Callable[[str], str],
+        includeParent: bool = True,
+        resolveParent: bool = True,
+        useBackupFooter: bool = False
+    ) -> CowImageInfo:
+        pass
+
+    @abstractmethod
+    def getInfoFromLVM(
+        self, lvName: str, extractUuidFunction: Callable[[str], str], vgName: str
+    ) -> Optional[CowImageInfo]:
+        pass
+
+    @abstractmethod
+    def getAllInfoFromVG(
+        self,
+        pattern: str,
+        extractUuidFunction: Callable[[str], str],
+        vgName: Optional[str] = None,
+        parents: bool = False,
+        exitOnError: bool = False
+    ) -> Dict[str, CowImageInfo]:
+        pass
+
+    @abstractmethod
+    def getParent(self, path: str, extractUuidFunction: Callable[[str], str]) -> Optional[str]:
+        pass
+
+    @abstractmethod
+    def getParentNoCheck(self, path: str) -> Optional[str]:
+        pass
+
+    @abstractmethod
+    def hasParent(self, path: str) -> bool:
+        pass
+
+    @abstractmethod
+    def setParent(self, path: str, parentPath: str, parentRaw: bool) -> None:
+        pass
+
+    @abstractmethod
+    def getHidden(self, path: str) -> bool:
+        pass
+
+    @abstractmethod
+    def setHidden(self, path: str, hidden: bool = True) -> None:
+        pass
+
+    @abstractmethod
+    def getSizeVirt(self, path: str) -> int:
+        pass
+
+    @abstractmethod
+    def setSizeVirt(self, path: str, size: int, jFile: str) -> None:
+        pass
+
+    @abstractmethod
+    def setSizeVirtFast(self, path: str, size: int) -> None:
+        pass
+
+    @abstractmethod
+    def getMaxResizeSize(self, path: str) -> int:
+        pass
+
+    @abstractmethod
+    def getSizePhys(self, path: str) -> int:
+        pass
+
+    @abstractmethod
+    def setSizePhys(self, path: str, size: int, debug: bool = True) -> None:
+        pass
+
+    @abstractmethod
+    def getAllocatedSize(self, path: str) -> int:
+        pass
+
+    @abstractmethod
+    def getResizeJournalSize(self) -> int:
+        pass
+
+    @abstractmethod
+    def killData(self, path: str) -> None:
+        pass
+
+    @abstractmethod
+    def getDepth(self, path: str) -> int:
+        pass
+
+    @abstractmethod
+    def getBlockBitmap(self, path: str) -> bytes:
+        pass
+
+    @abstractmethod
+    def coalesce(self, path: str) -> int:
+        pass
+
+    @abstractmethod
+    def create(self, path: str, size: int, static: bool, msize: int = 0) -> None:
+        pass
+
+    @abstractmethod
+    def snapshot(
+        self,
+        path: str,
+        parent: str,
+        parentRaw: bool,
+        msize: int = 0,
+        checkEmpty: Optional[bool] = True
+    ) -> None:
+        pass
+
+    @abstractmethod
+    def canSnapshotRaw(self, size: int) -> bool:
+        pass
+
+    @abstractmethod
+    def check(
+        self,
+        path: str,
+        ignoreMissingFooter: Optional[bool] = False,
+        fast: Optional[bool] = False
+    ) -> 'CowUtil.CheckResult':
+        pass
+
+    @abstractmethod
+    def revert(self, path: str, jFile: str) -> None:
+        pass
+
+    @abstractmethod
+    def repair(self, path: str) -> None:
+        pass
+
+    @abstractmethod
+    def validateAndRoundImageSize(self, size: int) -> int:
+        pass
+
+    @abstractmethod
+    def getKeyHash(self, path: str) -> Optional[str]:
+        pass
+
+    @abstractmethod
+    def setKey(self, path: str, key_hash: str) -> None:
+        pass
+
+    def getParentChain(self, lvName: str, extractUuidFunction: Callable[[str], str], vgName: str) -> Dict[str, str]:
+        """
+        Get the chain of all parents of 'path'. Safe to call for raw VDI's as well.
+        """
+        chain = {}
+        vdis: Dict[str, CowImageInfo] = {}
+        retries = 0
+        while (not vdis):
+            if retries > 60:
+                util.SMlog('ERROR: getAllInfoFromVG returned 0 VDIs after %d retries' % retries)
+                util.SMlog('ERROR: the image metadata might be corrupted')
+                break
+            vdis = self.getAllInfoFromVG(lvName, extractUuidFunction, vgName, True, True)
+            if (not vdis):
+                retries = retries + 1
+                time.sleep(1)
+        for uuid, vdi in vdis.items():
+            chain[uuid] = vdi.path
+        #util.SMlog("Parent chain for %s: %s" % (lvName, chain))
+        return chain
+
+    @staticmethod
+    def isCowImage(image_format: ImageFormat) -> bool:
+        return bool(image_format & IMAGE_FORMAT_COW_FLAG)
+
+    @staticmethod
+    def _ioretry(cmd: Sequence[str], text: bool = True) -> Union[str, bytes]:
+        return util.ioretry(
+            lambda: util.pread2(cmd, text=text),
+            errlist=[errno.EIO, errno.EAGAIN]
+        )
+
+# ------------------------------------------------------------------------------
+
+def getImageFormatFromVdiType(vdi_type: str) -> ImageFormat:
+    if vdi_type == VdiType.RAW:
+        return ImageFormat.RAW
+    if vdi_type == VdiType.VHD:
+        return ImageFormat.VHD
+
+    assert False, f"Unsupported vdi type: {vdi_type}"
+
+def getVdiTypeFromImageFormat(image_format: ImageFormat) -> str:
+    if image_format == ImageFormat.RAW:
+        return VdiType.RAW
+    if image_format == ImageFormat.VHD:
+        return VdiType.VHD
+
+    assert False, f"Unsupported image format: {IMAGE_FORMAT_TO_STR[image_format]}"
+
+# ------------------------------------------------------------------------------
+
+def getCowUtilFromImageFormat(image_format: ImageFormat) -> CowUtil:
+    import vhdutil
+
+    if image_format in (ImageFormat.RAW, ImageFormat.VHD):
+        return vhdutil.VhdUtil()
+
+    assert False, f"Unsupported image format: {image_format}"
+
+def getCowUtil(vdi_type: str) -> CowUtil:
+    return getCowUtilFromImageFormat(getImageFormatFromVdiType(vdi_type))
diff --git a/drivers/lcache.py b/drivers/lcache.py
index 1b7c78f2..50ea690f 100755
--- a/drivers/lcache.py
+++ b/drivers/lcache.py
@@ -22,6 +22,8 @@ import blktap2
 import glob
 from stat import *  # S_ISBLK(), ...
 
+from vditype import VdiType
+
 SECTOR_SHIFT = 9
 
 
@@ -33,7 +35,7 @@ class CachingTap(object):
 
     @classmethod
     def from_tapdisk(cls, tapdisk, stats):
-        # pick the last image. if it's a VHD, we got a parent
+        # pick the last image. if it's a COW, we got a parent
         # cache. the leaf case is an aio node sitting on a
         # parent-caching tapdev. always checking the complementary
         # case, so we bail on unexpected chains.
@@ -47,7 +49,7 @@ class CachingTap(object):
             if not cond:
                 raise cls.NotACachingTapdisk(tapdisk, stats)
 
-        if _type == 'vhd':
+        if VdiType.isCowImage(_type):
             # parent
 
             return ParentCachingTap(tapdisk, stats)
diff --git a/drivers/linstor-manager b/drivers/linstor-manager
index e568643c..fffb9736 100755
--- a/drivers/linstor-manager
+++ b/drivers/linstor-manager
@@ -27,15 +27,15 @@ import XenAPI
 import XenAPIPlugin
 
 from json import JSONEncoder
+from cowutil import getCowUtil
+from linstorcowutil import LinstorCowUtil
 from linstorjournaler import LinstorJournaler
-from linstorvhdutil import LinstorVhdUtil, check_ex
 from linstorvolumemanager import get_controller_uri, get_local_volume_openers, LinstorVolumeManager
 import json
 import LinstorSR
 import lock
 import re
 import util
-import vhdutil
 
 BACKING_DISK_RE = re.compile('^/dev/([^/]+)/(?:[^/]+)$')
 LVM_PLUGIN = 'lvm.py'
@@ -281,6 +281,12 @@ def get_ip_addr_of_pif(session, pif_uuid):
         raise XenAPIPlugin.Failure('-1', ['PIF has no IP'])
     return ip_addr
 
+
+def extract_uuid(device_path):
+    return linstor.get_volume_uuid_from_device_path(
+        device_path.rstrip('\n')
+    )
+
 # ------------------------------------------------------------------------------
 
 
@@ -387,20 +393,21 @@ def destroy(session, args):
 
 def check(session, args):
     try:
+        cowutil = getCowUtil(args['vdiType'])
         device_path = args['devicePath']
         ignore_missing_footer = util.strtobool(
             args['ignoreMissingFooter']
         )
         fast = util.strtobool(args['fast'])
-        check_ex(device_path, ignore_missing_footer, fast)
-        return str(True)
+        return cowutil.check(device_path, ignore_missing_footer, fast)
     except Exception as e:
         util.SMlog('linstor-manager:check error: {}'.format(e))
         raise
 
 
-def get_vhd_info(session, args):
+def get_info(session, args):
     try:
+        cowutil = getCowUtil(args['vdiType'])
         device_path = args['devicePath']
         group_name = args['groupName']
         include_parent = util.strtobool(args['includeParent'])
@@ -411,25 +418,20 @@ def get_vhd_info(session, args):
             logger=util.SMlog
         )
 
-        def extract_uuid(device_path):
-            # TODO: Remove new line in the vhdutil module. Not here.
-            return linstor.get_volume_uuid_from_device_path(
-                device_path.rstrip('\n')
-            )
-
-        vhd_info = vhdutil.getVHDInfo(
+        image_info = cowutil.getInfo(
             device_path, extract_uuid, include_parent, False
         )
-        return json.dumps(vhd_info.__dict__)
+        return json.dumps(image_info.__dict__)
     except Exception as e:
-        util.SMlog('linstor-manager:get_vhd_info error: {}'.format(e))
+        util.SMlog('linstor-manager:get_info error: {}'.format(e))
         raise
 
 
 def has_parent(session, args):
     try:
+        cowutil = getCowUtil(args['vdiType'])
         device_path = args['devicePath']
-        return str(vhdutil.hasParent(device_path))
+        return str(cowutil.hasParent(device_path))
     except Exception as e:
         util.SMlog('linstor-manager:has_parent error: {}'.format(e))
         raise
@@ -437,6 +439,7 @@ def has_parent(session, args):
 
 def get_parent(session, args):
     try:
+        cowutil = getCowUtil(args['vdiType'])
         device_path = args['devicePath']
         group_name = args['groupName']
 
@@ -446,13 +449,7 @@ def get_parent(session, args):
             logger=util.SMlog
         )
 
-        def extract_uuid(device_path):
-            # TODO: Remove new line in the vhdutil module. Not here.
-            return linstor.get_volume_uuid_from_device_path(
-                device_path.rstrip('\n')
-            )
-
-        return vhdutil.getParent(device_path, extract_uuid)
+        return cowutil.getParent(device_path, extract_uuid)
     except Exception as e:
         util.SMlog('linstor-manager:get_parent error: {}'.format(e))
         raise
@@ -460,8 +457,9 @@ def get_parent(session, args):
 
 def get_size_virt(session, args):
     try:
+        cowutil = getCowUtil(args['vdiType'])
         device_path = args['devicePath']
-        return str(vhdutil.getSizeVirt(device_path))
+        return str(cowutil.getSizeVirt(device_path))
     except Exception as e:
         util.SMlog('linstor-manager:get_size_virt error: {}'.format(e))
         raise
@@ -469,8 +467,9 @@ def get_size_virt(session, args):
 
 def get_size_phys(session, args):
     try:
+        cowutil = getCowUtil(args['vdiType'])
         device_path = args['devicePath']
-        return str(vhdutil.getSizePhys(device_path))
+        return str(cowutil.getSizePhys(device_path))
     except Exception as e:
         util.SMlog('linstor-manager:get_size_phys error: {}'.format(e))
         raise
@@ -478,8 +477,9 @@ def get_size_phys(session, args):
 
 def get_allocated_size(session, args):
     try:
+        cowutil = getCowUtil(args['vdiType'])
         device_path = args['devicePath']
-        return str(vhdutil.getAllocatedSize(device_path))
+        return str(cowutil.getAllocatedSize(device_path))
     except Exception as e:
         util.SMlog('linstor-manager:get_allocated_size error: {}'.format(e))
         raise
@@ -496,8 +496,9 @@ def get_max_resize_size(session, args):
 
 def get_depth(session, args):
     try:
+        cowutil = getCowUtil(args['vdiType'])
         device_path = args['devicePath']
-        return str(vhdutil.getDepth(device_path))
+        return str(cowutil.getDepth(device_path))
     except Exception as e:
         util.SMlog('linstor-manager:get_depth error: {}'.format(e))
         raise
@@ -505,8 +506,9 @@ def get_depth(session, args):
 
 def get_key_hash(session, args):
     try:
+        cowutil = getCowUtil(args['vdiType'])
         device_path = args['devicePath']
-        return vhdutil.getKeyHash(device_path) or ''
+        return cowutil.getKeyHash(device_path) or ''
     except Exception as e:
         util.SMlog('linstor-manager:get_key_hash error: {}'.format(e))
         raise
@@ -514,8 +516,9 @@ def get_key_hash(session, args):
 
 def get_block_bitmap(session, args):
     try:
+        cowutil = getCowUtil(args['vdiType'])
         device_path = args['devicePath']
-        return base64.b64encode(vhdutil.getBlockBitmap(device_path)).decode('ascii')
+        return base64.b64encode(cowutil.getBlockBitmap(device_path)).decode('ascii')
     except Exception as e:
         util.SMlog('linstor-manager:get_block_bitmap error: {}'.format(e))
         raise
@@ -537,8 +540,8 @@ def set_size_virt(session, args):
     try:
         device_path = args['devicePath']
         size = int(args['size'])
-        jfile = args['jfile']
-        vhdutil.setSizeVirt(device_path, size, jfile)
+        jFile = args['jFile']
+        vhdutil.setSizeVirt(device_path, size, jFile)
         return ''
     except Exception as e:
         util.SMlog('linstor-manager:set_size_virt error: {}'.format(e))
@@ -558,9 +561,10 @@ def set_size_virt_fast(session, args):
 
 def set_parent(session, args):
     try:
+        cowutil = getCowUtil(args['vdiType'])
         device_path = args['devicePath']
         parent_path = args['parentPath']
-        vhdutil.setParent(device_path, parent_path, False)
+        cowutil.setParent(device_path, parent_path, False)
         return ''
     except Exception as e:
         util.SMlog('linstor-manager:set_parent error: {}'.format(e))
@@ -569,8 +573,9 @@ def set_parent(session, args):
 
 def coalesce(session, args):
     try:
+        cowutil = getCowUtil(args['vdiType'])
         device_path = args['devicePath']
-        return str(vhdutil.coalesce(device_path))
+        return str(cowutil.coalesce(device_path))
     except Exception as e:
         util.SMlog('linstor-manager:coalesce error: {}'.format(e))
         raise
@@ -578,8 +583,9 @@ def coalesce(session, args):
 
 def repair(session, args):
     try:
+        cowutil = getCowUtil(args['vdiType'])
         device_path = args['devicePath']
-        vhdutil.repair(device_path)
+        cowutil.repair(device_path)
         return ''
     except Exception as e:
         util.SMlog('linstor-manager:repair error: {}'.format(e))
@@ -588,6 +594,7 @@ def repair(session, args):
 
 def deflate(session, args):
     try:
+        cowutil = getCowUtil(args['vdiType'])
         device_path = args['devicePath']
         new_size = int(args['newSize'])
         old_size = int(args['oldSize'])
@@ -599,7 +606,7 @@ def deflate(session, args):
             group_name,
             logger=util.SMlog
         )
-        LinstorVhdUtil(session, linstor).deflate(device_path, new_size, old_size, zeroize)
+        LinstorCowUtil(session, linstor, cowutil).deflate(device_path, new_size, old_size, zeroize)
         return ''
     except Exception as e:
         util.SMlog('linstor-manager:deflate error: {}'.format(e))
@@ -1232,14 +1239,14 @@ if __name__ == '__main__':
         'detach': detach,
         'destroy': destroy,
 
-        # vhdutil wrappers called by linstorvhdutil.
-        # Note: When a VHD is open in RO mode (so for all vhdutil getters),
+        # cowutil wrappers called by LinstorCowUtil.
+        # Note: When a COW image is open in RO mode (so for all cowutil getters),
         # the LVM layer is used directly to bypass DRBD verifications.
         # In this case there can't be EROFS errors.
-        # Note 2: We assume linstorvhdutil executes remote calls on diskful
+        # Note 2: We assume LinstorCowUtil executes remote calls on diskful
         # DRBDs, otherwise we still have EROFS errors...
         'check': check,
-        'getVHDInfo': get_vhd_info,
+        'getInfo': get_info,
         'hasParent': has_parent,
         'getParent': get_parent,
         'getSizeVirt': get_size_virt,
diff --git a/drivers/linstorvhdutil.py b/drivers/linstorcowutil.py
similarity index 79%
rename from drivers/linstorvhdutil.py
rename to drivers/linstorcowutil.py
index 83d3ec1a..0a1e7a6f 100644
--- a/drivers/linstorvhdutil.py
+++ b/drivers/linstorcowutil.py
@@ -16,16 +16,18 @@
 
 from sm_typing import override
 
-from linstorjournaler import LinstorJournaler
-from linstorvolumemanager import LinstorVolumeManager
 import base64
 import errno
 import json
 import socket
 import time
+
+from cowutil import CowImageInfo, CowUtil, getCowUtil
 import util
-import vhdutil
 import xs_errors
+
+from linstorjournaler import LinstorJournaler
+from linstorvolumemanager import LinstorVolumeManager
 from vditype import VdiType
 
 MANAGER_PLUGIN = 'linstor-manager'
@@ -49,16 +51,6 @@ def call_remote_method(session, host_ref, method, args):
     return response
 
 
-def check_ex(path, ignoreMissingFooter = False, fast = False):
-    cmd = [vhdutil.VHD_UTIL, "check", vhdutil.OPT_LOG_ERR, "-n", path]
-    if ignoreMissingFooter:
-        cmd.append("-i")
-    if fast:
-        cmd.append("-B")
-
-    vhdutil.ioretry(cmd)
-
-
 class LinstorCallException(util.SMException):
     def __init__(self, cmd_err):
         self.cmd_err = cmd_err
@@ -115,7 +107,8 @@ def linstorhostcall(local_method, remote_method):
             # B. Execute the plugin on master or slave.
             remote_args = {
                 'devicePath': device_path,
-                'groupName': self._linstor.group_name
+                'groupName': self._linstor.group_name,
+                'vdiType': self._vdi_type
             }
             remote_args.update(**kwargs)
             remote_args = {str(key): str(value) for key, value in remote_args.items()}
@@ -145,15 +138,19 @@ def linstormodifier():
     return decorated
 
 
-class LinstorVhdUtil:
-    MAX_SIZE = 2 * 1024 * 1024 * 1024 * 1024  # Max VHD size.
-
-    def __init__(self, session, linstor):
+class LinstorCowUtil(object):
+    def __init__(self, session, linstor, vdi_type: str):
         self._session = session
         self._linstor = linstor
+        self._cowutil = getCowUtil(vdi_type)
+        self._vdi_type = vdi_type
+
+    @property
+    def cowutil(self) -> CowUtil:
+        return self._cowutil
 
     def create_chain_paths(self, vdi_uuid, readonly=False):
-        # OPTIMIZE: Add a limit_to_first_allocated_block param to limit vhdutil calls.
+        # OPTIMIZE: Add a limit_to_first_allocated_block param to limit cowutil calls.
         # Useful for the snapshot code algorithm.
 
         leaf_vdi_path = self._linstor.get_device_path(vdi_uuid)
@@ -182,7 +179,7 @@ class LinstorVhdUtil:
                     break
             util.retry(check_volume_usable, 15, 2)
 
-            vdi_uuid = self.get_vhd_info(vdi_uuid).parentUuid
+            vdi_uuid = self.get_info(vdi_uuid).parentUuid
             if not vdi_uuid:
                 break
             path = self._linstor.get_device_path(vdi_uuid)
@@ -199,75 +196,70 @@ class LinstorVhdUtil:
             'ignoreMissingFooter': ignore_missing_footer,
             'fast': fast
         }
-        try:
-            self._check(vdi_uuid, **kwargs)
-            return True
-        except Exception as e:
-            util.SMlog('Call to `check` failed: {}'.format(e))
-            return False
+        return self._check(vdi_uuid, **kwargs)
 
-    @linstorhostcall(check_ex, 'check')
+    @linstorhostcall(CowUtil.check, 'check')
     def _check(self, vdi_uuid, response):
-        return util.strtobool(response)
+        return CowUtil.CheckResult(response)
 
-    def get_vhd_info(self, vdi_uuid, include_parent=True):
+    def get_info(self, vdi_uuid, include_parent=True):
         kwargs = {
             'includeParent': include_parent,
             'resolveParent': False
         }
-        return self._get_vhd_info(vdi_uuid, self._extract_uuid, **kwargs)
+        return self._get_info(vdi_uuid, self._extract_uuid, **kwargs)
 
-    @linstorhostcall(vhdutil.getVHDInfo, 'getVHDInfo')
-    def _get_vhd_info(self, vdi_uuid, response):
+    @linstorhostcall(CowUtil.getInfo, 'getInfo')
+    def _get_info(self, vdi_uuid, response):
         obj = json.loads(response)
 
-        vhd_info = vhdutil.VHDInfo(vdi_uuid)
-        vhd_info.sizeVirt = obj['sizeVirt']
-        vhd_info.sizePhys = obj['sizePhys']
+        image_info = CowImageInfo(vdi_uuid)
+        image_info.sizeVirt = obj['sizeVirt']
+        image_info.sizePhys = obj['sizePhys']
         if 'parentPath' in obj:
-            vhd_info.parentPath = obj['parentPath']
-            vhd_info.parentUuid = obj['parentUuid']
-        vhd_info.hidden = obj['hidden']
-        vhd_info.path = obj['path']
+            image_info.parentPath = obj['parentPath']
+            image_info.parentUuid = obj['parentUuid']
+        image_info.hidden = obj['hidden']
+        image_info.path = obj['path']
 
-        return vhd_info
+        return image_info
 
-    @linstorhostcall(vhdutil.hasParent, 'hasParent')
+    @linstorhostcall(CowUtil.hasParent, 'hasParent')
     def has_parent(self, vdi_uuid, response):
         return util.strtobool(response)
 
     def get_parent(self, vdi_uuid):
         return self._get_parent(vdi_uuid, self._extract_uuid)
 
-    @linstorhostcall(vhdutil.getParent, 'getParent')
+    @linstorhostcall(CowUtil.getParent, 'getParent')
     def _get_parent(self, vdi_uuid, response):
         return response
 
-    @linstorhostcall(vhdutil.getSizeVirt, 'getSizeVirt')
+    @linstorhostcall(CowUtil.getSizeVirt, 'getSizeVirt')
     def get_size_virt(self, vdi_uuid, response):
         return int(response)
 
-    @linstorhostcall(vhdutil.getMaxResizeSize, 'getMaxResizeSize')
+    @linstorhostcall(CowUtil.getMaxResizeSize, 'getMaxResizeSize')
     def get_max_resize_size(self, vdi_uuid, response):
         return int(response)
 
-    @linstorhostcall(vhdutil.getSizePhys, 'getSizePhys')
+    @linstorhostcall(CowUtil.getSizePhys, 'getSizePhys')
     def get_size_phys(self, vdi_uuid, response):
         return int(response)
 
-    @linstorhostcall(vhdutil.getAllocatedSize, 'getAllocatedSize')
+    @linstorhostcall(CowUtil.getAllocatedSize, 'getAllocatedSize')
     def get_allocated_size(self, vdi_uuid, response):
         return int(response)
 
-    @linstorhostcall(vhdutil.getDepth, 'getDepth')
+    @linstorhostcall(CowUtil.getDepth, 'getDepth')
     def get_depth(self, vdi_uuid, response):
         return int(response)
 
-    @linstorhostcall(vhdutil.getKeyHash, 'getKeyHash')
+    @linstorhostcall(CowUtil.getKeyHash, 'getKeyHash')
     def get_key_hash(self, vdi_uuid, response):
         return response or None
 
-    @linstorhostcall(vhdutil.getBlockBitmap, 'getBlockBitmap')
+    @linstorhostcall(CowUtil.getBlockBitmap, 'getBlockBitmap')
     def get_block_bitmap(self, vdi_uuid, response):
         return base64.b64decode(response)
 
@@ -275,7 +267,7 @@ class LinstorVhdUtil:
     def get_drbd_size(self, vdi_uuid, response):
         return int(response)
 
-    def _get_drbd_size(self, path):
+    def _get_drbd_size(self, cowutil_inst, path):
         (ret, stdout, stderr) = util.doexec(['blockdev', '--getsize64', path])
         if ret == 0:
             return int(stdout.strip())
@@ -287,31 +279,31 @@ class LinstorVhdUtil:
 
     @linstormodifier()
     def create(self, path, size, static, msize=0):
-        return self._call_local_method_or_fail(vhdutil.create, path, size, static, msize)
+        return self._call_local_method_or_fail(CowUtil.create, path, size, static, msize)
 
     @linstormodifier()
     def set_size_phys(self, path, size, debug=True):
-        return self._call_local_method_or_fail(vhdutil.setSizePhys, path, size, debug)
+        return self._call_local_method_or_fail(CowUtil.setSizePhys, path, size, debug)
 
     @linstormodifier()
     def set_parent(self, path, parentPath, parentRaw=False):
-        return self._call_local_method_or_fail(vhdutil.setParent, path, parentPath, parentRaw)
+        return self._call_local_method_or_fail(CowUtil.setParent, path, parentPath, parentRaw)
 
     @linstormodifier()
     def set_hidden(self, path, hidden=True):
-        return self._call_local_method_or_fail(vhdutil.setHidden, path, hidden)
+        return self._call_local_method_or_fail(CowUtil.setHidden, path, hidden)
 
     @linstormodifier()
     def set_key(self, path, key_hash):
-        return self._call_local_method_or_fail(vhdutil.setKey, path, key_hash)
+        return self._call_local_method_or_fail(CowUtil.setKey, path, key_hash)
 
     @linstormodifier()
     def kill_data(self, path):
-        return self._call_local_method_or_fail(vhdutil.killData, path)
+        return self._call_local_method_or_fail(CowUtil.killData, path)
 
     @linstormodifier()
     def snapshot(self, path, parent, parentRaw, msize=0, checkEmpty=True):
-        return self._call_local_method_or_fail(vhdutil.snapshot, path, parent, parentRaw, msize, checkEmpty)
+        return self._call_local_method_or_fail(CowUtil.snapshot, path, parent, parentRaw, msize, checkEmpty)
 
     def inflate(self, journaler, vdi_uuid, vdi_path, new_size, old_size):
         # Only inflate if the LINSTOR volume capacity is not enough.
@@ -336,14 +328,14 @@ class LinstorVhdUtil:
                 .format(new_size, result_size)
             )
 
-        self._zeroize(vdi_path, result_size - vhdutil.VHD_FOOTER_SIZE)
+        self._zeroize(vdi_path, result_size - self._cowutil.getFooterSize())
         self.set_size_phys(vdi_path, result_size, False)
         journaler.remove(LinstorJournaler.INFLATE, vdi_uuid)
 
     def deflate(self, vdi_path, new_size, old_size, zeroize=False):
         if zeroize:
-            assert old_size > vhdutil.VHD_FOOTER_SIZE
-            self._zeroize(vdi_path, old_size - vhdutil.VHD_FOOTER_SIZE)
+            assert old_size > self._cowutil.getFooterSize()
+            self._zeroize(vdi_path, old_size - self._cowutil.getFooterSize())
 
         new_size = LinstorVolumeManager.round_up_volume_size(new_size)
         if new_size >= old_size:
@@ -362,19 +354,19 @@ class LinstorVhdUtil:
     # --------------------------------------------------------------------------
 
     @linstormodifier()
-    def set_size_virt(self, path, size, jfile):
+    def set_size_virt(self, path, size, jFile):
         kwargs = {
             'size': size,
-            'jfile': jfile
+            'jFile': jFile
         }
-        return self._call_method(vhdutil.setSizeVirt, 'setSizeVirt', path, use_parent=False, **kwargs)
+        return self._call_method(CowUtil.setSizeVirt, 'setSizeVirt', path, use_parent=False, **kwargs)
 
     @linstormodifier()
     def set_size_virt_fast(self, path, size):
         kwargs = {
             'size': size
         }
-        return self._call_method(vhdutil.setSizeVirtFast, 'setSizeVirtFast', path, use_parent=False, **kwargs)
+        return self._call_method(CowUtil.setSizeVirtFast, 'setSizeVirtFast', path, use_parent=False, **kwargs)
 
     @linstormodifier()
     def force_parent(self, path, parentPath, parentRaw=False):
@@ -382,15 +374,15 @@ class LinstorVhdUtil:
             'parentPath': str(parentPath),
             'parentRaw': parentRaw
         }
-        return self._call_method(vhdutil.setParent, 'setParent', path, use_parent=False, **kwargs)
+        return self._call_method(CowUtil.setParent, 'setParent', path, use_parent=False, **kwargs)
 
     @linstormodifier()
     def force_coalesce(self, path):
-        return int(self._call_method(vhdutil.coalesce, 'coalesce', path, use_parent=True))
+        return int(self._call_method(CowUtil.coalesce, 'coalesce', path, use_parent=True))
 
     @linstormodifier()
     def force_repair(self, path):
-        return self._call_method(vhdutil.repair, 'repair', path, use_parent=False)
+        return self._call_method(CowUtil.repair, 'repair', path, use_parent=False)
 
     @linstormodifier()
     def force_deflate(self, path, newSize, oldSize, zeroize):
@@ -401,30 +393,27 @@ class LinstorVhdUtil:
         }
         return self._call_method('_force_deflate', 'deflate', path, use_parent=False, **kwargs)
 
-    def _force_deflate(self, path, newSize, oldSize, zeroize):
+    def _force_deflate(self, cowutil_inst, path, newSize, oldSize, zeroize):
         self.deflate(path, newSize, oldSize, zeroize)
 
     # --------------------------------------------------------------------------
-    # Static helpers.
+    # Helpers.
     # --------------------------------------------------------------------------
 
-    @classmethod
-    def compute_volume_size(cls, virtual_size, image_type):
-        if VdiType.isCowImage(image_type):
+    def compute_volume_size(self, virtual_size: int) -> int:
+        if VdiType.isCowImage(self._vdi_type):
             # All LINSTOR VDIs have the metadata area preallocated for
             # the maximum possible virtual size (for fast online VDI.resize).
-            meta_overhead = vhdutil.calcOverheadEmpty(cls.MAX_SIZE)
-            bitmap_overhead = vhdutil.calcOverheadBitmap(virtual_size)
+            meta_overhead = self._cowutil.calcOverheadEmpty(
+                max(virtual_size, self._cowutil.getDefaultPreallocationSizeVirt())
+            )
+            bitmap_overhead = self._cowutil.calcOverheadBitmap(virtual_size)
             virtual_size += meta_overhead + bitmap_overhead
         else:
-            raise Exception('Invalid image type: {}'.format(image_type))
+            raise Exception('Invalid image type: {}'.format(self._vdi_type))
 
         return LinstorVolumeManager.round_up_volume_size(virtual_size)
 
-    # --------------------------------------------------------------------------
-    # Helpers.
-    # --------------------------------------------------------------------------
-
     def _extract_uuid(self, device_path):
         # TODO: Remove new line in the vhdutil module. Not here.
         return self._linstor.get_volume_uuid_from_device_path(
@@ -433,9 +422,9 @@ class LinstorVhdUtil:
 
     def _get_readonly_host(self, vdi_uuid, device_path, node_names):
         """
-        When vhd-util is called to fetch VDI info we must find a
+        When CowUtil is called to fetch VDI info we must find a
         diskful DRBD disk to read the data. It's the goal of this function.
-        Why? Because when a VHD is open in RO mode, the LVM layer is used
+        Why? Because when a COW image is open in RO mode, the LVM layer is used
         directly to bypass DRBD verifications (we can have only one process
         that reads/writes to disk with DRBD devices).
         """
@@ -489,7 +478,7 @@ class LinstorVhdUtil:
         try:
             def local_call():
                 try:
-                    return local_method(device_path, *args, **kwargs)
+                    return local_method(self._cowutil, device_path, *args, **kwargs)
                 except util.CommandException as e:
                     if e.code == errno.EROFS or e.code == errno.EMEDIUMTYPE:
                         raise ErofsLinstorCallException(e)  # Break retry calls.
@@ -499,7 +488,7 @@ class LinstorVhdUtil:
             # Retry only locally if it's not an EROFS exception.
             return util.retry(local_call, 5, 2, exceptions=[util.CommandException])
         except util.CommandException as e:
-            util.SMlog('failed to execute locally vhd-util (sys {})'.format(e.code))
+            util.SMlog('failed to execute locally CowUtil (sys {})'.format(e.code))
             raise e
 
     def _call_local_method_or_fail(self, local_method, device_path, *args, **kwargs):
@@ -510,7 +499,7 @@ class LinstorVhdUtil:
             self._raise_openers_exception(device_path, e.cmd_err)
 
     def _call_method(self, local_method, remote_method, device_path, use_parent, *args, **kwargs):
-        # Note: `use_parent` exists to know if the VHD parent is used by the local/remote method.
+        # Note: `use_parent` exists to know if the COW image parent is used by the local/remote method.
         # Normally in case of failure, if the parent is unused we try to execute the method on
         # another host using the DRBD opener list. In the other case, if the parent is required,
         # we must check where this last one is open instead of the child.
@@ -533,7 +522,7 @@ class LinstorVhdUtil:
         except Exception as e:
             raise xs_errors.XenError(
                 'VDIUnavailable',
-                opterr='Unable to get host list to run vhd-util command `{}` (path={}): {}'
+                opterr='Unable to get host list to run CowUtil command `{}` (path={}): {}'
                 .format(remote_method, device_path, e)
             )
 
@@ -561,7 +550,7 @@ class LinstorVhdUtil:
             except Exception as e:
                 raise xs_errors.XenError(
                     'VDIUnavailable',
-                    opterr='Unable to get DRBD openers to run vhd-util command `{}` (path={}): {}'
+                    opterr='Unable to get DRBD openers to run CowUtil command `{}` (path={}): {}'
                     .format(remote_method, device_path, e)
                 )
 
@@ -583,21 +572,20 @@ class LinstorVhdUtil:
 
             if no_host_found:
                 try:
-                    return local_method(device_path, *args, **kwargs)
+                    return local_method(self._cowutil, device_path, *args, **kwargs)
                 except Exception as e:
                     self._raise_openers_exception(device_path, e)
 
             raise xs_errors.XenError(
                 'VDIUnavailable',
-                opterr='No valid host found to run vhd-util command `{}` (path=`{}`, openers=`{}`)'
+                opterr='No valid host found to run CowUtil command `{}` (path=`{}`, openers=`{}`)'
                 .format(remote_method, device_path, openers)
             )
         return util.retry(remote_call, 5, 2)
 
-    @staticmethod
-    def _zeroize(path, size):
-        if not util.zeroOut(path, size, vhdutil.VHD_FOOTER_SIZE):
+    def _zeroize(self, path, size):
+        if not util.zeroOut(path, size, self._cowutil.getFooterSize()):
             raise xs_errors.XenError(
                 'EIO',
-                opterr='Failed to zero out VHD footer {}'.format(path)
+                opterr='Failed to zero out COW image footer {}'.format(path)
             )
diff --git a/drivers/lvhd-thin b/drivers/lvhd-thin
index 694c07fb..2d66a2ba 100755
--- a/drivers/lvhd-thin
+++ b/drivers/lvhd-thin
@@ -21,8 +21,8 @@
 import sys
 import XenAPIPlugin
 sys.path.append("/opt/xensource/sm/")
+import lvmcowutil
 import util
-import lvhdutil
 from lvmcache import LVMCache
 from journaler import Journaler
 import lvutil
@@ -35,11 +35,12 @@ def attach(session, args):
         os.environ['LVM_SYSTEM_DIR'] = lvutil.MASTER_LVM_CONF
     srUuid = args["srUuid"]
     vdiUuid = args["vdiUuid"]
+    vdiType = args["vdiType"]
     vgName = "%s%s" % (VG_PREFIX, srUuid)
     lvmCache = LVMCache(vgName)
     journaler = Journaler(lvmCache)
     try:
-        lvhdutil.attachThin(journaler, srUuid, vdiUuid)
+        LvmCowUtil(getCowUtil(vdiType)).attachThin(journaler, srUuid, vdiUuid, vdiType)
         return str(True)
     except Exception as e:
         util.logException("lvhd-thin:attach %s" % e)
@@ -50,10 +51,11 @@ def detach(session, args):
         os.environ['LVM_SYSTEM_DIR'] = lvutil.MASTER_LVM_CONF
     srUuid = args["srUuid"]
     vdiUuid = args["vdiUuid"]
+    vdiType = args["vdiType"]
     vgName = "%s%s" % (VG_PREFIX, srUuid)
     lvmCache = LVMCache(vgName)
     try:
-        lvhdutil.detachThin(session, lvmCache, args["srUuid"], args["vdiUuid"])
+        LvmCowUtil(getCowUtil(vdiType)).detachThin(session, lvmCache, srUuid, vdiUuid, vdiType)
         return str(True)
     except Exception as e:
         util.logException("lvhd-thin:detach %s" % e)
diff --git a/drivers/lvhdutil.py b/drivers/lvhdutil.py
deleted file mode 100755
index 484260b8..00000000
--- a/drivers/lvhdutil.py
+++ /dev/null
@@ -1,373 +0,0 @@
-#!/usr/bin/python3
-#
-# Copyright (C) Citrix Systems Inc.
-#
-# This program is free software; you can redistribute it and/or modify
-# it under the terms of the GNU Lesser General Public License as published
-# by the Free Software Foundation; version 2.1 only.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
-# GNU Lesser General Public License for more details.
-#
-# You should have received a copy of the GNU Lesser General Public License
-# along with this program; if not, write to the Free Software Foundation, Inc.,
-# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
-
-"""Helper functions for LVHD SR. This module knows about RAW and VHD VDI's 
-that live in LV's."""
-import os
-import sys
-import time
-
-import lock
-import util
-import vhdutil
-
-from refcounter import RefCounter
-from vditype import VdiType
-
-MSIZE_MB = 2 * 1024 * 1024  # max virt size for fast resize
-MSIZE = int(MSIZE_MB * 1024 * 1024)
-
-VG_LOCATION = "/dev"
-VG_PREFIX = "VG_XenStorage-"
-LVM_SIZE_INCREMENT = 4 * 1024 * 1024
-
-LV_PREFIX = {
-        VdiType.VHD: "VHD-",
-        VdiType.RAW: "LV-",
-}
-VDI_TYPES = [VdiType.VHD, VdiType.RAW]
-
-JRN_INFLATE = "inflate"
-
-JVHD_TAG = "jvhd"
-
-LOCK_RETRY_ATTEMPTS = 20
-
-# ref counting for VDI's: we need a ref count for LV activation/deactivation
-# on the master
-NS_PREFIX_LVM = "lvm-"
-
-
-class VDIInfo:
-    uuid = ""
-    scanError = False
-    vdiType = None
-    lvName = ""
-    sizeLV = -1
-    sizeVirt = -1
-    lvActive = False
-    lvOpen = False
-    lvReadonly = False
-    hidden = False
-    parentUuid = ""
-
-    def __init__(self, uuid):
-        self.uuid = uuid
-
-
-def matchLV(lvName):
-    """given LV name, return the VDI type and the UUID, or (None, None)
-    if the name doesn't match any known type"""
-    for vdiType in VDI_TYPES:
-        prefix = LV_PREFIX[vdiType]
-        if lvName.startswith(prefix):
-            return (vdiType, lvName.replace(prefix, ""))
-    return (None, None)
-
-
-def extractUuid(path):
-    uuid = os.path.basename(path)
-    if uuid.startswith(VG_PREFIX):
-        # we are dealing with realpath
-        uuid = uuid.replace("--", "-")
-        uuid.replace(VG_PREFIX, "")
-    for t in VDI_TYPES:
-        if uuid.find(LV_PREFIX[t]) != -1:
-            uuid = uuid.split(LV_PREFIX[t])[-1]
-            uuid = uuid.strip()
-            # TODO: validate UUID format
-            return uuid
-    return None
-
-
-def calcSizeLV(sizeVHD):
-    return util.roundup(LVM_SIZE_INCREMENT, sizeVHD)
-
-
-def calcSizeVHDLV(sizeVirt):
-    # all LVHD VDIs have the metadata area preallocated for the maximum
-    # possible virtual size (for fast online VDI.resize)
-    metaOverhead = vhdutil.calcOverheadEmpty(MSIZE)
-    bitmapOverhead = vhdutil.calcOverheadBitmap(sizeVirt)
-    return calcSizeLV(sizeVirt + metaOverhead + bitmapOverhead)
-
-
-def getLVInfo(lvmCache, lvName=None):
-    """Load LV info for all LVs in the VG or an individual LV. 
-    This is a wrapper for lvutil.getLVInfo that filters out LV's that
-    are not LVHD VDI's and adds the vdi_type information"""
-    allLVs = lvmCache.getLVInfo(lvName)
-
-    lvs = dict()
-    for lvName, lv in allLVs.items():
-        vdiType, uuid = matchLV(lvName)
-        if not vdiType:
-            continue
-        lv.vdiType = vdiType
-        lvs[uuid] = lv
-    return lvs
-
-
-def getVDIInfo(lvmCache):
-    """Load VDI info (both LV and if the VDI is not raw, VHD info)"""
-    vdis = {}
-    lvs = getLVInfo(lvmCache)
-
-    haveVHDs = False
-    for uuid, lvInfo in lvs.items():
-        if VdiType.isCowImage(lvInfo.vdiType):
-            haveVHDs = True
-        vdiInfo = VDIInfo(uuid)
-        vdiInfo.vdiType = lvInfo.vdiType
-        vdiInfo.lvName = lvInfo.name
-        vdiInfo.sizeLV = lvInfo.size
-        vdiInfo.sizeVirt = lvInfo.size
-        vdiInfo.lvActive = lvInfo.active
-        vdiInfo.lvOpen = lvInfo.open
-        vdiInfo.lvReadonly = lvInfo.readonly
-        vdiInfo.hidden = lvInfo.hidden
-        vdis[uuid] = vdiInfo
-
-    if haveVHDs:
-        pattern = "%s*" % LV_PREFIX[VdiType.VHD]
-        vhds = vhdutil.getAllVHDs(pattern, extractUuid, lvmCache.vgName)
-        uuids = vdis.keys()
-        for uuid in uuids:
-            vdi = vdis[uuid]
-            if VdiType.isCowImage(vdi.vdiType):
-                if not vhds.get(uuid):
-                    lvmCache.refresh()
-                    if lvmCache.checkLV(vdi.lvName):
-                        util.SMlog("*** VHD info missing: %s" % uuid)
-                        vdis[uuid].scanError = True
-                    else:
-                        util.SMlog("LV disappeared since last scan: %s" % uuid)
-                        del vdis[uuid]
-                elif vhds[uuid].error:
-                    util.SMlog("*** vhd-scan error: %s" % uuid)
-                    vdis[uuid].scanError = True
-                else:
-                    vdis[uuid].sizeVirt = vhds[uuid].sizeVirt
-                    vdis[uuid].parentUuid = vhds[uuid].parentUuid
-                    vdis[uuid].hidden = vhds[uuid].hidden
-    return vdis
-
-
-def inflate(journaler, srUuid, vdiUuid, size):
-    """Expand a VDI LV (and its VHD) to 'size'. If the LV is already bigger
-    than that, it's a no-op. Does not change the virtual size of the VDI"""
-    lvName = LV_PREFIX[VdiType.VHD] + vdiUuid
-    vgName = VG_PREFIX + srUuid
-    path = os.path.join(VG_LOCATION, vgName, lvName)
-    lvmCache = journaler.lvmCache
-
-    currSizeLV = lvmCache.getSize(lvName)
-    newSize = calcSizeLV(size)
-    if newSize <= currSizeLV:
-        return
-    journaler.create(JRN_INFLATE, vdiUuid, str(currSizeLV))
-    util.fistpoint.activate("LVHDRT_inflate_after_create_journal", srUuid)
-    lvmCache.setSize(lvName, newSize)
-    util.fistpoint.activate("LVHDRT_inflate_after_setSize", srUuid)
-    if not util.zeroOut(path, newSize - vhdutil.VHD_FOOTER_SIZE,
-            vhdutil.VHD_FOOTER_SIZE):
-        raise Exception('failed to zero out VHD footer')
-    util.fistpoint.activate("LVHDRT_inflate_after_zeroOut", srUuid)
-    vhdutil.setSizePhys(path, newSize, False)
-    util.fistpoint.activate("LVHDRT_inflate_after_setSizePhys", srUuid)
-    journaler.remove(JRN_INFLATE, vdiUuid)
-
-
-def deflate(lvmCache, lvName, size):
-    """Shrink the LV and the VHD on it to 'size'. Does not change the 
-    virtual size of the VDI"""
-    currSizeLV = lvmCache.getSize(lvName)
-    newSize = calcSizeLV(size)
-    if newSize >= currSizeLV:
-        return
-    path = os.path.join(VG_LOCATION, lvmCache.vgName, lvName)
-    # no undo necessary if this fails at any point between now and the end
-    vhdutil.setSizePhys(path, newSize)
-    lvmCache.setSize(lvName, newSize)
-
-
-def setSizeVirt(journaler, srUuid, vdiUuid, size, jFile):
-    """When resizing the VHD virtual size, we might have to inflate the LV in
-    case the metadata size increases"""
-    lvName = LV_PREFIX[VdiType.VHD] + vdiUuid
-    vgName = VG_PREFIX + srUuid
-    path = os.path.join(VG_LOCATION, vgName, lvName)
-    inflate(journaler, srUuid, vdiUuid, calcSizeVHDLV(size))
-    vhdutil.setSizeVirt(path, size, jFile)
-
-
-def _tryAcquire(lock):
-    """We must give up if the SR is locked because it could be locked by the
-    coalesce thread trying to acquire the VDI lock we're holding, so as to
-    avoid deadlock"""
-    for i in range(LOCK_RETRY_ATTEMPTS):
-        gotLock = lock.acquireNoblock()
-        if gotLock:
-            return
-        time.sleep(1)
-    raise util.SRBusyException()
-
-
-def attachThin(journaler, srUuid, vdiUuid):
-    """Ensure that the VDI LV is expanded to the fully-allocated size"""
-    lvName = LV_PREFIX[VdiType.VHD] + vdiUuid
-    vgName = VG_PREFIX + srUuid
-    sr_lock = lock.Lock(lock.LOCK_TYPE_SR, srUuid)
-    lvmCache = journaler.lvmCache
-    _tryAcquire(sr_lock)
-    lvmCache.refresh()
-    vhdInfo = vhdutil.getVHDInfoLVM(lvName, extractUuid, vgName)
-    newSize = calcSizeVHDLV(vhdInfo.sizeVirt)
-    currSizeLV = lvmCache.getSize(lvName)
-    if newSize <= currSizeLV:
-        return
-    lvmCache.activate(NS_PREFIX_LVM + srUuid, vdiUuid, lvName, False)
-    try:
-        inflate(journaler, srUuid, vdiUuid, newSize)
-    finally:
-        lvmCache.deactivate(NS_PREFIX_LVM + srUuid, vdiUuid, lvName, False)
-    sr_lock.release()
-
-
-def detachThin(session, lvmCache, srUuid, vdiUuid):
-    """Shrink the VDI to the minimal size if no one is using it"""
-    lvName = LV_PREFIX[VdiType.VHD] + vdiUuid
-    path = os.path.join(VG_LOCATION, VG_PREFIX + srUuid, lvName)
-    sr_lock = lock.Lock(lock.LOCK_TYPE_SR, srUuid)
-    _tryAcquire(sr_lock)
-
-    vdiRef = session.xenapi.VDI.get_by_uuid(vdiUuid)
-    vbds = session.xenapi.VBD.get_all_records_where( \
-            "field \"VDI\" = \"%s\"" % vdiRef)
-    numPlugged = 0
-    for vbdRec in vbds.values():
-        if vbdRec["currently_attached"]:
-            numPlugged += 1
-
-    if numPlugged > 1:
-        raise util.SMException("%s still in use by %d others" % \
-                (vdiUuid, numPlugged - 1))
-    lvmCache.activate(NS_PREFIX_LVM + srUuid, vdiUuid, lvName, False)
-    try:
-        newSize = calcSizeLV(vhdutil.getSizePhys(path))
-        deflate(lvmCache, lvName, newSize)
-    finally:
-        lvmCache.deactivate(NS_PREFIX_LVM + srUuid, vdiUuid, lvName, False)
-    sr_lock.release()
-
-
-def createVHDJournalLV(lvmCache, jName, size):
-    """Create a LV to hold a VHD journal"""
-    lvName = "%s_%s" % (JVHD_TAG, jName)
-    lvmCache.create(lvName, size, JVHD_TAG)
-    return os.path.join(lvmCache.vgPath, lvName)
-
-
-def deleteVHDJournalLV(lvmCache, jName):
-    """Delete a VHD journal LV"""
-    lvName = "%s_%s" % (JVHD_TAG, jName)
-    lvmCache.remove(lvName)
-
-
-def getAllVHDJournals(lvmCache):
-    """Get a list of all VHD journals in VG vgName as (jName,jFile) pairs"""
-    journals = []
-    lvList = lvmCache.getTagged(JVHD_TAG)
-    for lvName in lvList:
-        jName = lvName[len(JVHD_TAG) + 1:]
-        journals.append((jName, lvName))
-    return journals
-
-
-def lvRefreshOnSlaves(session, srUuid, vgName, lvName, vdiUuid, slaves):
-    args = {"vgName": vgName,
-            "action1": "activate",
-            "uuid1": vdiUuid,
-            "ns1": NS_PREFIX_LVM + srUuid,
-            "lvName1": lvName,
-            "action2": "refresh",
-            "lvName2": lvName,
-            "action3": "deactivate",
-            "uuid3": vdiUuid,
-            "ns3": NS_PREFIX_LVM + srUuid,
-            "lvName3": lvName}
-    for slave in slaves:
-        util.SMlog("Refreshing %s on slave %s" % (lvName, slave))
-        text = session.xenapi.host.call_plugin(slave, "on-slave", "multi", args)
-        util.SMlog("call-plugin returned: '%s'" % text)
-
-
-def lvRefreshOnAllSlaves(session, srUuid, vgName, lvName, vdiUuid):
-    slaves = util.get_all_slaves(session)
-    lvRefreshOnSlaves(session, srUuid, vgName, lvName, vdiUuid, slaves)
-
-
-def setInnerNodeRefcounts(lvmCache, srUuid):
-    """[Re]calculate and set the refcounts for inner VHD nodes based on
-    refcounts of the leaf nodes. We can infer inner node refcounts on slaves
-    directly because they are in use only when VDIs are attached - as opposed
-    to the Master case where the coalesce process can also operate on inner
-    nodes.
-    Return all LVs (paths) that are active but not in use (i.e. that should
-    be deactivated)"""
-    vdiInfo = getVDIInfo(lvmCache)
-    for uuid, vdi in vdiInfo.items():
-        vdi.refcount = 0
-
-    ns = NS_PREFIX_LVM + srUuid
-    for uuid, vdi in vdiInfo.items():
-        if vdi.hidden:
-            continue  # only read leaf refcounts
-        refcount = RefCounter.check(uuid, ns)
-        assert(refcount == (0, 0) or refcount == (0, 1))
-        if refcount[1]:
-            vdi.refcount = 1
-            while vdi.parentUuid:
-                vdi = vdiInfo[vdi.parentUuid]
-                vdi.refcount += 1
-
-    pathsNotInUse = []
-    for uuid, vdi in vdiInfo.items():
-        if vdi.hidden:
-            util.SMlog("Setting refcount for %s to %d" % (uuid, vdi.refcount))
-            RefCounter.set(uuid, vdi.refcount, 0, ns)
-        if vdi.refcount == 0 and vdi.lvActive:
-            path = os.path.join("/dev", lvmCache.vgName, vdi.lvName)
-            pathsNotInUse.append(path)
-
-    return pathsNotInUse
-
-if __name__ == "__main__":
-    # used by the master changeover script
-    cmd = sys.argv[1]
-    if cmd == "fixrefcounts":
-        from lvmcache import LVMCache
-        srUuid = sys.argv[2]
-        try:
-            vgName = VG_PREFIX + srUuid
-            lvmCache = LVMCache(vgName)
-            setInnerNodeRefcounts(lvmCache, srUuid)
-        except:
-            util.logException("setInnerNodeRefcounts")
-    else:
-        util.SMlog("Invalid usage")
-        print("Usage: %s fixrefcounts <sr_uuid>" % sys.argv[0])
diff --git a/drivers/lvmanager.py b/drivers/lvmanager.py
index 86f25b0b..c49a5d8c 100644
--- a/drivers/lvmanager.py
+++ b/drivers/lvmanager.py
@@ -18,7 +18,6 @@
 
 import time
 import util
-import lvhdutil
 
 from constants import NS_PREFIX_LVM
 
diff --git a/drivers/lvmcache.py b/drivers/lvmcache.py
index 6731b210..2148e311 100644
--- a/drivers/lvmcache.py
+++ b/drivers/lvmcache.py
@@ -16,10 +16,9 @@
 # LVM cache (for minimizing the number of lvs commands)
 #
 
+import lvutil
 import os
 import util
-import lvutil
-import lvhdutil
 
 from constants import NS_PREFIX_LVM
 from lock import Lock
@@ -29,15 +28,17 @@ from refcounter import RefCounter
 class LVInfo:
     def __init__(self, name):
         self.name = name
+        self.vdiType = ''
         self.size = 0
         self.active = False
         self.open = 0
         self.readonly = False
+        self.hidden = False
         self.tags = []
 
     def toString(self):
-        return "%s, size=%d, active=%s, open=%s, ro=%s, tags=%s" % \
-                (self.name, self.size, self.active, self.open, self.readonly, \
+        return "%s, type=%s, size=%d, active=%s, open=%s, ro=%s, hidden=%s, tags=%s" % \
+                (self.name, self.vdiType, self.size, self.active, self.open, self.readonly, self.hidden, \
                 self.tags)
 
 
diff --git a/drivers/lvmcowutil.py b/drivers/lvmcowutil.py
new file mode 100755
index 00000000..cafe072a
--- /dev/null
+++ b/drivers/lvmcowutil.py
@@ -0,0 +1,417 @@
+#!/usr/bin/python3
+#
+# Copyright (C) Citrix Systems Inc.
+#
+# This program is free software; you can redistribute it and/or modify
+# it under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation; version 2.1 only.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+# GNU Lesser General Public License for more details.
+#
+# You should have received a copy of the GNU Lesser General Public License
+# along with this program; if not, write to the Free Software Foundation, Inc.,
+# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
+
+"""
+Helper functions for LVMSR. This module knows about RAW and VHD VDI's that live in LV's.
+"""
+
+from sm_typing import Dict, Final, List, Optional, Tuple, cast
+
+import os
+import sys
+import time
+
+import lock
+import util
+import XenAPI # pylint: disable=import-error
+
+from constants import NS_PREFIX_LVM, VG_LOCATION, VG_PREFIX
+from cowutil import CowImageInfo, CowUtil, getCowUtil
+from journaler import Journaler
+from lvmcache import LVInfo, LVMCache
+from lvutil import calcSizeLV
+from refcounter import RefCounter
+from vditype import VdiType, VDI_COW_TYPES
+
+# ------------------------------------------------------------------------------
+
+LOCK_RETRY_ATTEMPTS: Final = 20
+
+LV_PREFIX: Final = {
+    VdiType.RAW: "LV-",
+    VdiType.VHD: "VHD-"
+}
+
+LV_PREFIX_TO_VDI_TYPE: Final = {v: k for k, v in LV_PREFIX.items()}
+
+# ------------------------------------------------------------------------------
+
+class VDIInfo:
+    uuid = ""
+    scanError = False
+    vdiType = None
+    lvName = ""
+    sizeLV = -1
+    sizeVirt = -1
+    lvActive = False
+    lvOpen = False
+    lvReadonly = False
+    hidden = False
+    parentUuid = ""
+    refcount = 0
+
+    def __init__(self, uuid: str):
+        self.uuid = uuid
+
+# ------------------------------------------------------------------------------
+
+class LvmCowUtil(object):
+    JOURNAL_INFLATE: Final = "inflate"
+    JOURNAL_RESIZE_TAG: Final = "jvhd"
+
+    def __init__(self, cowutil: CowUtil):
+        self.cowutil = cowutil
+
+    def calcVolumeSize(self, sizeVirt: int) -> int:
+        # all LVM COW VDIs have the metadata area preallocated for the maximum
+        # possible virtual size in the VHD case (for fast online VDI.resize)
+        metaOverhead = self.cowutil.calcOverheadEmpty(
+            max(sizeVirt, self.cowutil.getDefaultPreallocationSizeVirt())
+        )
+        bitmapOverhead = self.cowutil.calcOverheadBitmap(sizeVirt)
+        return calcSizeLV(sizeVirt + metaOverhead + bitmapOverhead)
+
+    def createResizeJournal(self, lvmCache: LVMCache, jName: str) -> str:
+        """
+        Create a LV to hold a VDI resize journal.
+        """
+        size = self.cowutil.getResizeJournalSize()
+        if size <= 0:
+            return ''
+        lvName = "%s_%s" % (self.JOURNAL_RESIZE_TAG, jName)
+        lvmCache.create(lvName, size, self.JOURNAL_RESIZE_TAG)
+        return os.path.join(lvmCache.vgPath, lvName)
+
+    def destroyResizeJournal(self, lvmCache: LVMCache, jName: str) -> None:
+        """
+        Destroy a VDI resize journal.
+        """
+        if jName:
+            lvName = "%s_%s" % (self.JOURNAL_RESIZE_TAG, jName)
+            lvmCache.remove(lvName)
+
+    @classmethod
+    def getAllResizeJournals(cls, lvmCache: LVMCache) -> List[Tuple[str, str]]:
+        """
+        Get a list of all resize journals in VG vgName as (jName, sjFile) pairs.
+        """
+        journals = []
+        lvList = lvmCache.getTagged(cls.JOURNAL_RESIZE_TAG)
+        for lvName in lvList:
+            jName = lvName[len(cls.JOURNAL_RESIZE_TAG) + 1:]
+            journals.append((jName, lvName))
+        return journals
+
+    def setSizeVirt(
+        self, journaler: Journaler, srUuid: str, vdiUuid: str, vdiType: str, size: int, jFile : str
+    ) -> None:
+        """
+        When resizing the image virtual size, we might have to inflate the LV in
+        case the metadata size increases.
+        """
+        lvName = LV_PREFIX[vdiType] + vdiUuid
+        vgName = VG_PREFIX + srUuid
+        path = os.path.join(VG_LOCATION, vgName, lvName)
+        self.inflate(journaler, srUuid, vdiUuid, vdiType, self.calcVolumeSize(size))
+        self.cowutil.setSizeVirt(path, size, jFile)
+
+    def inflate(self, journaler: Journaler, srUuid: str, vdiUuid: str, vdiType: str, size: int) -> None:
+        """
+        Expand a VDI LV (and its image) to 'size'. If the LV is already bigger
+        than that, it's a no-op. Does not change the virtual size of the VDI.
+        """
+        lvName = LV_PREFIX[vdiType] + vdiUuid
+        vgName = VG_PREFIX + srUuid
+        path = os.path.join(VG_LOCATION, vgName, lvName)
+        lvmCache = journaler.lvmCache
+
+        currSizeLV = lvmCache.getSize(lvName)
+        newSize = calcSizeLV(size)
+        if newSize <= currSizeLV:
+            return
+        journaler.create(self.JOURNAL_INFLATE, vdiUuid, str(currSizeLV))
+        util.fistpoint.activate("LVHDRT_inflate_after_create_journal", srUuid)
+        lvmCache.setSize(lvName, newSize)
+        util.fistpoint.activate("LVHDRT_inflate_after_setSize", srUuid)
+        footer_size = self.cowutil.getFooterSize()
+        if not util.zeroOut(path, newSize - footer_size, footer_size):
+            raise Exception('failed to zero out image footer')
+        util.fistpoint.activate("LVHDRT_inflate_after_zeroOut", srUuid)
+        self.cowutil.setSizePhys(path, newSize, False)
+        util.fistpoint.activate("LVHDRT_inflate_after_setSizePhys", srUuid)
+        journaler.remove(self.JOURNAL_INFLATE, vdiUuid)
+
+    def deflate(self, lvmCache: LVMCache, lvName: str, size: int) -> None:
+        """
+        Shrink the LV and the image on it to 'size'. Does not change the
+        virtual size of the VDI.
+        """
+        currSizeLV = lvmCache.getSize(lvName)
+        newSize = calcSizeLV(size)
+
+        if newSize >= currSizeLV:
+            return
+        path = os.path.join(VG_LOCATION, lvmCache.vgName, lvName)
+        # no undo necessary if this fails at any point between now and the end
+        self.cowutil.setSizePhys(path, newSize)
+        lvmCache.setSize(lvName, newSize)
+
+    def attachThin(self, journaler: Journaler, srUuid: str, vdiUuid: str, vdiType: str) -> None:
+        """
+        Ensure that the VDI LV is expanded to the fully-allocated size.
+        """
+        lvName = LV_PREFIX[vdiType] + vdiUuid
+        vgName = VG_PREFIX + srUuid
+        sr_lock = lock.Lock(lock.LOCK_TYPE_SR, srUuid)
+        lvmCache = journaler.lvmCache
+        self._tryAcquire(sr_lock)
+        lvmCache.refresh()
+        info = self.cowutil.getInfoFromLVM(lvName, self.extractUuid, vgName)
+        if not info:
+            raise Exception(f"unable to get LVM info from {vdiUuid}")
+        newSize = self.calcVolumeSize(info.sizeVirt)
+        currSizeLV = lvmCache.getSize(lvName)
+        if newSize <= currSizeLV:
+            return
+        lvmCache.activate(NS_PREFIX_LVM + srUuid, vdiUuid, lvName, False)
+        try:
+            self.inflate(journaler, srUuid, vdiUuid, vdiType, newSize)
+        finally:
+            lvmCache.deactivate(NS_PREFIX_LVM + srUuid, vdiUuid, lvName, False)
+        sr_lock.release()
+
+    def detachThin(self, session: XenAPI.Session, lvmCache: LVMCache, srUuid: str, vdiUuid: str, vdiType: str) -> None:
+        """
+        Shrink the VDI to the minimal size if no one is using it.
+        """
+        lvName = LV_PREFIX[vdiType] + vdiUuid
+        path = os.path.join(VG_LOCATION, VG_PREFIX + srUuid, lvName)
+        sr_lock = lock.Lock(lock.LOCK_TYPE_SR, srUuid)
+        self._tryAcquire(sr_lock)
+
+        vdiRef = session.xenapi.VDI.get_by_uuid(vdiUuid)
+        vbds = session.xenapi.VBD.get_all_records_where( \
+                "field \"VDI\" = \"%s\"" % vdiRef)
+        numPlugged = 0
+        for vbdRec in vbds.values():
+            if vbdRec["currently_attached"]:
+                numPlugged += 1
+
+        if numPlugged > 1:
+            raise util.SMException("%s still in use by %d others" % \
+                    (vdiUuid, numPlugged - 1))
+        lvmCache.activate(NS_PREFIX_LVM + srUuid, vdiUuid, lvName, False)
+        try:
+            newSize = calcSizeLV(self.cowutil.getSizePhys(path))
+            self.deflate(lvmCache, lvName, newSize)
+        finally:
+            lvmCache.deactivate(NS_PREFIX_LVM + srUuid, vdiUuid, lvName, False)
+        sr_lock.release()
+
+    @staticmethod
+    def extractUuid(path: str) -> str:
+        uuid = os.path.basename(path)
+        if uuid.startswith(VG_PREFIX):
+            # we are dealing with realpath
+            uuid = uuid.replace("--", "-")
+            uuid.replace(VG_PREFIX, "")
+        for prefix in LV_PREFIX.values():
+            if uuid.find(prefix) != -1:
+                uuid = uuid.split(prefix)[-1]
+                uuid = uuid.strip()
+                # TODO: validate UUID format
+                return uuid
+        return ''
+
+    @staticmethod
+    def matchVolume(lvName: str) -> Tuple[Optional[str], Optional[str]]:
+        """
+        Given LV name, return the VDI type and the UUID, or (None, None)
+        if the name doesn't match any known type.
+        """
+        for vdiType, prefix in LV_PREFIX.items():
+            if lvName.startswith(prefix):
+                return (vdiType, lvName.replace(prefix, ""))
+        return (None, None)
+
+    @classmethod
+    def getVolumeInfo(cls, lvmCache: LVMCache, lvName: Optional[str] = None) -> Dict[str, LVInfo]:
+        """
+        Load LV info for all LVs in the VG or an individual LV.
+        This is a wrapper for lvutil.getLVInfo that filters out LV's that
+        are not LVM COW VDI's and adds the vdi_type information.
+        """
+        allLVs = lvmCache.getLVInfo(lvName)
+
+        lvs: Dict[str, LVInfo] = dict()
+        for name, lv in allLVs.items():
+            vdiType, uuid = cls.matchVolume(name)
+            if not vdiType:
+                continue
+            lv.vdiType = vdiType
+            lvs[cast(str, uuid)] = lv
+        return lvs
+
+    @classmethod
+    def getVDIInfo(cls, lvmCache: LVMCache) -> Dict[str, VDIInfo]:
+        """
+        Load VDI info (both LV and if the VDI is not raw, VHD info).
+        """
+        vdis: Dict[str, VDIInfo] = {}
+        lvs = cls.getVolumeInfo(lvmCache)
+
+        hasCowVdis = False
+        for uuid, lvInfo in lvs.items():
+            if VdiType.isCowImage(lvInfo.vdiType):
+                hasCowVdis = True
+            vdiInfo = VDIInfo(uuid)
+            vdiInfo.vdiType = lvInfo.vdiType
+            vdiInfo.lvName = lvInfo.name
+            vdiInfo.sizeLV = lvInfo.size
+            vdiInfo.sizeVirt = lvInfo.size
+            vdiInfo.lvActive = lvInfo.active
+            vdiInfo.lvOpen = lvInfo.open
+            vdiInfo.lvReadonly = lvInfo.readonly
+            vdiInfo.hidden = lvInfo.hidden
+            vdis[uuid] = vdiInfo
+
+        if not hasCowVdis:
+            return vdis
+
+        scan_result: Dict[str, CowImageInfo] = {}
+        for vdi_type in VDI_COW_TYPES:
+            pattern = "%s*" % LV_PREFIX[vdi_type]
+            scan_result.update(getCowUtil(vdi_type).getAllInfoFromVG(pattern, cls.extractUuid, lvmCache.vgName))
+
+        uuids = vdis.keys()
+        for uuid in uuids:
+            vdi = vdis[uuid]
+            if VdiType.isCowImage(vdi.vdiType):
+                if not scan_result.get(uuid):
+                    lvmCache.refresh()
+                    if lvmCache.checkLV(vdi.lvName):
+                        util.SMlog("*** COW image info missing: %s" % uuid)
+                        vdis[uuid].scanError = True
+                    else:
+                        util.SMlog("LV disappeared since last scan: %s" % uuid)
+                        del vdis[uuid]
+                elif scan_result[uuid].error:
+                    util.SMlog("*** cow-scan error: %s" % uuid)
+                    vdis[uuid].scanError = True
+                else:
+                    vdis[uuid].sizeVirt = scan_result[uuid].sizeVirt
+                    vdis[uuid].parentUuid = scan_result[uuid].parentUuid
+                    vdis[uuid].hidden = scan_result[uuid].hidden
+        return vdis
+
+    @staticmethod
+    def refreshVolumeOnSlaves(
+        session: XenAPI.Session, srUuid: str, vgName: str, lvName: str, vdiUuid: str, slaves: List[str]
+    ) -> None:
+        args = {
+            "vgName": vgName,
+            "action1": "activate",
+            "uuid1": vdiUuid,
+            "ns1": NS_PREFIX_LVM + srUuid,
+            "lvName1": lvName,
+            "action2": "refresh",
+            "lvName2": lvName,
+            "action3": "deactivate",
+            "uuid3": vdiUuid,
+            "ns3": NS_PREFIX_LVM + srUuid,
+            "lvName3": lvName
+        }
+        for slave in slaves:
+            util.SMlog("Refreshing %s on slave %s" % (lvName, slave))
+            text = session.xenapi.host.call_plugin(slave, "on-slave", "multi", args)
+            util.SMlog("call-plugin returned: '%s'" % text)
+
+    @classmethod
+    def refreshVolumeOnAllSlaves(
+        cls, session: XenAPI.Session, srUuid: str, vgName: str, lvName: str, vdiUuid: str
+    ) -> None:
+        cls.refreshVolumeOnSlaves(session, srUuid, vgName, lvName, vdiUuid, util.get_all_slaves(session))
+
+    @staticmethod
+    def _tryAcquire(lock):
+        """
+        We must give up if the SR is locked because it could be locked by the
+        coalesce thread trying to acquire the VDI lock we're holding, so as to
+        avoid deadlock.
+        """
+        for i in range(LOCK_RETRY_ATTEMPTS):
+            gotLock = lock.acquireNoblock()
+            if gotLock:
+                return
+            time.sleep(1)
+        raise util.SRBusyException()
+
+# ------------------------------------------------------------------------------
+
+def setInnerNodeRefcounts(lvmCache: LVMCache, srUuid: str) -> List[str]:
+    """
+    [Re]calculate and set the refcounts for inner image nodes based on
+    refcounts of the leaf nodes. We can infer inner node refcounts on slaves
+    directly because they are in use only when VDIs are attached - as opposed
+    to the Master case where the coalesce process can also operate on inner
+    nodes.
+    Return all LVs (paths) that are active but not in use (i.e. that should
+    be deactivated).
+    """
+    vdiInfo = LvmCowUtil.getVDIInfo(lvmCache)
+    for uuid, vdi in vdiInfo.items():
+        vdi.refcount = 0
+
+    ns = NS_PREFIX_LVM + srUuid
+    for uuid, vdi in vdiInfo.items():
+        if vdi.hidden:
+            continue  # only read leaf refcounts
+        refcount = RefCounter.check(uuid, ns)
+        assert(refcount == (0, 0) or refcount == (0, 1))
+        if refcount[1]:
+            vdi.refcount = 1
+            while vdi.parentUuid:
+                vdi = vdiInfo[vdi.parentUuid]
+                vdi.refcount += 1
+
+    pathsNotInUse = []
+    for uuid, vdi in vdiInfo.items():
+        if vdi.hidden:
+            util.SMlog("Setting refcount for %s to %d" % (uuid, vdi.refcount))
+            RefCounter.set(uuid, vdi.refcount, 0, ns)
+        if vdi.refcount == 0 and vdi.lvActive:
+            path = os.path.join("/dev", lvmCache.vgName, vdi.lvName)
+            pathsNotInUse.append(path)
+
+    return pathsNotInUse
+
+# ------------------------------------------------------------------------------
+
+if __name__ == "__main__":
+    # used by the master changeover script
+    cmd = sys.argv[1]
+    if cmd == "fixrefcounts":
+        srUuid = sys.argv[2]
+        try:
+            vgName = VG_PREFIX + srUuid
+            lvmCache = LVMCache(vgName)
+            setInnerNodeRefcounts(lvmCache, srUuid)
+        except:
+            util.logException("setInnerNodeRefcounts")
+    else:
+        util.SMlog("Invalid usage")
+        print("Usage: %s fixrefcounts <sr_uuid>" % sys.argv[0])
diff --git a/drivers/lvutil.py b/drivers/lvutil.py
index 5babe71a..53e729d9 100755
--- a/drivers/lvutil.py
+++ b/drivers/lvutil.py
@@ -114,6 +114,9 @@ LVM_RETRY_ERRORS = [
     "Incorrect checksum in metadata area header"
 ]
 
+def calcSizeLV(size: int) -> int:
+    return util.roundup(LVM_SIZE_INCREMENT, size)
+
 
 def lvmretry(func):
     def check_exception(exception):
diff --git a/drivers/tapdisk-pause b/drivers/tapdisk-pause
index c63359fb..92244beb 100755
--- a/drivers/tapdisk-pause
+++ b/drivers/tapdisk-pause
@@ -2,13 +2,13 @@
 #
 # Copyright (C) Citrix Systems Inc.
 #
-# This program is free software; you can redistribute it and/or modify 
-# it under the terms of the GNU Lesser General Public License as published 
+# This program is free software; you can redistribute it and/or modify
+# it under the terms of the GNU Lesser General Public License as published
 # by the Free Software Foundation; version 2.1 only.
 #
-# This program is distributed in the hope that it will be useful, 
-# but WITHOUT ANY WARRANTY; without even the implied warranty of 
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the 
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 # GNU Lesser General Public License for more details.
 #
 # You should have received a copy of the GNU Lesser General Public License
@@ -25,15 +25,15 @@ import blktap2, util
 from lock import Lock
 import xs_errors
 import XenAPI
-import lvhdutil
-import vhdutil
 import lvmcache
 
 from constants import NS_PREFIX_LVM, VG_PREFIX
+from cowutil import getCowUtil
+from lvmcowutil import LV_PREFIX, LV_PREFIX_TO_VDI_TYPE
 from vditype import VdiType
 
 try:
-    from linstorvhdutil import LinstorVhdUtil
+    from linstorcowutil import LinstorCowUtil
     from linstorvolumemanager import get_controller_uri, LinstorVolumeManager
     LINSTOR_AVAILABLE = True
 except ImportError:
@@ -90,13 +90,13 @@ def tapPause(session, args):
 def tapUnpause(session, args):
     tap = Tapdisk(session, args)
     return tap.Unpause()
-    
+
 def tapRefresh(session, args):
     tap = Tapdisk(session, args)
     if tap.Pause() != "True":
         return str(False)
     return tap.Unpause()
-    
+
 
 class Tapdisk:
     def __init__(self, session, args):
@@ -126,20 +126,19 @@ class Tapdisk:
             realpath = os.readlink(self.phypath)
         except OSError as e:
             util.SMlog("Phypath %s does not exist" % self.phypath)
-            return            
+            return
         util.SMlog("Realpath: %s" % realpath)
         if realpath.startswith("/dev/VG_XenStorage-") and \
                 not os.path.exists(realpath):
             util.SMlog("Path inconsistent")
             pfx = "/dev/VG_XenStorage-%s/" % self.sr_uuid
-            for ty in ["LV","VHD"]:
-                p = pfx + ty + "-" + self.vdi_uuid
+            for ty in LV_PREFIX.values():
+                p = pfx + ty + self.vdi_uuid
                 util.SMlog("Testing path: %s" % p)
                 if os.path.exists(p):
                     _mkphylink(self.sr_uuid, self.vdi_uuid, p)
                     self.realpath = p
-                    if ty == "LV": self.vdi_type = VdiType.RAW
-                    else: self.vdi_type = VdiType.VHD
+                    self.vdi_type = LV_PREFIX_TO_VDI_TYPE[ty]
         elif realpath.startswith('/dev/drbd/by-res/xcp-volume-'):
             if not LINSTOR_AVAILABLE:
                 raise util.SMException(
@@ -171,7 +170,7 @@ class Tapdisk:
                 group_name,
                 logger=util.SMlog
             )
-            device_path = LinstorVhdUtil(session, linstor).create_chain_paths(self.vdi_uuid)
+            device_path = LinstorCowUtil(session, linstor, cowutil).create_chain_paths(self.vdi_uuid)
 
             if realpath != device_path:
                 util.SMlog(
@@ -205,25 +204,26 @@ class Tapdisk:
             util.SMlog("No %s: nothing to unpause" % self.path)
             return str(True)
         self._pathRefresh()
-        self.major, self.minor = _getDevMajor_minor(self.path)    
+        self.major, self.minor = _getDevMajor_minor(self.path)
         if self.major != blktap2.Tapdisk.major():
             util.SMlog("Non-tap major number: %d" % self.major)
             return str(False)
+
+        import VDI
+        vdi = VDI.VDI.from_uuid(self.session, self.vdi_uuid)
+
         if self.activate_parents:
             util.SMlog("Activating parents of %s" % self.vdi_uuid)
             vg_name = VG_PREFIX + self.sr_uuid
             ns = NS_PREFIX_LVM + self.sr_uuid
             lvm_cache = lvmcache.LVMCache(vg_name)
-            lv_name = lvhdutil.LV_PREFIX[VdiType.VHD] + self.vdi_uuid
-            vdi_list = vhdutil.getParentChain(lv_name,
-                    lvhdutil.extractUuid, vg_name)
+            lv_name = LV_PREFIX[vdi.vdi_type] + self.vdi_uuid
+            vdi_list = getCowUtil(vdi.vdi_type).getParentChain(lv_name, LvmCowUtil.extractUuid, vg_name)
             for uuid, lv_name in vdi_list.items():
                 if uuid == self.vdi_uuid:
                     continue
                 lvm_cache.activate(ns, uuid, lv_name, False)
 
-        import VDI
-        vdi = VDI.VDI.from_uuid(self.session, self.vdi_uuid)
         # Check if CBT is enabled on disk we are about to unpause
         if vdi._get_blocktracking_status():
             logname = vdi._get_cbt_logname(self.vdi_uuid)
diff --git a/drivers/trim_util.py b/drivers/trim_util.py
index dc8b087e..1aa73117 100755
--- a/drivers/trim_util.py
+++ b/drivers/trim_util.py
@@ -21,8 +21,6 @@ import os
 import time
 import util
 import lock
-import lvhdutil
-import vhdutil
 import lvutil
 
 from constants import VG_LOCATION, VG_PREFIX
diff --git a/drivers/vditype.py b/drivers/vditype.py
index 159f6c2b..c43b26b2 100644
--- a/drivers/vditype.py
+++ b/drivers/vditype.py
@@ -23,10 +23,10 @@ class VdiType(object):
     ISO = "iso"
     FILE = "file"
     CBTLOG = "cbtlog"
-    
+
     @classmethod
     def isCowImage(cls, vdi_type) -> bool:
-        return vdi_type in (cls.VHD)
+        return vdi_type in VDI_COW_TYPES
 
 # TODO: Use StrEnum in python 3.11.
 class VdiTypeExtension(object):
@@ -36,6 +36,8 @@ class VdiTypeExtension(object):
     FILE = ".file"
     CBTLOG = ".cbtlog"
 
+VDI_COW_TYPES: Final = (VdiType.VHD, )
+
 VDI_TYPE_TO_EXTENSION: Final = {
     VdiType.RAW: VdiTypeExtension.RAW,
     VdiType.VHD: VdiTypeExtension.VHD,
diff --git a/drivers/verifyVHDsOnSR.py b/drivers/verifyVHDsOnSR.py
index 334e20a8..d7d5a7fa 100755
--- a/drivers/verifyVHDsOnSR.py
+++ b/drivers/verifyVHDsOnSR.py
@@ -24,13 +24,13 @@ import os
 import sys
 import util
 import lvutil
-import lvhdutil
-import vhdutil
 
 import VDI
 
 from constants import NS_PREFIX_LVM, VG_LOCATION, VG_PREFIX
+from cowutil import getCowUtil
 from lock import Lock
+from lvmcowutil import LV_PREFIX, LvmCowUtil
 from refcounter import RefCounter
 from vditype import VdiType
 
@@ -43,9 +43,9 @@ def activateVdiChainAndCheck(vhd_info, vg_name):
     global VHDs_passed
     global VHDs_failed
     activated_list = []
-    vhd_path = os.path.join(lvhdutil.VG_LOCATION, vg_name, vhd_info.path)
+    vhd_path = os.path.join(VG_LOCATION, vg_name, vhd_info.path)
     if not activateVdi(
-                       vg_name.lstrip(lvhdutil.VG_PREFIX),
+                       vg_name.lstrip(VG_PREFIX),
                        vhd_info.uuid,
                        vhd_path):
         # If activation fails, do not run check, also no point on running
@@ -55,8 +55,11 @@ def activateVdiChainAndCheck(vhd_info, vg_name):
         return activated_list
 
     activated_list.append([vhd_info.uuid, vhd_path])
+
+    cowutil = None # TODO
+
     # Do a vhdutil check with -i option, to ignore error in primary
-    if not vhdutil.check(vhd_path, True):
+    if cowutil.check(vhd_path, True) != cowutil.CheckResult.Success:
         util.SMlog("VHD check for %s failed, continuing with the rest!" % vg_name)
         VHDs_failed += 1
     else:
@@ -70,7 +73,7 @@ def activateVdiChainAndCheck(vhd_info, vg_name):
 
 
 def activateVdi(sr_uuid, vdi_uuid, vhd_path):
-    name_space = lvhdutil.NS_PREFIX_LVM + sr_uuid
+    name_space = NS_PREFIX_LVM + sr_uuid
     lock = Lock(vdi_uuid, name_space)
     lock.acquire()
     try:
@@ -90,7 +93,7 @@ def activateVdi(sr_uuid, vdi_uuid, vhd_path):
 
 
 def deactivateVdi(sr_uuid, vdi_uuid, vhd_path):
-    name_space = lvhdutil.NS_PREFIX_LVM + sr_uuid
+    name_space = NS_PREFIX_LVM + sr_uuid
     lock = Lock(vdi_uuid, name_space)
     lock.acquire()
     try:
@@ -112,11 +115,12 @@ def checkAllVHD(sr_uuid):
     vhd_trees = []
     VHDs_total = 0
 
-    vg_name = lvhdutil.VG_PREFIX + sr_uuid
-    pattern = "%s*" % lvhdutil.LV_PREFIX[VdiType.VHD]
+    vg_name = VG_PREFIX + sr_uuid
+    vdi_type = VdiType.VHD
+    pattern = "%s*" % LV_PREFIX[vdi_type]
 
     # Do a vhd scan and gets all the VHDs
-    vhds = vhdutil.getAllVHDs(pattern, lvhdutil.extractUuid, vg_name)
+    vhds = getCowUtil(vdi_type).getAllInfoFromVG(pattern, LvmCowUtil.extractUuid, vg_name)
     VHDs_total = len(vhds)
 
     # Build VHD chain, that way it will be easier to activate all the VHDs
diff --git a/drivers/vhdutil.py b/drivers/vhdutil.py
index 5484ad2e..f0bfe22a 100755
--- a/drivers/vhdutil.py
+++ b/drivers/vhdutil.py
@@ -16,425 +16,470 @@
 # Helper functions pertaining to VHD operations
 #
 
-import os
-import util
-import errno
-import zlib
-import re
-import xs_errors
-import time
-from vditype import VdiType
-
-MIN_VHD_SIZE = 2 * 1024 * 1024
-MAX_VHD_SIZE = 2040 * 1024 * 1024 * 1024
-MAX_VHD_JOURNAL_SIZE = 6 * 1024 * 1024  # 2MB VHD block size, max 2TB VHD size
-MAX_CHAIN_SIZE = 30  # max VHD parent chain size
-VHD_UTIL = "/usr/bin/vhd-util"
-OPT_LOG_ERR = "--debug"
-VHD_BLOCK_SIZE = 2 * 1024 * 1024
-VHD_FOOTER_SIZE = 512
-
-# lock to lock the entire SR for short ops
-LOCK_TYPE_SR = "sr"
-
-
-class VHDInfo:
-    uuid = ""
-    path = ""
-    sizeVirt = -1
-    sizePhys = -1
-    sizeAllocated = -1
-    hidden = False
-    parentUuid = ""
-    parentPath = ""
-    error = 0
-
-    def __init__(self, uuid):
-        self.uuid = uuid
-
-
-def calcOverheadEmpty(virtual_size):
-    """Calculate the VHD space overhead (metadata size) for an empty VDI of
-    size virtual_size"""
-    overhead = 0
-    size_mb = virtual_size // (1024 * 1024)
-
-    # Footer + footer copy + header + possible CoW parent locator fields
-    overhead = 3 * 1024
-
-    # BAT 4 Bytes per block segment
-    overhead += (size_mb // 2) * 4
-    overhead = util.roundup(512, overhead)
-
-    # BATMAP 1 bit per block segment
-    overhead += (size_mb // 2) // 8
-    overhead = util.roundup(4096, overhead)
-
-    return overhead
-
-
-def calcOverheadBitmap(virtual_size):
-    num_blocks = virtual_size // VHD_BLOCK_SIZE
-    if virtual_size % VHD_BLOCK_SIZE:
-        num_blocks += 1
-    return num_blocks * 4096
-
-
-def ioretry(cmd, text=True):
-    return util.ioretry(lambda: util.pread2(cmd, text=text),
-                        errlist=[errno.EIO, errno.EAGAIN])
-
-
-def convertAllocatedSizeToBytes(size):
-    # Assume we have standard 2MB allocation blocks
-    return size * 2 * 1024 * 1024
-
-
-def getVHDInfo(path, extractUuidFunction, includeParent=True, resolveParent=True):
-    """Get the VHD info. The parent info may optionally be omitted: vhd-util
-    tries to verify the parent by opening it, which results in error if the VHD
-    resides on an inactive LV"""
-    opts = "-vsaf"
-    if includeParent:
-        opts += "p"
-        if not resolveParent:
-            opts += "u"
-
-    cmd = [VHD_UTIL, "query", OPT_LOG_ERR, opts, "-n", path]
-    ret = ioretry(cmd)
-    fields = ret.strip().split('\n')
-    uuid = extractUuidFunction(path)
-    vhdInfo = VHDInfo(uuid)
-    vhdInfo.sizeVirt = int(fields[0]) * 1024 * 1024
-    vhdInfo.sizePhys = int(fields[1])
-    nextIndex = 2
-    if includeParent:
-        if fields[nextIndex].find("no parent") == -1:
-            vhdInfo.parentPath = fields[nextIndex]
-            vhdInfo.parentUuid = extractUuidFunction(fields[nextIndex])
-        nextIndex += 1
-    vhdInfo.hidden = int(fields[nextIndex].replace("hidden: ", ""))
-    vhdInfo.sizeAllocated = convertAllocatedSizeToBytes(int(fields[nextIndex+1]))
-    vhdInfo.path = path
-    return vhdInfo
-
-
-def getVHDInfoLVM(lvName, extractUuidFunction, vgName):
-    """Get the VHD info. This function does not require the container LV to be
-    active, but uses lvs & vgs"""
-    vhdInfo = None
-    cmd = [VHD_UTIL, "scan", "-f", "-l", vgName, "-m", lvName]
-    ret = ioretry(cmd)
-    return _parseVHDInfo(ret, extractUuidFunction)
-
-
-def getAllVHDs(pattern, extractUuidFunction, vgName=None, \
-        parentsOnly=False, exitOnError=False):
-    vhds = dict()
-    cmd = [VHD_UTIL, "scan", "-f", "-m", pattern]
-    if vgName:
-        cmd.append("-l")
-        cmd.append(vgName)
-    if parentsOnly:
-        cmd.append("-a")
-    try:
-        ret = ioretry(cmd)
-    except Exception as e:
-        util.SMlog("WARN: vhd scan failed: output: %s" % e)
-        ret = ioretry(cmd + ["-c"])
-        util.SMlog("WARN: vhd scan with NOFAIL flag, output: %s" % ret)
-    for line in ret.split('\n'):
-        if len(line.strip()) == 0:
-            continue
-        vhdInfo = _parseVHDInfo(line, extractUuidFunction)
-        if vhdInfo:
-            if vhdInfo.error != 0 and exitOnError:
-                # Just return an empty dict() so the scan will be done
-                # again by getParentChain. See CA-177063 for details on
-                # how this has been discovered during the stress tests.
-                return dict()
-            vhds[vhdInfo.uuid] = vhdInfo
-        else:
-            util.SMlog("WARN: vhdinfo line doesn't parse correctly: %s" % line)
-    return vhds
-
-
-def getParentChain(lvName, extractUuidFunction, vgName):
-    """Get the chain of all VHD parents of 'path'. Safe to call for raw VDI's
-    as well"""
-    chain = dict()
-    vdis = dict()
-    retries = 0
-    while (not vdis):
-        if retries > 60:
-            util.SMlog('ERROR: getAllVHDs returned 0 VDIs after %d retries' % retries)
-            util.SMlog('ERROR: the VHD metadata might be corrupted')
-            break
-        vdis = getAllVHDs(lvName, extractUuidFunction, vgName, True, True)
-        if (not vdis):
-            retries = retries + 1
-            time.sleep(1)
-    for uuid, vdi in vdis.items():
-        chain[uuid] = vdi.path
-    #util.SMlog("Parent chain for %s: %s" % (lvName, chain))
-    return chain
-
-
-def getParent(path, extractUuidFunction):
-    cmd = [VHD_UTIL, "query", OPT_LOG_ERR, "-p", "-n", path]
-    ret = ioretry(cmd)
-    if ret.find("query failed") != -1 or ret.find("Failed opening") != -1:
-        raise util.SMException("VHD query returned %s" % ret)
-    if ret.find("no parent") != -1:
-        return None
-    return extractUuidFunction(ret)
-
-
-def hasParent(path):
-    """Check if the VHD has a parent. A VHD has a parent iff its type is
-    'Differencing'. This function does not need the parent to actually
-    be present (e.g. the parent LV to be activated)."""
-    cmd = [VHD_UTIL, "read", OPT_LOG_ERR, "-p", "-n", path]
-    ret = ioretry(cmd)
-    # pylint: disable=no-member
-    m = re.match(r".*Disk type\s+: (\S+) hard disk.*", ret, flags=re.S)
-    vhd_type = m.group(1)
-    assert(vhd_type == "Differencing" or vhd_type == "Dynamic")
-    return vhd_type == "Differencing"
-
-
-def setParent(path, parentPath, parentRaw):
-    normpath = os.path.normpath(parentPath)
-    cmd = [VHD_UTIL, "modify", OPT_LOG_ERR, "-p", normpath, "-n", path]
-    if parentRaw:
-        cmd.append("-m")
-    ioretry(cmd)
-
+from sm_typing import Callable, Dict, Final, Optional, Sequence, cast, override
 
-def getHidden(path):
-    cmd = [VHD_UTIL, "query", OPT_LOG_ERR, "-f", "-n", path]
-    ret = ioretry(cmd)
-    hidden = int(ret.split(':')[-1].strip())
-    return hidden
-
-
-def setHidden(path, hidden=True):
-    opt = "1"
-    if not hidden:
-        opt = "0"
-    cmd = [VHD_UTIL, "set", OPT_LOG_ERR, "-n", path, "-f", "hidden", "-v", opt]
-    ret = ioretry(cmd)
-
-
-def getSizeVirt(path):
-    cmd = [VHD_UTIL, "query", OPT_LOG_ERR, "-v", "-n", path]
-    ret = ioretry(cmd)
-    size = int(ret) * 1024 * 1024
-    return size
+from abc import abstractmethod
 
+import errno
+import os
+import re
+import zlib
 
-def setSizeVirt(path, size, jFile):
-    "resize VHD offline"
-    size_mb = size // (1024 * 1024)
-    cmd = [VHD_UTIL, "resize", OPT_LOG_ERR, "-s", str(size_mb), "-n", path,
-            "-j", jFile]
-    ioretry(cmd)
-
-
-def setSizeVirtFast(path, size):
-    "resize VHD online"
-    size_mb = size // (1024 * 1024)
-    cmd = [VHD_UTIL, "resize", OPT_LOG_ERR, "-s", str(size_mb), "-n", path, "-f"]
-    ioretry(cmd)
-
-
-def getMaxResizeSize(path):
-    """get the max virtual size for fast resize"""
-    cmd = [VHD_UTIL, "query", OPT_LOG_ERR, "-S", "-n", path]
-    ret = ioretry(cmd)
-    return int(ret)
-
-
-def getSizePhys(path):
-    cmd = [VHD_UTIL, "query", OPT_LOG_ERR, "-s", "-n", path]
-    ret = ioretry(cmd)
-    return int(ret)
-
-
-def setSizePhys(path, size, debug=True):
-    "set physical utilisation (applicable to VHD's on fixed-size files)"
-    if debug:
-        cmd = [VHD_UTIL, "modify", OPT_LOG_ERR, "-s", str(size), "-n", path]
-    else:
-        cmd = [VHD_UTIL, "modify", "-s", str(size), "-n", path]
-    ioretry(cmd)
-
-
-def getAllocatedSize(path):
-    cmd = [VHD_UTIL, "query", OPT_LOG_ERR, '-a', '-n', path]
-    ret = ioretry(cmd)
-    return convertAllocatedSizeToBytes(int(ret))
-
-def killData(path):
-    "zero out the disk (kill all data inside the VHD file)"
-    cmd = [VHD_UTIL, "modify", OPT_LOG_ERR, "-z", "-n", path]
-    ioretry(cmd)
-
-
-def getDepth(path):
-    "get the VHD parent chain depth"
-    cmd = [VHD_UTIL, "query", OPT_LOG_ERR, "-d", "-n", path]
-    text = ioretry(cmd)
-    depth = -1
-    if text.startswith("chain depth:"):
-        depth = int(text.split(':')[1].strip())
-    return depth
-
-
-def getBlockBitmap(path):
-    cmd = [VHD_UTIL, "read", OPT_LOG_ERR, "-B", "-n", path]
-    text = ioretry(cmd, text=False)
-    return zlib.compress(text)
-
-
-def coalesce(path):
-    """
-    Coalesce the VHD, on success it returns the number of sectors coalesced
-    """
-    cmd = [VHD_UTIL, "coalesce", OPT_LOG_ERR, "-n", path]
-    text = ioretry(cmd)
-    match = re.match(r'^Coalesced (\d+) sectors', text)
-    if match:
-        return int(match.group(1))
-
-    return 0
+import util
+import XenAPI # pylint: disable=import-error
+import xs_errors
 
+from cowutil import CowImageInfo, CowUtil, ImageFormat
 
-def create(path, size, static, msize=0):
-    size_mb = size // (1024 * 1024)
-    cmd = [VHD_UTIL, "create", OPT_LOG_ERR, "-n", path, "-s", str(size_mb)]
-    if static:
-        cmd.append("-r")
-    if msize:
-        cmd.append("-S")
-        cmd.append(str(msize))
-    ioretry(cmd)
-
-
-def snapshot(path, parent, parentRaw, msize=0, checkEmpty=True):
-    cmd = [VHD_UTIL, "snapshot", OPT_LOG_ERR, "-n", path, "-p", parent]
-    if parentRaw:
-        cmd.append("-m")
-    if msize:
-        cmd.append("-S")
-        cmd.append(str(msize))
-    if not checkEmpty:
-        cmd.append("-e")
-    ioretry(cmd)
-
-
-def check(path, ignoreMissingFooter=False, fast=False):
-    cmd = [VHD_UTIL, "check", OPT_LOG_ERR, "-n", path]
-    if ignoreMissingFooter:
-        cmd.append("-i")
-    if fast:
-        cmd.append("-B")
-    try:
-        ioretry(cmd)
-        return True
-    except util.CommandException:
-        return False
-
-
-def revert(path, jFile):
-    cmd = [VHD_UTIL, "revert", OPT_LOG_ERR, "-n", path, "-j", jFile]
-    ioretry(cmd)
-
-
-def _parseVHDInfo(line, extractUuidFunction):
-    vhdInfo = None
-    valueMap = line.split()
-    if len(valueMap) < 1 or valueMap[0].find("vhd=") == -1:
-        return None
-    for keyval in valueMap:
-        (key, val) = keyval.split('=')
-        if key == "vhd":
-            uuid = extractUuidFunction(val)
-            if not uuid:
-                util.SMlog("***** malformed output, no UUID: %s" % valueMap)
-                return None
-            vhdInfo = VHDInfo(uuid)
-            vhdInfo.path = val
-        elif key == "scan-error":
-            vhdInfo.error = line
-            util.SMlog("***** VHD scan error: %s" % line)
-            break
-        elif key == "capacity":
-            vhdInfo.sizeVirt = int(val)
-        elif key == "size":
-            vhdInfo.sizePhys = int(val)
-        elif key == "hidden":
-            vhdInfo.hidden = int(val)
-        elif key == "parent" and val != "none":
-            vhdInfo.parentPath = val
-            vhdInfo.parentUuid = extractUuidFunction(val)
-    return vhdInfo
-
-
-def _getVHDParentNoCheck(path):
-    cmd = ["vhd-util", "read", "-p", "-n", "%s" % path]
-    text = util.pread(cmd)
-    util.SMlog(text)
-    for line in text.split('\n'):
-        if line.find("decoded name :") != -1:
-            val = line.split(':')[1].strip()
-            vdi = val.replace("--", "-")[-40:]
-            if vdi[1:].startswith("LV-"):
-                vdi = vdi[1:]
-            return vdi
-    return None
-
-
-def repair(path):
-    """Repairs the VHD."""
-    ioretry([VHD_UTIL, 'repair', '-n', path])
-
-
-def validate_and_round_vhd_size(size):
-    """ Take the supplied vhd size, in bytes, and check it is positive and less
-    that the maximum supported size, rounding up to the next block boundary
-    """
-    if size < 0 or size > MAX_VHD_SIZE:
-        raise xs_errors.XenError(
-            'VDISize', opterr='VDI size ' +
-                              'must be between 1 MB and %d MB' %
-                              (MAX_VHD_SIZE // (1024 * 1024)))
-
-    if size < MIN_VHD_SIZE:
-        size = MIN_VHD_SIZE
-
-    size = util.roundup(VHD_BLOCK_SIZE, size)
-
-    return size
-
-
-def getKeyHash(path):
-    """Extract the hash of the encryption key from the header of an encrypted VHD"""
-    cmd = ["vhd-util", "key", "-p", "-n", path]
-    ret = ioretry(cmd)
-    ret = ret.strip()
-    if ret == 'none':
+# ------------------------------------------------------------------------------
+
+MIN_VHD_SIZE: Final = 2 * 1024 * 1024
+MAX_VHD_SIZE: Final = 2040 * 1024 * 1024 * 1024
+VHD_MAX_VOLUME_SIZE: Final = 2 * 1024 * 1024 * 1024 * 1024
+
+MAX_VHD_JOURNAL_SIZE: Final = 6 * 1024 * 1024  # 2MB VHD block size, max 2TB VHD size.
+
+VHD_BLOCK_SIZE: Final = 2 * 1024 * 1024
+
+VHD_FOOTER_SIZE: Final = 512
+
+VHD_SECTOR_SIZE: Final = 512
+
+MAX_VHD_CHAIN_LENGTH: Final = 30
+
+VHD_UTIL: Final = "/usr/bin/vhd-util"
+
+OPT_LOG_ERR: Final = "--debug"
+
+# ------------------------------------------------------------------------------
+
+class VhdUtil(CowUtil):
+    @override
+    def getMinImageSize(self) -> int:
+        return MIN_VHD_SIZE
+
+    @override
+    def getMaxImageSize(self) -> int:
+        return MAX_VHD_SIZE
+
+    @override
+    def getBlockSize(self, path: str) -> int:
+        return VHD_BLOCK_SIZE
+
+    @override
+    def getFooterSize(self) -> int:
+        return VHD_FOOTER_SIZE
+
+    @override
+    def getDefaultPreallocationSizeVirt(self) -> int:
+        return VHD_MAX_VOLUME_SIZE
+
+    @override
+    def getMaxChainLength(self) -> int:
+        return MAX_VHD_CHAIN_LENGTH
+
+    @override
+    def calcOverheadEmpty(self, virtual_size: int) -> int:
+        """
+        Calculate the VHD space overhead (metadata size) for an empty VDI of
+        size virtual_size.
+        """
+        overhead = 0
+        size_mb = virtual_size // (1024 * 1024)
+
+        # Footer + footer copy + header + possible CoW parent locator fields
+        overhead = 3 * 1024
+
+        # BAT 4 Bytes per block segment
+        overhead += (size_mb // 2) * 4
+        overhead = util.roundup(512, overhead)
+
+        # BATMAP 1 bit per block segment
+        overhead += (size_mb // 2) // 8
+        overhead = util.roundup(4096, overhead)
+
+        return overhead
+
+    @override
+    def calcOverheadBitmap(self, virtual_size: int) -> int:
+        num_blocks = virtual_size // VHD_BLOCK_SIZE
+        if virtual_size % VHD_BLOCK_SIZE:
+            num_blocks += 1
+        return num_blocks * 4096
+
+    @override
+    def getInfo(
+        self,
+        path: str,
+        extractUuidFunction: Callable[[str], str],
+        includeParent: bool = True,
+        resolveParent: bool = True,
+        useBackupFooter: bool = False
+    ) -> CowImageInfo:
+        """
+        Get the VHD info. The parent info may optionally be omitted: vhd-util
+        tries to verify the parent by opening it, which results in error if the VHD
+        resides on an inactive LV.
+        """
+        opts = "-vsaf"
+        if includeParent:
+            opts += "p"
+            if not resolveParent:
+                opts += "u"
+        if useBackupFooter:
+            opts += "b"
+
+        ret = cast(str, self._ioretry([VHD_UTIL, "query", OPT_LOG_ERR, opts, "-n", path]))
+        fields = ret.strip().split("\n")
+        uuid = extractUuidFunction(path)
+        vhdInfo = CowImageInfo(uuid)
+        vhdInfo.sizeVirt = int(fields[0]) * 1024 * 1024
+        vhdInfo.sizePhys = int(fields[1])
+        nextIndex = 2
+        if includeParent:
+            if fields[nextIndex].find("no parent") == -1:
+                vhdInfo.parentPath = fields[nextIndex]
+                vhdInfo.parentUuid = extractUuidFunction(fields[nextIndex])
+            nextIndex += 1
+        vhdInfo.hidden = bool(int(fields[nextIndex].replace("hidden: ", "")))
+        vhdInfo.sizeAllocated = self._convertAllocatedSizeToBytes(int(fields[nextIndex+1]))
+        vhdInfo.path = path
+        return vhdInfo
+
+    @override
+    def getInfoFromLVM(
+        self, lvName: str, extractUuidFunction: Callable[[str], str], vgName: str
+    ) -> Optional[CowImageInfo]:
+        """
+        Get the VHD info. This function does not require the container LV to be
+        active, but uses LVs & VGs.
+        """
+        ret = cast(str, self._ioretry([VHD_UTIL, "scan", "-f", "-l", vgName, "-m", lvName]))
+        return self._parseVHDInfo(ret, extractUuidFunction)
+
+    @override
+    def getAllInfoFromVG(
+        self,
+        pattern: str,
+        extractUuidFunction: Callable[[str], str],
+        vgName: Optional[str] = None,
+        parents: bool = False,
+        exitOnError: bool = False
+    ) -> Dict[str, CowImageInfo]:
+        result: Dict[str, CowImageInfo] = dict()
+        cmd = [VHD_UTIL, "scan", "-f", "-m", pattern]
+        if vgName:
+            cmd.append("-l")
+            cmd.append(vgName)
+        if parents:
+            cmd.append("-a")
+        try:
+            ret = cast(str, self._ioretry(cmd))
+        except Exception as e:
+            util.SMlog("WARN: VHD scan failed: output: %s" % e)
+            ret = cast(str, self._ioretry(cmd + ["-c"]))
+            util.SMlog("WARN: VHD scan with NOFAIL flag, output: %s" % ret)
+        for line in ret.split('\n'):
+            if not line.strip():
+                continue
+            info = self._parseVHDInfo(line, extractUuidFunction)
+            if info:
+                if info.error != 0 and exitOnError:
+                    # Just return an empty dict() so the scan will be done
+                    # again by getParentChain. See CA-177063 for details on
+                    # how this has been discovered during the stress tests.
+                    return dict()
+                result[info.uuid] = info
+            else:
+                util.SMlog("WARN: VHD info line doesn't parse correctly: %s" % line)
+        return result
+
+    @override
+    def getParent(self, path: str, extractUuidFunction: Callable[[str], str]) -> Optional[str]:
+        ret = cast(str, self._ioretry([VHD_UTIL, "query", OPT_LOG_ERR, "-p", "-n", path]))
+        if ret.find("query failed") != -1 or ret.find("Failed opening") != -1:
+            raise util.SMException("VHD query returned %s" % ret)
+        if ret.find("no parent") != -1:
+            return None
+        return extractUuidFunction(ret)
+
+    @override
+    def getParentNoCheck(self, path: str) -> Optional[str]:
+        text = util.pread([VHD_UTIL, "read", "-p", "-n", "%s" % path])
+        util.SMlog(text)
+        for line in text.split("\n"):
+            if line.find("decoded name :") != -1:
+                val = line.split(":")[1].strip()
+                vdi = val.replace("--", "-")[-40:]
+                if vdi[1:].startswith("LV-"):
+                    vdi = vdi[1:]
+                return vdi
         return None
-    vals = ret.split()
-    if len(vals) != 2:
-        util.SMlog('***** malformed output from vhd-util'
-                   ' for VHD {}: "{}"'.format(path, ret))
-        return None
-    [_nonce, key_hash] = vals
-    return key_hash
-
 
-def setKey(path, key_hash):
-    """Set the encryption key for a VHD"""
-    cmd = ["vhd-util", "key", "-s", "-n", path, "-H", key_hash]
-    ioretry(cmd)
+    @override
+    def hasParent(self, path: str) -> bool:
+        """
+        Check if the VHD has a parent. A VHD has a parent iff its type is
+        'Differencing'. This function does not need the parent to actually
+        be present (e.g. the parent LV to be activated).
+        """
+        ret = cast(str, self._ioretry([VHD_UTIL, "read", OPT_LOG_ERR, "-p", "-n", path]))
+        # pylint: disable=no-member
+        m = re.match(r".*Disk type\s+: (\S+) hard disk.*", ret, flags=re.S)
+        if m:
+            vhd_type = m.group(1)
+            assert vhd_type == "Differencing" or vhd_type == "Dynamic"
+            return vhd_type == "Differencing"
+        assert False, f"Ill-formed {VHD_UTIL} output detected during VHD parent parsing"
+
+    @override
+    def setParent(self, path: str, parentPath: str, parentRaw: bool) -> None:
+        normpath = os.path.normpath(parentPath)
+        cmd = [VHD_UTIL, "modify", OPT_LOG_ERR, "-p", normpath, "-n", path]
+        if parentRaw:
+            cmd.append("-m")
+        self._ioretry(cmd)
+
+    @override
+    def getHidden(self, path: str) -> bool:
+        ret = cast(str, self._ioretry([VHD_UTIL, "query", OPT_LOG_ERR, "-f", "-n", path]))
+        return bool(int(ret.split(":")[-1].strip()))
+
+    @override
+    def setHidden(self, path: str, hidden: bool = True) -> None:
+        opt = "1"
+        if not hidden:
+            opt = "0"
+        self._ioretry([VHD_UTIL, "set", OPT_LOG_ERR, "-n", path, "-f", "hidden", "-v", opt])
+
+    @override
+    def getSizeVirt(self, path: str) -> int:
+        ret = self._ioretry([VHD_UTIL, "query", OPT_LOG_ERR, "-v", "-n", path])
+        return int(ret) * 1024 * 1024
+
+    @override
+    def setSizeVirt(self, path: str, size: int, jFile: str) -> None:
+        """
+        Resize VHD offline
+        """
+        size_mb = size // (1024 * 1024)
+        self._ioretry([VHD_UTIL, "resize", OPT_LOG_ERR, "-s", str(size_mb), "-n", path, "-j", jFile])
+
+    @override
+    def setSizeVirtFast(self, path: str, size: int) -> None:
+        """
+        Resize VHD online.
+        """
+        size_mb = size // (1024 * 1024)
+        self._ioretry([VHD_UTIL, "resize", OPT_LOG_ERR, "-s", str(size_mb), "-n", path, "-f"])
+
+    @override
+    def getMaxResizeSize(self, path: str) -> int:
+        """
+        Get the max virtual size for fast resize.
+        """
+        ret = self._ioretry([VHD_UTIL, "query", OPT_LOG_ERR, "-S", "-n", path])
+        return int(ret) * 1024 * 1024
+
+    @override
+    def getSizePhys(self, path: str) -> int:
+        return int(self._ioretry([VHD_UTIL, "query", OPT_LOG_ERR, "-s", "-n", path]))
+
+    @override
+    def setSizePhys(self, path: str, size: int, debug: bool = True) -> None:
+        """
+        Set physical utilisation (applicable to VHD's on fixed-size files).
+        """
+        if debug:
+            cmd = [VHD_UTIL, "modify", OPT_LOG_ERR, "-s", str(size), "-n", path]
+        else:
+            cmd = [VHD_UTIL, "modify", "-s", str(size), "-n", path]
+        self._ioretry(cmd)
+
+    @override
+    def getAllocatedSize(self, path: str) -> int:
+        ret = self._ioretry([VHD_UTIL, "query", OPT_LOG_ERR, "-a", "-n", path])
+        return self._convertAllocatedSizeToBytes(int(ret))
+
+    @override
+    def getResizeJournalSize(self) -> int:
+        return MAX_VHD_JOURNAL_SIZE
+
+    @override
+    def killData(self, path: str) -> None:
+        """
+        Zero out the disk (kill all data inside the VHD file).
+        """
+        self._ioretry([VHD_UTIL, "modify", OPT_LOG_ERR, "-z", "-n", path])
+
+    @override
+    def getDepth(self, path: str) -> int:
+        """
+        Get the VHD parent chain depth.
+        """
+        text = cast(str, self._ioretry([VHD_UTIL, "query", OPT_LOG_ERR, "-d", "-n", path]))
+        depth = -1
+        if text.startswith("chain depth:"):
+            depth = int(text.split(":")[1].strip())
+        return depth
+
+    @override
+    def getBlockBitmap(self, path: str) -> bytes:
+        text = cast(bytes, self._ioretry([VHD_UTIL, "read", OPT_LOG_ERR, "-B", "-n", path], text=False))
+        return zlib.compress(text)
+
+    @override
+    def coalesce(self, path: str) -> int:
+        """
+        Coalesce the VHD, on success it returns the number of bytes coalesced.
+        """
+        text = cast(str, self._ioretry([VHD_UTIL, "coalesce", OPT_LOG_ERR, "-n", path]))
+        match = re.match(r"^Coalesced (\d+) sectors", text)
+        if match:
+            return int(match.group(1)) * VHD_SECTOR_SIZE
+        return 0
+
+    @override
+    def create(self, path: str, size: int, static: bool, msize: int = 0) -> None:
+        cmd = [VHD_UTIL, "create", OPT_LOG_ERR, "-n", path, "-s", str(size // (1024 * 1024))]
+        if static:
+            cmd.append("-r")
+        if msize:
+            cmd.append("-S")
+            cmd.append(str(max(msize, size) // (1024 * 1024)))
+        self._ioretry(cmd)
+
+    @override
+    def snapshot(
+        self,
+        path: str,
+        parent: str,
+        parentRaw: bool,
+        msize: int = 0,
+        checkEmpty: Optional[bool] = True
+    ) -> None:
+        cmd = [VHD_UTIL, "snapshot", OPT_LOG_ERR, "-n", path, "-p", parent]
+        if parentRaw:
+            cmd.append("-m")
+        if msize:
+            cmd.append("-S")
+            cmd.append(str(msize // (1024 * 1024)))
+        if not checkEmpty:
+            cmd.append("-e")
+        self._ioretry(cmd)
+
+    @override
+    def canSnapshotRaw(self, size: int) -> bool:
+        return size <= MAX_VHD_SIZE
+
+    @override
+    def check(
+        self,
+        path: str,
+        ignoreMissingFooter: Optional[bool] = False,
+        fast: Optional[bool] = False
+    ) -> CowUtil.CheckResult:
+        cmd = [VHD_UTIL, "check", OPT_LOG_ERR, "-n", path]
+        if ignoreMissingFooter:
+            cmd.append("-i")
+        if fast:
+            cmd.append("-B")
+        try:
+            self._ioretry(cmd)
+            return CowUtil.CheckResult.Success
+        except util.CommandException as e:
+            if e.code in (errno.ENOENT, errno.EROFS, errno.EMEDIUMTYPE):
+                return CowUtil.CheckResult.Unavailable
+            return CowUtil.CheckResult.Fail
+
+    @override
+    def revert(self, path: str, jFile: str) -> None:
+        self._ioretry([VHD_UTIL, "revert", OPT_LOG_ERR, "-n", path, "-j", jFile])
+
+    @override
+    def repair(self, path: str) -> None:
+        """
+        Repairs a VHD.
+        """
+        self._ioretry([VHD_UTIL, "repair", "-n", path])
+
+    @override
+    def validateAndRoundImageSize(self, size: int) -> int:
+        """
+        Take the supplied vhd size, in bytes, and check it is positive and less
+        that the maximum supported size, rounding up to the next block boundary.
+        """
+        if size < 0 or size > MAX_VHD_SIZE:
+            raise xs_errors.XenError(
+                "VDISize",
+                opterr="VDI size must be between 1 MB and %d MB" % (MAX_VHD_SIZE // (1024 * 1024))
+            )
+
+        if size < MIN_VHD_SIZE:
+            size = MIN_VHD_SIZE
+
+        return util.roundup(VHD_BLOCK_SIZE, size)
+
+    @override
+    def getKeyHash(self, path: str) -> Optional[str]:
+        """
+        Extract the hash of the encryption key from the header of an encrypted VHD.
+        """
+        ret = cast(str, self._ioretry([VHD_UTIL, "key", "-p", "-n", path])).strip()
+        if ret == "none":
+            return None
+        vals = ret.split()
+        if len(vals) != 2:
+            util.SMlog("***** malformed output from vhd-util for VHD {}: \"{}\"".format(path, ret))
+            return None
+        [_nonce, key_hash] = vals
+        return key_hash
+
+    @override
+    def setKey(self, path: str, key_hash: str) -> None:
+        """
+        Set the encryption key for a VHD.
+        """
+        self._ioretry([VHD_UTIL, "key", "-s", "-n", path, "-H", key_hash])
+
+    @staticmethod
+    def _convertAllocatedSizeToBytes(size: int):
+        # Assume we have standard 2MB allocation blocks
+        return size * 2 * 1024 * 1024
+
+    @staticmethod
+    def _parseVHDInfo(line: str, extractUuidFunction: Callable[[str], str]) -> Optional[CowImageInfo]:
+        vhdInfo = None
+        valueMap = line.split()
+
+        try:
+            (key, val) = valueMap[0].split("=")
+        except:
+            return None
+
+        if key != "vhd":
+            return None
+
+        uuid = extractUuidFunction(val)
+        if not uuid:
+            util.SMlog("***** malformed output, no UUID: %s" % valueMap)
+            return None
+        vhdInfo = CowImageInfo(uuid)
+        vhdInfo.path = val
+
+        for keyval in valueMap:
+            (key, val) = keyval.split("=")
+            if key == "scan-error":
+                vhdInfo.error = line
+                util.SMlog("***** VHD scan error: %s" % line)
+                break
+            elif key == "capacity":
+                vhdInfo.sizeVirt = int(val)
+            elif key == "size":
+                vhdInfo.sizePhys = int(val)
+            elif key == "hidden":
+                vhdInfo.hidden = bool(int(val))
+            elif key == "parent" and val != "none":
+                vhdInfo.parentPath = val
+                vhdInfo.parentUuid = extractUuidFunction(val)
+        return vhdInfo
diff --git a/mk/sm.spec.in b/mk/sm.spec.in
index 2353b13e..31c345a2 100755
--- a/mk/sm.spec.in
+++ b/mk/sm.spec.in
@@ -173,7 +173,7 @@ tests/run_python_unittests.sh
 /opt/xensource/sm/lcache.py
 /opt/xensource/sm/lock.py
 /opt/xensource/sm/lock_queue.py
-/opt/xensource/sm/lvhdutil.py
+/opt/xensource/sm/lvmcowutil.py
 /opt/xensource/sm/lvmanager.py
 /opt/xensource/sm/lvmcache.py
 /opt/xensource/sm/lvutil.py
diff --git a/mocks/XenAPI/__init__.py b/mocks/XenAPI/__init__.py
index 9dd4441f..1bfe123c 100644
--- a/mocks/XenAPI/__init__.py
+++ b/mocks/XenAPI/__init__.py
@@ -5,3 +5,7 @@ class Failure(Exception):
 def xapi_local():
     # Mock stub
     pass
+
+class Session(object):
+    def __getattr__(self, name):
+        pass
diff --git a/tests/test_FileSR.py b/tests/test_FileSR.py
index 8dfaca9b..d0c08ae6 100644
--- a/tests/test_FileSR.py
+++ b/tests/test_FileSR.py
@@ -15,7 +15,7 @@ import SR
 import SRCommand
 import testlib
 import util
-import vhdutil
+import cowutil
 import xs_errors
 from vditype import VdiType
 
@@ -23,12 +23,22 @@ from vditype import VdiType
 class FakeFileVDI(FileSR.FileVDI):
     @override
     def load(self, uuid) -> None:
-        self.vdi_type = VdiType.VHD
+        if not self.vdi_type:
+            self.vdi_type = VdiType.VHD
+        extension = "raw" if self.vdi_type == "aio" else self.vdi_type
+        self.cowutil = cowutil.getCowUtil(self.vdi_type)
         self.hidden = False
         self.path = os.path.join(self.sr.path, '%s.%s' % (
-               uuid, VdiType.VHD))
+               uuid, extension))
         self.key_hash = None
 
+def createFakeFileVDI(sr, vdi_uuid, vdi_type=VdiType.VHD):
+    vdi = FakeFileVDI(sr, vdi_uuid)
+    if vdi_type != VdiType.VHD:
+        vdi.vdi_type = vdi_type
+        vdi.load(vdi_uuid)
+    return vdi
+
 
 class TestFileVDI(unittest.TestCase):
     @override
@@ -49,8 +59,8 @@ class TestFileVDI(unittest.TestCase):
         self.mock_os_unlink = os_unlink_patcher.start()
         pread_patcher = mock.patch('FileSR.util.pread')
         self.mock_pread = pread_patcher.start()
-        gethidden_patch = mock.patch('FileSR.vhdutil.getHidden')
-        self.mock_gethidden = gethidden_patch.start()
+        gethidden_patcher = mock.patch('vhdutil.VhdUtil.getHidden')
+        self.mock_gethidden = gethidden_patcher.start()
 
         fist_patcher = mock.patch('FileSR.util.FistPoint.is_active',
                                   autospec=True)
@@ -71,7 +81,7 @@ class TestFileVDI(unittest.TestCase):
         vdi_uuid = uuid.uuid4()
         sr = mock.MagicMock()
         sr.path = "sr_path"
-        vdi = FakeFileVDI(sr, None)
+        vdi = createFakeFileVDI(sr, None)
         vdi.sr = sr
         mock_os_stat.side_effect = [os.stat_result((stat.S_IFREG, 0, 0, 0, 0, 0, 1024, 0, 0, 0))]
 
@@ -87,10 +97,13 @@ class TestFileVDI(unittest.TestCase):
         vdi_uuid = uuid.uuid4()
         sr = mock.MagicMock()
         sr.path = "sr_path"
-        vdi = FakeFileVDI(sr, None)
+        vdi = createFakeFileVDI(sr, None)
         vdi.sr = sr
-        mock_os_stat.side_effect = [OSError(errno.ENOENT),
-                                     os.stat_result((stat.S_IFREG, 0, 0, 0, 0, 0, 1024, 0, 0, 0))]
+        mock_os_stat.side_effect = [
+            OSError(errno.ENOENT),
+            OSError(errno.ENOENT),
+            os.stat_result((stat.S_IFREG, 0, 0, 0, 0, 0, 1024, 0, 0, 0))
+        ]
 
         found = vdi._find_path_with_retries(vdi_uuid)
 
@@ -105,12 +118,15 @@ class TestFileVDI(unittest.TestCase):
         vdi_uuid = uuid.uuid4()
         sr = mock.MagicMock()
         sr.path = "sr_path"
-        vdi = FakeFileVDI(sr, None)
+        vdi = createFakeFileVDI(sr, None)
         vdi.sr = sr
-        mock_os_stat.side_effect = [OSError(errno.ENOENT),
-                                     OSError(errno.ENOENT),
-                                     OSError(errno.ENOENT),
-                                     os.stat_result((stat.S_IFREG, 0, 0, 0, 0, 0, 1024, 0, 0, 0))]
+        mock_os_stat.side_effect = [
+            OSError(errno.ENOENT),
+            OSError(errno.ENOENT),
+            OSError(errno.ENOENT),
+            OSError(errno.ENOENT),
+            os.stat_result((stat.S_IFREG, 0, 0, 0, 0, 0, 1024, 0, 0, 0))
+        ]
 
         found = vdi._find_path_with_retries(vdi_uuid)
 
@@ -124,7 +140,7 @@ class TestFileVDI(unittest.TestCase):
         vdi_uuid = uuid.uuid4()
         sr = mock.MagicMock()
         sr.path = "sr_path"
-        vdi = FakeFileVDI(sr, None)
+        vdi = createFakeFileVDI(sr, None)
         vdi.sr = sr
         self.mock_os_stat.side_effect = OSError(errno.ENOENT)
 
@@ -142,18 +158,18 @@ class TestFileVDI(unittest.TestCase):
                for x in vdi.getElementsByTagName('member')}
 
     @mock.patch('FileSR.util.gen_uuid')
-    @mock.patch('FileSR.FileVDI._query_p_uuid')
+    @mock.patch('vhdutil.VhdUtil.getParent')
     @mock.patch('FileSR.util.pathexists', autospec=True)
-    @mock.patch('FileSR.vhdutil.getDepth', autospec=True)
+    @mock.patch('vhdutil.VhdUtil.getDepth', autospec=True)
     @mock.patch('FileSR.blktap2', autospec=True)
     def test_clone_success(self, mock_blktap, mock_getDepth, mock_pathexists,
-                            mock_query_p_uuid, mock_uuid):
+                            mock_getParent, mock_uuid):
         # Arrange
         sr_uuid = str(uuid.uuid4())
         vdi_uuid = str(uuid.uuid4())
         sr = mock.MagicMock()
         sr.path = "sr_path"
-        vdi = FakeFileVDI(sr, vdi_uuid)
+        vdi = createFakeFileVDI(sr, vdi_uuid)
         vdi.sr = sr
 
         mock_getDepth.return_value = 1
@@ -163,7 +179,7 @@ class TestFileVDI(unittest.TestCase):
         mock_uuid.side_effect = [clone_vdi_uuid, new_vdi_uuid]
         grandp_uuid = str(uuid.uuid4())
 
-        mock_query_p_uuid.side_effect = [new_vdi_uuid, new_vdi_uuid, grandp_uuid]
+        mock_getParent.side_effect = [new_vdi_uuid, new_vdi_uuid, grandp_uuid]
 
         # Act
         clone_xml = vdi.clone(sr_uuid, vdi_uuid)
@@ -181,20 +197,20 @@ class TestFileVDI(unittest.TestCase):
                          'sr_path/%s.vhd' % vdi_uuid)])
 
     @mock.patch('FileSR.util.gen_uuid')
-    @mock.patch('FileSR.FileVDI._query_p_uuid')
+    @mock.patch('vhdutil.VhdUtil.getParent')
     @mock.patch('FileSR.util.pathexists', autospec=True)
-    @mock.patch('FileSR.vhdutil.getDepth', autospec=True)
+    @mock.patch('vhdutil.VhdUtil.getDepth', autospec=True)
     @mock.patch('FileSR.blktap2', autospec=True)
     def test_clone_no_links_success(
             self, mock_blktap, mock_getDepth, mock_pathexists,
-            mock_query_p_uuid, mock_uuid):
+            mock_getParent, mock_uuid):
         # Arrange
         sr_uuid = str(uuid.uuid4())
         vdi_uuid = str(uuid.uuid4())
         sr = mock.MagicMock()
         sr.path = "sr_path"
         sr._check_hardlinks.return_value = False
-        vdi = FakeFileVDI(sr, vdi_uuid)
+        vdi = createFakeFileVDI(sr, vdi_uuid)
         vdi.sr = sr
 
         mock_getDepth.return_value = 1
@@ -204,7 +220,7 @@ class TestFileVDI(unittest.TestCase):
         mock_uuid.side_effect = [clone_vdi_uuid, new_vdi_uuid]
         grandp_uuid = str(uuid.uuid4())
 
-        mock_query_p_uuid.side_effect = [new_vdi_uuid, new_vdi_uuid, grandp_uuid]
+        mock_getParent.side_effect = [new_vdi_uuid, new_vdi_uuid, grandp_uuid]
 
         # Act
         clone_xml = vdi.clone(sr_uuid, vdi_uuid)
@@ -223,19 +239,19 @@ class TestFileVDI(unittest.TestCase):
 
     @mock.patch('FileSR.FileVDI._snap')
     @mock.patch('FileSR.util.gen_uuid')
-    @mock.patch('FileSR.FileVDI._query_p_uuid')
+    @mock.patch('vhdutil.VhdUtil.getParent')
     @mock.patch('FileSR.util.pathexists', autospec=True)
-    @mock.patch('FileSR.vhdutil.getDepth', autospec=True)
+    @mock.patch('vhdutil.VhdUtil.getDepth', autospec=True)
     @mock.patch('FileSR.blktap2', autospec=True)
     def test_clone_nospace_snap_1(
                self, mock_blktap, mock_getDepth, mock_pathexists,
-               mock_query_p_uuid, mock_uuid, mock_snap):
+               mock_getParent, mock_uuid, mock_snap):
         # Arrange
         sr_uuid = str(uuid.uuid4())
         vdi_uuid = str(uuid.uuid4())
         sr = mock.MagicMock()
         sr.path = "sr_path"
-        vdi = FakeFileVDI(sr, vdi_uuid)
+        vdi = createFakeFileVDI(sr, vdi_uuid)
         vdi.sr = sr
 
         mock_getDepth.return_value = 1
@@ -270,19 +286,19 @@ class TestFileVDI(unittest.TestCase):
 
     @mock.patch('FileSR.FileVDI._snap')
     @mock.patch('FileSR.util.gen_uuid')
-    @mock.patch('FileSR.FileVDI._query_p_uuid')
+    @mock.patch('vhdutil.VhdUtil.getParent')
     @mock.patch('FileSR.util.pathexists', autospec=True)
-    @mock.patch('FileSR.vhdutil.getDepth', autospec=True)
+    @mock.patch('vhdutil.VhdUtil.getDepth', autospec=True)
     @mock.patch('FileSR.blktap2', autospec=True)
     def test_clone_nospace_snap_2(
                self, mock_blktap, mock_getDepth, mock_pathexists,
-               mock_query_p_uuid, mock_uuid, mock_snap):
+               mock_getParent, mock_uuid, mock_snap):
         # Arrange
         sr_uuid = str(uuid.uuid4())
         vdi_uuid = str(uuid.uuid4())
         sr = mock.MagicMock()
         sr.path = "sr_path"
-        vdi = FakeFileVDI(sr, vdi_uuid)
+        vdi = createFakeFileVDI(sr, vdi_uuid)
         vdi.sr = sr
 
         mock_getDepth.return_value = 1
@@ -320,16 +336,13 @@ class TestFileVDI(unittest.TestCase):
                mock.call('sr_path/%s.vhd' % new_vdi_uuid,
                          'sr_path/%s.vhd' % vdi_uuid)])
 
-    @mock.patch('FileSR.vhdutil', spec=True)
-    def test_create_vdi_vhd(self, mock_vhdutil):
+    def test_create_vdi_vhd(self):
         # Arrange
         sr_uuid = str(uuid.uuid4())
         vdi_uuid = str(uuid.uuid4())
         sr = mock.MagicMock()
         sr.path = "sr_path"
-        vdi = FakeFileVDI(sr, vdi_uuid)
-        vdi.vdi_type = VdiType.VHD
-        mock_vhdutil.validate_and_round_vhd_size.side_effect = vhdutil.validate_and_round_vhd_size
+        vdi = createFakeFileVDI(sr, vdi_uuid, VdiType.VHD)
 
         # Act
         vdi.create(sr_uuid, vdi_uuid, 20 * 1024 * 1024)
@@ -337,27 +350,23 @@ class TestFileVDI(unittest.TestCase):
         # Assert
         expected_path = f"sr_path/{vdi_uuid}.vhd"
         self.mock_pread.assert_has_calls([
-            mock.call(["/usr/sbin/td-util", "create", vdi.vdi_type,
-                       "20", expected_path]),
-            mock.call(["/usr/sbin/td-util", "query", vdi.vdi_type, "-v",
-                       expected_path])])
+            mock.call(["/usr/bin/vhd-util", "create", "--debug", "-n", expected_path, "-s", "20"], quiet=False, text=True),
+            mock.call(["/usr/bin/vhd-util", "query", "--debug", "-v", "-n", expected_path], quiet=False, text=True)])
 
-    @mock.patch('FileSR.vhdutil', spec=True)
     @mock.patch('builtins.open', new_callable=mock.mock_open())
-    def test_create_vdi_raw(self, mock_open, mock_vhdutil):
+    def test_create_vdi_raw(self, mock_open):
         # Arrange
         sr_uuid = str(uuid.uuid4())
         vdi_uuid = str(uuid.uuid4())
         sr = mock.MagicMock()
         sr.path = "sr_path"
-        vdi = FakeFileVDI(sr, vdi_uuid)
-        vdi.vdi_type = VdiType.RAW
+        vdi = createFakeFileVDI(sr, vdi_uuid, VdiType.RAW)
 
         # Act
         vdi.create(sr_uuid, vdi_uuid, 20 * 1024 * 1024)
 
         # Assert
-        expected_path = f"sr_path/{vdi_uuid}.vhd"
+        expected_path = f"sr_path/{vdi_uuid}.raw"
         mock_open.assert_called_with(expected_path, 'w')
 
     @mock.patch("FileSR.util.pathexists", autospec=True)
@@ -365,8 +374,10 @@ class TestFileVDI(unittest.TestCase):
     def test_vdi_load_vhd(self, mock_chdir, mock_pathexists):
         # Arrange
         self.mock_pread.return_value = """10240
+10240
 /dev/VG_XenStorage-602fa2e9-2f9e-84af-ac1d-de4616cdcccb/VHD-155a6d00-2f70-411f-9bc7-3fa51fa543ca has no parent
 hidden: 0
+10240
 """
         sr_uuid = str(uuid.uuid4())
         vdi_uuid = str(uuid.uuid4())
@@ -402,7 +413,7 @@ hidden: 0
             'command': 'vdi_create'
         }
         sr = FakeSharedFileSR(srcmd, sr_uuid)
-        vdi = FakeFileVDI(sr, vdi_uuid)
+        vdi = createFakeFileVDI(sr, vdi_uuid)
         mock_pathexists.return_value = True
 
         # Act
@@ -446,6 +457,9 @@ class TestShareFileSR(unittest.TestCase):
 
     @override
     def setUp(self) -> None:
+        pread_patcher = mock.patch('FileSR.util.pread')
+        self.mock_pread = pread_patcher.start()
+
         util_patcher = mock.patch('FileSR.util', autospec=True)
         self.mock_util = util_patcher.start()
 
@@ -466,8 +480,8 @@ class TestShareFileSR(unittest.TestCase):
         self.mock_session = mock.MagicMock()
         self.mock_xapi.xapi_local.return_value = self.mock_session
 
-        vhdutil_patcher = mock.patch('FileSR.vhdutil', autospec=True)
-        self.mock_vhdutil = vhdutil_patcher.start()
+        getAllInfoFromVG_patcher = mock.patch('vhdutil.VhdUtil.getAllInfoFromVG')
+        self.mock_getAllInfoFromVG = getAllInfoFromVG_patcher.start()
         glob_patcher = mock.patch("FileSR.glob", autospec=True)
         self.mock_glob = glob_patcher.start()
 
@@ -552,7 +566,7 @@ class TestShareFileSR(unittest.TestCase):
         self.mock_util.ismount.return_value = True
 
         vdi1_uuid = str(uuid.uuid4())
-        vdi1_info = vhdutil.VHDInfo(vdi1_uuid)
+        vdi1_info = cowutil.CowImageInfo(vdi1_uuid)
         vdi1_info.error = False
         vdi1_info.path = f"sr_path/{vdi1_uuid}.vhd"
         test_vhds = {
@@ -560,7 +574,7 @@ class TestShareFileSR(unittest.TestCase):
         }
         self.mock_glob.glob.return_value = []
 
-        self.mock_vhdutil.getAllVHDs.return_value = test_vhds
+        self.mock_getAllInfoFromVG.return_value = test_vhds
 
         # Act
         test_sr.scan(self.sr_uuid)
@@ -577,6 +591,7 @@ class TestFileSR(unittest.TestCase):
         sr_init_patcher = mock.patch('SR.SR.__init__')
         def fake_sr_init(self, srcmd, sr_uuid):
             self.sr_ref = False
+            self.dconf = None
         self.mock_sr_init = sr_init_patcher.start()
         self.mock_sr_init.side_effect = fake_sr_init
 
diff --git a/tests/test_LVMSR.py b/tests/test_LVMSR.py
index 627d1b23..a3bc5eb7 100644
--- a/tests/test_LVMSR.py
+++ b/tests/test_LVMSR.py
@@ -8,10 +8,12 @@ import unittest.mock as mock
 import uuid
 
 import cleanup
+import cowutil
+import lvmcowutil
 import LVMSR
-import lvhdutil
 import lvutil
 import vhdutil
+
 from vditype import VdiType
 
 import testlib
@@ -61,22 +63,24 @@ class TestLVMSR(unittest.TestCase, Stubs):
         return LVMSR.LVMSR(srcmd, sr_uuid)
 
     @mock.patch('lvutil.Fairlock', autospec=True)
-    @mock.patch('lvhdutil.getVDIInfo', autospec=True)
+    @mock.patch('lvmcowutil.LvmCowUtil.getVDIInfo')
     @mock.patch('LVMSR.lock.Lock', autospec=True)
     @mock.patch('SR.XenAPI')
     def test_loadvids(self, mock_xenapi, mock_lock, mock_getVDIInfo, mock_lvlock):
         """sr.allVDIs populated by _loadvdis"""
 
         vdi_uuid = 'some VDI UUID'
-        mock_getVDIInfo.return_value = {vdi_uuid: lvhdutil.VDIInfo(vdi_uuid)}
+        vdi_info = lvmcowutil.VDIInfo(vdi_uuid)
+        vdi_info.vdiType = VdiType.VHD
+        mock_getVDIInfo.return_value = {vdi_uuid: vdi_info}
         sr = self.create_LVMSR()
 
         sr._loadvdis()
 
         self.assertEqual([vdi_uuid], list(sr.allVDIs.keys()))
 
-    @mock.patch('lvhdutil.lvRefreshOnAllSlaves', autospec=True)
-    @mock.patch('lvhdutil.getVDIInfo', autospec=True)
+    @mock.patch('lvmcowutil.LvmCowUtil.refreshVolumeOnAllSlaves')
+    @mock.patch('lvmcowutil.LvmCowUtil.getVDIInfo')
     @mock.patch('journaler.Journaler.getAll', autospec=True)
     @mock.patch('LVMSR.lock.Lock', autospec=True)
     @mock.patch('SR.XenAPI')
@@ -86,24 +90,25 @@ class TestLVMSR(unittest.TestCase, Stubs):
             mock_lock,
             mock_getAll,
             mock_getVDIInfo,
-            mock_lvhdutil_lvRefreshOnAllSlaves):
-        """No LV refresh on slaves when Cleaning up local LVHD SR's journal"""
+            mock_lvmcowutil_refreshVolumeOnAllSlaves):
+        """No LV refresh on slaves when Cleaning up local COW image SR's journal"""
 
         self.stubout('journaler.Journaler.remove')
         self.stubout('util.zeroOut')
-        self.stubout('lvhdutil.deflate')
+        self.stubout('lvmcowutil.LvmCowUtil.deflate')
         self.stubout('util.SMlog', new_callable=SMLog)
         self.stubout('lvmcache.LVMCache')
 
         vdi_uuid = 'some VDI UUID'
-
+        vdi_info = lvmcowutil.VDIInfo(vdi_uuid)
+        vdi_info.vdiType = VdiType.VHD
         mock_getAll.return_value = {vdi_uuid: '0'}
-        mock_getVDIInfo.return_value = {vdi_uuid: lvhdutil.VDIInfo(vdi_uuid)}
+        mock_getVDIInfo.return_value = {vdi_uuid: vdi_info}
 
         sr = self.create_LVMSR()
 
         sr._undoAllInflateJournals()
-        self.assertEqual(0, mock_lvhdutil_lvRefreshOnAllSlaves.call_count)
+        self.assertEqual(0, mock_lvmcowutil_refreshVolumeOnAllSlaves.call_count)
 
     @mock.patch('LVMSR.cleanup', autospec=True)
     @mock.patch('LVMSR.IPCFlag', autospec=True)
@@ -269,11 +274,12 @@ class TestLVMSR(unittest.TestCase, Stubs):
                     'vdi_type': 'vhd'
                 }
             }})
-        with mock.patch('LVHDSR.LVMMetadataHandler', autospec=True) as m, \
-             mock.patch('LVHDSR.vhdutil', autotspec=True) as v:
+        with mock.patch('LVMSR.LVMMetadataHandler', autospec=True) as m, \
+             mock.patch('vhdutil.VhdUtil', autotspec=True) as v:
             m.return_value.getMetadata.return_value = [
                 None, self.convert_vdi_to_meta(extended_vdi_data)]
-            v._getVHDParentNoCheck.return_value = None
+            v.return_value.getParentNoCheck.return_value = None
+            v.return_value.getDefaultPreallocationSizeVirt.return_value = vhdutil.VHD_MAX_VOLUME_SIZE
             sr.scan(sr.uuid)
 
             lvm_cache = mock_lvm_cache.return_value
@@ -302,19 +308,41 @@ class TestLVMVDI(unittest.TestCase, Stubs):
     def setUp(self) -> None:
         self.init_stubs()
 
-        lvhdutil_patcher = mock.patch('LVMSR.lvhdutil', autospec=True)
-        self.mock_lvhdutil = lvhdutil_patcher.start()
-        self.mock_lvhdutil.VG_LOCATION = lvhdutil.VG_LOCATION
-        self.mock_lvhdutil.VG_PREFIX = lvhdutil.VG_PREFIX
-        self.mock_lvhdutil.LV_PREFIX = lvhdutil.LV_PREFIX
-        vhdutil_patcher = mock.patch('LVMSR.vhdutil', autospec=True)
-        self.mock_vhdutil = vhdutil_patcher.start()
-        self.mock_vhdutil.MAX_CHAIN_SIZE = vhdutil.MAX_CHAIN_SIZE
+        getInfo_patcher = mock.patch('vhdutil.VhdUtil.getInfo')
+        self.mock_getInfo = getInfo_patcher.start()
+
+        getAllInfoFromVG_patcher = mock.patch('vhdutil.VhdUtil.getAllInfoFromVG', autospec=True)
+        self.mock_getAllInfoFromVG = getAllInfoFromVG_patcher.start()
+
+        getDepth_patcher = mock.patch('vhdutil.VhdUtil.getDepth')
+        self.mock_getDepth = getDepth_patcher.start()
+
+        setHidden_patcher = mock.patch('vhdutil.VhdUtil.setHidden', autospec=True)
+        self.mock_setHidden = setHidden_patcher.start()
+
+        snapshot_patcher = mock.patch('vhdutil.VhdUtil.snapshot')
+        self.mock_snapshot = snapshot_patcher.start()
+
+        getParent_patcher = mock.patch('vhdutil.VhdUtil.getParent')
+        self.getParent = getParent_patcher.start()
+
+        getSizePhys_patcher = mock.patch('vhdutil.VhdUtil.getSizePhys', autospec=True)
+        self.mock_getSizePhys = getSizePhys_patcher.start()
+
+        mock_getVDIInfo_patcher = mock.patch('LVMSR.LvmCowUtil.getVDIInfo')
+        self.mock_getVDIInfo = mock_getVDIInfo_patcher.start()
+
+        mock_getVolumeInfo_patcher = mock.patch('LVMSR.LvmCowUtil.getVolumeInfo')
+        self.mock_getVolumeInfo = mock_getVolumeInfo_patcher.start()
+
+        mock_deflate_patcher = mock.patch('LVMSR.LvmCowUtil.deflate', autospec=True)
+        self.mock_deflate = mock_deflate_patcher.start()
+
         lvutil_patcher = mock.patch('LVMSR.lvutil', autospec=True)
         self.mock_lvutil = lvutil_patcher.start()
         vdi_util_patcher = mock.patch('VDI.util', autospec=True)
         self.mock_vdi_util = vdi_util_patcher.start()
-        sr_util_patcher = mock.patch('LVMSR.util', autospec=True)
+        sr_util_patcher = mock.patch('LVMSR.util')
         self.mock_sr_util = sr_util_patcher.start()
         self.mock_sr_util.gen_uuid.side_effect = str(uuid.uuid4())
         xmlrpclib_patcher = mock.patch('VDI.xmlrpc.client', autospec=True)
@@ -345,8 +373,7 @@ class TestLVMVDI(unittest.TestCase, Stubs):
         return LVMSR.LVMSR(srcmd, "some SR UUID")
 
     def get_dummy_vdi(self, vdi_uuid):
-        self.mock_lvhdutil.getVDIInfo.return_value = {
-            vdi_uuid: lvhdutil.VDIInfo(vdi_uuid)}
+        self.mock_getVDIInfo.return_value = {vdi_uuid: lvmcowutil.VDIInfo(vdi_uuid)}
 
         mock_lv =  lvutil.LVInfo('test-lv')
         mock_lv.size = 10240
@@ -354,15 +381,14 @@ class TestLVMVDI(unittest.TestCase, Stubs):
         mock_lv.hidden = False
         mock_lv.vdiType = VdiType.VHD
 
-        self.mock_lvhdutil.getLVInfo.return_value = {
-            vdi_uuid: mock_lv}
+        self.mock_getVolumeInfo.return_value = {vdi_uuid: mock_lv}
 
         return mock_lv
 
     def get_dummy_vhd(self, vdi_uuid, hidden):
-        test_vhdInfo = vhdutil.VHDInfo(vdi_uuid)
-        test_vhdInfo.hidden = hidden
-        self.mock_vhdutil.getVHDInfo.return_value = test_vhdInfo
+        test_imageInfo = cowutil.CowImageInfo(vdi_uuid)
+        test_imageInfo.hidden = hidden
+        self.mock_getInfo.return_value = test_imageInfo
 
     @mock.patch('LVMSR.lock.Lock', autospec=True)
     @mock.patch('SR.XenAPI')
@@ -370,6 +396,7 @@ class TestLVMVDI(unittest.TestCase, Stubs):
         """
         Successfully create clone
         """
+        import sys
 
         # Arrange
         xapi_session = mock_xenapi.xapi_local.return_value
@@ -383,10 +410,29 @@ class TestLVMVDI(unittest.TestCase, Stubs):
         sr.legacyMode = False
         sr.srcmd.params = {'vdi_ref': 'test ref'}
 
+        self.mock_sr_util.pathexists.side_effect = [
+            False,
+            False,
+            False, # AIO
+            True,  # VHD
+            False,
+            True,
+            True,
+            False,
+            False, # AIO
+            True,  # VHD
+            False,
+            True,
+            False,
+            True,
+            False,
+            True,
+            False
+        ]
+
         vdi = sr.vdi('some VDI UUID')
-        self.mock_sr_util.pathexists.return_value = True
 
-        self.mock_vhdutil.getDepth.return_value = 1
+        self.mock_getDepth.return_value = 1
 
         # Act
         clone = vdi.clone(sr.uuid, 'some VDI UUID')
@@ -418,12 +464,31 @@ class TestLVMVDI(unittest.TestCase, Stubs):
             }
         sr.cmd = "vdi_snapshot"
 
+        self.mock_sr_util.pathexists.side_effect = [
+            False,
+            False,
+            False, # AIO
+            True,  # VHD
+            False,
+            True,
+            True,
+            False,
+            False, # AIO
+            True,  # VHD
+            False,
+            True,
+            False,
+            True,
+            False,
+            True,
+            False
+        ]
+
         vdi = sr.vdi('some VDI UUID')
         vdi.vdi_type = VdiType.VHD
-        self.mock_sr_util.pathexists.return_value = True
         self.mock_sr_util.get_hosts_attached_on.return_value = ["hostref2"]
         self.mock_sr_util.get_this_host_ref.return_value = ["hostref1"]
-        self.mock_vhdutil.getDepth.return_value = 1
+        self.mock_getDepth.return_value = 1
 
         # Act
         snap = vdi.snapshot(sr.uuid, "Dummy UUID")
@@ -455,14 +520,33 @@ class TestLVMVDI(unittest.TestCase, Stubs):
             }
         sr.cmd = "vdi_snapshot"
 
+        self.mock_sr_util.pathexists.side_effect = [
+            False,
+            False,
+            False, # AIO
+            True,  # VHD
+            False,
+            True,
+            True,
+            False,
+            False, # AIO
+            True,  # VHD
+            False,
+            True,
+            False,
+            True,
+            False,
+            True,
+            False
+        ]
+
         vdi = sr.vdi('some VDI UUID')
         vdi.vdi_type = VdiType.VHD
-        self.mock_sr_util.pathexists.return_value = True
         self.mock_sr_util.get_hosts_attached_on.return_value = ["hostref2"]
         self.mock_sr_util.get_this_host_ref.return_value = ["hostref1"]
         self.mock_vdi_util.sr_get_capability.return_value = {
             'VDI_CONFIG_CBT'}
-        self.mock_vhdutil.getDepth.return_value = 1
+        self.mock_getDepth.return_value = 1
 
         # Act
         with mock.patch('lock.Lock'):
@@ -472,11 +556,11 @@ class TestLVMVDI(unittest.TestCase, Stubs):
         self.assertIsNotNone(snap)
         self.assertEqual(self.mock_cbtutil.set_cbt_child.call_count, 3)
 
-    @mock.patch('LVHDSR.Lock', autospec=True)
+    @mock.patch('lock.Lock', autospec=True)
     @mock.patch('SR.XenAPI')
     def test_snapshot_secondary_success(self, mock_xenapi, mock_lock):
         """
-        LVHDSR.snapshot, attached on host with secondary mirror
+        LVMSR.snapshot, attached on host with secondary mirror
         """
         # Arrange
         xapi_session = mock_xenapi.xapi_local.return_value
@@ -488,7 +572,7 @@ class TestLVMVDI(unittest.TestCase, Stubs):
         self.get_dummy_vdi(vdi_uuid)
         self.get_dummy_vhd(vdi_uuid, False)
 
-        sr = self.create_LVHDSR()
+        sr = self.create_LVMSR()
         sr.isMaster = True
         sr.legacyMode = False
         sr.srcmd.params = {
@@ -499,12 +583,33 @@ class TestLVMVDI(unittest.TestCase, Stubs):
             }
         sr.cmd = "vdi_snapshot"
 
+        self.mock_sr_util.pathexists.side_effect = [
+            False,
+            False,
+            False, # AIO
+            True,  # VHD
+            False, # QCOW2
+            False,
+            True,
+            True,
+            False,
+            False, # AIO
+            True,  # VHD
+            False, # QCOW2
+            False,
+            True,
+            False,
+            True,
+            False,
+            True,
+            False
+        ]
+
         vdi = sr.vdi('some VDI UUID')
-        vdi.vdi_type = vhdutil.VDI_TYPE_VHD
-        self.mock_sr_util.pathexists.return_value = True
+        vdi.vdi_type = VdiType.VHD
         self.mock_sr_util.get_hosts_attached_on.return_value = ["hostref2"]
         self.mock_sr_util.get_this_host_ref.return_value = ["hostref1"]
-        self.mock_vhdutil.getDepth.return_value = 1
+        self.mock_getDepth.return_value = 1
 
         # Act
         with mock.patch('lock.Lock'):
diff --git a/tests/test_cbt.py b/tests/test_cbt.py
index 530aee10..bf8d176c 100644
--- a/tests/test_cbt.py
+++ b/tests/test_cbt.py
@@ -6,7 +6,6 @@ import testlib
 import unittest
 import uuid
 import VDI
-import vhdutil
 import xs_errors
 import util
 import errno
diff --git a/tests/test_cleanup.py b/tests/test_cleanup.py
index ce2138b8..0737a3bc 100644
--- a/tests/test_cleanup.py
+++ b/tests/test_cleanup.py
@@ -9,10 +9,10 @@ import uuid
 from uuid import uuid4
 
 import cleanup
+import cowutil
 import lock
 
 import util
-import vhdutil
 
 import ipc
 
@@ -1484,7 +1484,7 @@ class TestSR(unittest.TestCase):
 
     @mock.patch('cleanup.os.unlink', autospec=True)
     @mock.patch('cleanup.util', autospec=True)
-    @mock.patch('cleanup.vhdutil', autospec=True)
+    @mock.patch('vhdutil.VhdUtil')
     @mock.patch('cleanup.journaler.Journaler', autospec=True)
     @mock.patch('cleanup.Util.runAbortable')
     def test_coalesce_success(
@@ -1496,6 +1496,7 @@ class TestSR(unittest.TestCase):
         self.xapi_mock.getConfigVDI.return_value = {}
 
         mock_abortable.side_effect = self.runAbortable
+        mock_vhdutil.return_value.check.return_value = cowutil.CowUtil.CheckResult.Success
 
         sr_uuid = uuid4()
         sr = create_cleanup_sr(self.xapi_mock, uuid=str(sr_uuid))
@@ -1533,7 +1534,7 @@ class TestSR(unittest.TestCase):
 
     @mock.patch('cleanup.os.unlink', autospec=True)
     @mock.patch('cleanup.util', autospec=True)
-    @mock.patch('cleanup.vhdutil', autospec=True)
+    @mock.patch('vhdutil.VhdUtil')
     @mock.patch('cleanup.journaler.Journaler', autospec=True)
     @mock.patch('cleanup.Util.runAbortable')
     def test_coalesce_error(
@@ -1543,6 +1544,7 @@ class TestSR(unittest.TestCase):
         Handle errors in coalesce
         """
         mock_util.SMException = util.SMException
+        mock_vhdutil.return_value.check.return_value = cowutil.CowUtil.CheckResult.Success
 
         self.xapi_mock.getConfigVDI.return_value = {}
 
@@ -1562,16 +1564,16 @@ class TestSR(unittest.TestCase):
         vdis = self.add_vdis_for_coalesce(sr)
         mock_journaler.get.return_value = None
 
-        mock_vhdutil.getParent.return_value = vdis['parent'].path
+        mock_vhdutil.return_value.getParent.return_value = vdis['parent'].path
 
         sr.coalesce(vdis['vdi'], False)
 
         self.assertIn(vdis['vdi'], sr._failedCoalesceTargets)
-        mock_vhdutil.repair.assert_called_with(vdis['parent'].path)
+        mock_vhdutil.return_value.repair.assert_called_with(vdis['parent'].path)
 
     @mock.patch('cleanup.os.unlink', autospec=True)
     @mock.patch('cleanup.util', autospec=True)
-    @mock.patch('cleanup.vhdutil', autospec=True)
+    @mock.patch('vhdutil.VhdUtil')
     @mock.patch('cleanup.journaler.Journaler', autospec=True)
     @mock.patch('cleanup.Util.runAbortable')
     def test_coalesce_error_raw_parent(
@@ -1581,6 +1583,7 @@ class TestSR(unittest.TestCase):
         Handle errors in coalesce with raw parent
         """
         mock_util.SMException = util.SMException
+        mock_vhdutil.return_value.check.return_value = cowutil.CowUtil.CheckResult.Success
 
         self.xapi_mock.getConfigVDI.return_value = {}
 
@@ -1601,12 +1604,12 @@ class TestSR(unittest.TestCase):
         vdis['parent'].vdi_type = VdiType.RAW
         mock_journaler.get.return_value = None
 
-        mock_vhdutil.getParent.return_value = vdis['parent'].path
+        mock_vhdutil.return_value.getParent.return_value = vdis['parent'].path
 
         sr.coalesce(vdis['vdi'], False)
 
         self.assertIn(vdis['vdi'], sr._failedCoalesceTargets)
-        self.assertEqual(0, mock_vhdutil.repair.call_count)
+        self.assertEqual(0, mock_vhdutil.return_value.repair.call_count)
 
     def test_tag_children_for_relink_activation(self):
         """
diff --git a/tests/test_on_slave.py b/tests/test_on_slave.py
index 5629db45..33792d8e 100644
--- a/tests/test_on_slave.py
+++ b/tests/test_on_slave.py
@@ -5,10 +5,9 @@ import unittest
 import unittest.mock as mock
 import uuid
 
-import lvhdutil
 import lvmcache
+import lvmcowutil
 import util
-import vhdutil
 
 import on_slave
 
@@ -208,7 +207,7 @@ class Test_on_slave_multi(unittest.TestCase):
         child_uuid = str(uuid.uuid4())
         child_fileName = "child-vdi.vhd"
         parent_fileName = "parent-vdi.vhd"
-        tmpName = lvhdutil.LV_PREFIX[VdiType.VHD] + \
+        tmpName = lvmcowutil.LV_PREFIX[VdiType.VHD] + \
                 self.TMP_RENAME_PREFIX + child_uuid
 
         args = {"vgName": vgName,
diff --git a/tests/test_vhdutil.py b/tests/test_vhdutil.py
index 6aa91e15..25ea1004 100644
--- a/tests/test_vhdutil.py
+++ b/tests/test_vhdutil.py
@@ -1,8 +1,8 @@
+from sm_typing import override
 
 import unittest
 import zlib
 
-import lvhdutil
 import vhdutil
 import xs_errors
 
@@ -16,41 +16,41 @@ VHD_UTIL = '/usr/bin/vhd-util'
 
 
 class TestVhdUtil(unittest.TestCase):
+    @override
+    def setUp(self):
+        self.vhdutil = vhdutil.VhdUtil()
 
     def test_validate_and_round_min_size(self):
-        size = vhdutil.validate_and_round_vhd_size(2 * 1024 * 1024)
-
+        size = self.vhdutil.validateAndRoundImageSize(2 * 1024 * 1024)
         self.assertTrue(size == 2 * 1024 * 1024)
 
     def test_validate_and_round_max_size(self):
-        size = vhdutil.validate_and_round_vhd_size(vhdutil.MAX_VHD_SIZE)
-
-        self.assertTrue(size == vhdutil.MAX_VHD_SIZE)
+        size = self.vhdutil.validateAndRoundImageSize(self.vhdutil.getMaxImageSize())
+        self.assertTrue(size == self.vhdutil.getMaxImageSize())
 
     def test_validate_and_round_odd_size_up_to_next_boundary(self):
-        size = vhdutil.validate_and_round_vhd_size(vhdutil.MAX_VHD_SIZE - 1)
-
-        self.assertTrue(size == vhdutil.MAX_VHD_SIZE)
+        size = self.vhdutil.validateAndRoundImageSize(self.vhdutil.getMaxImageSize() - 1)
+        self.assertTrue(size == self.vhdutil.getMaxImageSize())
 
     def test_validate_and_round_negative(self):
         with self.assertRaises(xs_errors.SROSError):
-            vhdutil.validate_and_round_vhd_size(-1)
+            self.vhdutil.validateAndRoundImageSize(-1)
 
     def test_validate_and_round_too_large(self):
         with self.assertRaises(xs_errors.SROSError):
-            vhdutil.validate_and_round_vhd_size(vhdutil.MAX_VHD_SIZE + 1)
+            self.vhdutil.validateAndRoundImageSize(self.vhdutil.getMaxImageSize() + 1)
 
     @testlib.with_context
     def test_calc_overhead_empty_small(self, context):
         virtual_size = 25 * 1024 * 1024
-        result = vhdutil.calcOverheadEmpty(virtual_size)
+        result = self.vhdutil.calcOverheadEmpty(virtual_size)
 
         self.assertEqual(4096, result)
 
     @testlib.with_context
     def test_calc_overhead_empty_max(self, context):
         virtual_size = 2 * 1024 * 1024 * 1024 * 1024  # 2TB
-        result = vhdutil.calcOverheadEmpty(virtual_size)
+        result = self.vhdutil.calcOverheadEmpty(virtual_size)
 
         # Footer -> 3 * 1024
         # BAT -> (Size in MB / 2) * 4 = 4194304
@@ -63,14 +63,14 @@ class TestVhdUtil(unittest.TestCase):
     def test_calc_overhead_bitmap_round_blocks(self, context):
         virtual_size = 24 * 1024 * 1024
 
-        result = vhdutil.calcOverheadBitmap(virtual_size)
+        result = self.vhdutil.calcOverheadBitmap(virtual_size)
 
         self.assertEqual(49152, result)
     @testlib.with_context
     def test_calc_overhead_bitmap_extra_block(self, context):
         virtual_size = 25 * 1024 * 1024
 
-        result = vhdutil.calcOverheadBitmap(virtual_size)
+        result = self.vhdutil.calcOverheadBitmap(virtual_size)
 
         self.assertEqual(53248, result)
 
@@ -86,7 +86,7 @@ class TestVhdUtil(unittest.TestCase):
         context.add_executable(VHD_UTIL, test_function)
 
         # Act
-        result = vhdutil.getSizeVirt(TEST_VHD_NAME)
+        result = self.vhdutil.getSizeVirt(TEST_VHD_NAME)
 
         # Assert
         self.assertEqual(25*1024*1024, result)
@@ -107,7 +107,7 @@ class TestVhdUtil(unittest.TestCase):
         context.add_executable(VHD_UTIL, test_function)
 
         # Act
-        vhdutil.setSizeVirt(
+        self.vhdutil.setSizeVirt(
             TEST_VHD_NAME, 30*1024*1024,
             '/test/path/test-vdi.jrnl')
 
@@ -129,7 +129,7 @@ class TestVhdUtil(unittest.TestCase):
         context.add_executable(VHD_UTIL, test_function)
 
         # Act
-        vhdutil.setSizeVirtFast(
+        self.vhdutil.setSizeVirtFast(
             TEST_VHD_NAME, 30*1024*1024)
 
         # Assert
@@ -151,7 +151,7 @@ class TestVhdUtil(unittest.TestCase):
         context.add_executable(VHD_UTIL, test_function)
 
         # Act
-        result = vhdutil.getBlockBitmap(TEST_VHD_NAME)
+        result = self.vhdutil.getBlockBitmap(TEST_VHD_NAME)
 
         # Assert
         self.assertIsNotNone(result)
@@ -175,7 +175,7 @@ class TestVhdUtil(unittest.TestCase):
         context.add_executable(VHD_UTIL,
                                test_function)
         # Act
-        vhdutil.create(TEST_VHD_NAME, 30 * 1024 * 1024, False)
+        self.vhdutil.create(TEST_VHD_NAME, 30 * 1024 * 1024, False)
 
         # Assert
         self.assertEqual(
@@ -196,7 +196,7 @@ class TestVhdUtil(unittest.TestCase):
 
         context.add_executable(VHD_UTIL, test_function)
         # Act
-        vhdutil.create(TEST_VHD_NAME, 30 * 1024 * 1024, True)
+        self.vhdutil.create(TEST_VHD_NAME, 30 * 1024 * 1024, True)
 
         # Assert
         self.assertEqual(
@@ -217,8 +217,9 @@ class TestVhdUtil(unittest.TestCase):
 
         context.add_executable(VHD_UTIL, test_function)
         # Act
-        vhdutil.create(TEST_VHD_NAME, 30 * 1024 * 1024, False,
-                       msize=lvhdutil.MSIZE_MB)
+        self.vhdutil.create(
+            TEST_VHD_NAME, 30 * 1024 * 1024, False, msize=self.vhdutil.getDefaultPreallocationSizeVirt()
+        )
 
         # Assert
         self.assertEqual(
@@ -241,7 +242,7 @@ class TestVhdUtil(unittest.TestCase):
         context.add_executable(VHD_UTIL, test_function)
 
         # Act
-        vhdutil.snapshot(
+        self.vhdutil.snapshot(
             TEST_VHD_NAME,
             TEST_VHD_PATH,
             False)
@@ -267,7 +268,7 @@ class TestVhdUtil(unittest.TestCase):
         context.add_executable(VHD_UTIL, test_function)
 
         # Act
-        vhdutil.snapshot(
+        self.vhdutil.snapshot(
             TEST_VHD_NAME,
             TEST_VHD_PATH,
             True)
@@ -293,11 +294,12 @@ class TestVhdUtil(unittest.TestCase):
         context.add_executable(VHD_UTIL, test_function)
 
         # Act
-        vhdutil.snapshot(
+        self.vhdutil.snapshot(
             TEST_VHD_NAME,
             TEST_VHD_PATH,
             False,
-            msize=lvhdutil.MSIZE_MB)
+            msize=self.vhdutil.getDefaultPreallocationSizeVirt()
+        )
 
         # Assert
         self.assertEqual(
@@ -321,7 +323,7 @@ class TestVhdUtil(unittest.TestCase):
         context.add_executable(VHD_UTIL, test_function)
 
         # Act
-        vhdutil.snapshot(
+        self.vhdutil.snapshot(
             TEST_VHD_NAME,
             TEST_VHD_PATH,
             False,
@@ -347,7 +349,7 @@ class TestVhdUtil(unittest.TestCase):
         context.add_executable(VHD_UTIL, test_function)
 
         # Act/Assert
-        self.assertEqual(0, vhdutil.coalesce(TEST_VHD_PATH))
+        self.assertEqual(0, self.vhdutil.coalesce(TEST_VHD_PATH))
 
     @testlib.with_context
     def test_coalesce_with_sector_count(self, context):
@@ -361,12 +363,12 @@ class TestVhdUtil(unittest.TestCase):
         context.add_executable(VHD_UTIL, test_function)
 
         # Act/Assert
-        self.assertEqual(25, vhdutil.coalesce(TEST_VHD_PATH))
+        self.assertEqual(25 * vhdutil.VHD_SECTOR_SIZE, self.vhdutil.coalesce(TEST_VHD_PATH))
 
     @testlib.with_context
     def test_get_vhd_info_allocated_size(self, context):
         """
-        Test that vhdutil.getVHDInfo return the allocated size in byte
+        Test that vhdutil.getInfo return the allocated size in byte
         """
         # Arrange
         def test_function(args, inp):
@@ -374,7 +376,7 @@ class TestVhdUtil(unittest.TestCase):
 
         context.add_executable(VHD_UTIL, test_function)
         import FileSR
-        vhdinfo = vhdutil.getVHDInfo(TEST_VHD_PATH, FileSR.FileVDI.extractUuid)
+        vhdinfo = self.vhdutil.getInfo(TEST_VHD_PATH, FileSR.FileVDI.extractUuid)
 
         # Act/Assert
         self.assertEqual(18856*2*1024*1024 , vhdinfo.sizeAllocated)
@@ -394,7 +396,7 @@ class TestVhdUtil(unittest.TestCase):
         context.add_executable(VHD_UTIL, test_function)
 
         # Act
-        result = vhdutil.getAllocatedSize(TEST_VHD_NAME)
+        result = self.vhdutil.getAllocatedSize(TEST_VHD_NAME)
 
         # Assert
         self.assertEqual(18856*2*1024*1024, result)
