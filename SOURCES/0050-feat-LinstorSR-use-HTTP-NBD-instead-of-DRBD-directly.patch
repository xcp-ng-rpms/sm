From 7983be637bf274036cd89552891cc406bf20ea0a Mon Sep 17 00:00:00 2001
From: Ronan Abhamon <ronan.abhamon@vates.fr>
Date: Thu, 12 May 2022 17:52:35 +0200
Subject: [PATCH] feat(LinstorSR): use HTTP/NBD instead of DRBD directly with
 heartbeat VDI

Signed-off-by: Ronan Abhamon <ronan.abhamon@vates.fr>
---
 Makefile                        |   1 +
 drivers/LinstorSR.py            | 380 ++++++++++++++++++++++++++++----
 drivers/linstor-manager         |  43 +---
 drivers/linstorvhdutil.py       |   6 +-
 drivers/linstorvolumemanager.py |  17 +-
 drivers/util.py                 |  49 ++++
 scripts/fork-log-daemon         |  34 +++
 7 files changed, 438 insertions(+), 92 deletions(-)
 create mode 100755 scripts/fork-log-daemon

diff --git a/Makefile b/Makefile
index 2eb6a868..af1011a1 100755
--- a/Makefile
+++ b/Makefile
@@ -239,6 +239,7 @@ install: precheck
 	install -m 755 drivers/iscsilib.py $(SM_STAGING)$(SM_DEST)
 	install -m 755 drivers/fcoelib.py $(SM_STAGING)$(SM_DEST)
 	mkdir -p $(SM_STAGING)$(LIBEXEC)
+	install -m 755 scripts/fork-log-daemon $(SM_STAGING)$(LIBEXEC)
 	install -m 755 scripts/local-device-change $(SM_STAGING)$(LIBEXEC)
 	install -m 755 scripts/check-device-sharing $(SM_STAGING)$(LIBEXEC)
 	install -m 755 scripts/usb_change $(SM_STAGING)$(LIBEXEC)
diff --git a/drivers/LinstorSR.py b/drivers/LinstorSR.py
index 15b9dda3..5bdf6769 100755
--- a/drivers/LinstorSR.py
+++ b/drivers/LinstorSR.py
@@ -34,9 +34,13 @@ import cleanup
 import distutils
 import errno
 import functools
+import os
+import re
 import scsiutil
+import signal
 import SR
 import SRCommand
+import subprocess
 import time
 import traceback
 import util
@@ -52,6 +56,8 @@ from srmetadata import \
 
 HIDDEN_TAG = 'hidden'
 
+FORK_LOG_DAEMON = '/opt/xensource/libexec/fork-log-daemon'
+
 # ==============================================================================
 
 # TODO: Supports 'VDI_INTRODUCE', 'VDI_RESET_ON_BOOT/2', 'SR_TRIM',
@@ -354,7 +360,9 @@ class LinstorSR(SR.SR):
 
         def load(self, *args, **kwargs):
             if not self._has_session:
-                if self.srcmd.cmd == 'vdi_attach_from_config':
+                if self.srcmd.cmd in (
+                    'vdi_attach_from_config', 'vdi_detach_from_config'
+                ):
                     # We must have a valid LINSTOR instance here without using
                     # the XAPI.
                     controller_uri = get_controller_uri()
@@ -1444,7 +1452,7 @@ class LinstorVDI(VDI.VDI):
             if (
                 self.sr.srcmd.cmd == 'vdi_attach_from_config' or
                 self.sr.srcmd.cmd == 'vdi_detach_from_config'
-            ) and self.sr.srcmd.params['vdi_uuid'] == self.uuid:
+            ):
                 self.vdi_type = vhdutil.VDI_TYPE_RAW
                 self.path = self.sr.srcmd.params['vdi_path']
             else:
@@ -1529,7 +1537,7 @@ class LinstorVDI(VDI.VDI):
 
             self._linstor.create_volume(
                 self.uuid, volume_size, persistent=False,
-                volume_name=volume_name, no_diskless=(volume_name is not None)
+                volume_name=volume_name
             )
             volume_info = self._linstor.get_volume_info(self.uuid)
 
@@ -1631,8 +1639,9 @@ class LinstorVDI(VDI.VDI):
 
     def attach(self, sr_uuid, vdi_uuid):
         util.SMlog('LinstorVDI.attach for {}'.format(self.uuid))
+        attach_from_config = self.sr.srcmd.cmd == 'vdi_attach_from_config'
         if (
-            self.sr.srcmd.cmd != 'vdi_attach_from_config' or
+            not attach_from_config or
             self.sr.srcmd.params['vdi_uuid'] != self.uuid
         ) and self.sr._journaler.has_entries(self.uuid):
             raise xs_errors.XenError(
@@ -1641,50 +1650,54 @@ class LinstorVDI(VDI.VDI):
                 'scan SR first to trigger auto-repair'
             )
 
-        writable = 'args' not in self.sr.srcmd.params or \
-            self.sr.srcmd.params['args'][0] == 'true'
+        if not attach_from_config or self.sr._is_master:
+            writable = 'args' not in self.sr.srcmd.params or \
+                self.sr.srcmd.params['args'][0] == 'true'
 
-        # We need to inflate the volume if we don't have enough place
-        # to mount the VHD image. I.e. the volume capacity must be greater
-        # than the VHD size + bitmap size.
-        need_inflate = True
-        if self.vdi_type == vhdutil.VDI_TYPE_RAW or not writable or \
-                self.capacity >= compute_volume_size(self.size, self.vdi_type):
-            need_inflate = False
-
-        if need_inflate:
-            try:
-                self._prepare_thin(True)
-            except Exception as e:
-                raise xs_errors.XenError(
-                    'VDIUnavailable',
-                    opterr='Failed to attach VDI during "prepare thin": {}'
-                    .format(e)
-                )
+            # We need to inflate the volume if we don't have enough place
+            # to mount the VHD image. I.e. the volume capacity must be greater
+            # than the VHD size + bitmap size.
+            need_inflate = True
+            if (
+                self.vdi_type == vhdutil.VDI_TYPE_RAW or
+                not writable or
+                self.capacity >= compute_volume_size(self.size, self.vdi_type)
+            ):
+                need_inflate = False
 
-        if not util.pathexists(self.path):
-            raise xs_errors.XenError(
-                'VDIUnavailable', opterr='Could not find: {}'.format(self.path)
-            )
+            if need_inflate:
+                try:
+                    self._prepare_thin(True)
+                except Exception as e:
+                    raise xs_errors.XenError(
+                        'VDIUnavailable',
+                        opterr='Failed to attach VDI during "prepare thin": {}'
+                        .format(e)
+                    )
 
         if not hasattr(self, 'xenstore_data'):
             self.xenstore_data = {}
+        self.xenstore_data['storage-type'] = LinstorSR.DRIVER_TYPE
 
-        # TODO: Is it useful?
-        self.xenstore_data.update(scsiutil.update_XS_SCSIdata(
-            self.uuid, scsiutil.gen_synthetic_page_data(self.uuid)
-        ))
+        if attach_from_config and self.path.startswith('/dev/http-nbd/'):
+            return self._attach_using_http_nbd()
 
-        self.xenstore_data['storage-type'] = LinstorSR.DRIVER_TYPE
+        if not util.pathexists(self.path):
+            raise xs_errors.XenError(
+                'VDIUnavailable', opterr='Could not find: {}'.format(self.path)
+            )
 
         self.attached = True
-
         return VDI.VDI.attach(self, self.sr.uuid, self.uuid)
 
     def detach(self, sr_uuid, vdi_uuid):
         util.SMlog('LinstorVDI.detach for {}'.format(self.uuid))
+        detach_from_config = self.sr.srcmd.cmd == 'vdi_detach_from_config'
         self.attached = False
 
+        if detach_from_config and self.path.startswith('/dev/http-nbd/'):
+            return self._detach_using_http_nbd()
+
         if self.vdi_type == vhdutil.VDI_TYPE_RAW:
             return
 
@@ -1816,25 +1829,40 @@ class LinstorVDI(VDI.VDI):
 
         util.SMlog('LinstorVDI.generate_config for {}'.format(self.uuid))
 
-        if not self.path or not util.pathexists(self.path):
-            available = False
-            # Try to refresh symlink path...
-            try:
-                self.path = self._linstor.get_device_path(vdi_uuid)
-                available = util.pathexists(self.path)
-            except Exception:
-                pass
-            if not available:
-                raise xs_errors.XenError('VDIUnavailable')
-
         resp = {}
         resp['device_config'] = self.sr.dconf
         resp['sr_uuid'] = sr_uuid
         resp['vdi_uuid'] = self.uuid
         resp['sr_sm_config'] = self.sr.sm_config
-        resp['vdi_path'] = self.path
         resp['command'] = 'vdi_attach_from_config'
 
+        # By default, we generate a normal config.
+        # But if the disk is persistent, we must use a HTTP/NBD
+        # server to ensure we can always write or read data.
+        # Why? DRBD is unsafe when used with more than 4 hosts:
+        # We are limited to use 1 diskless and 3 full.
+        # We can't increase this limitation, so we use a NBD/HTTP device
+        # instead.
+        volume_name = self._linstor.get_volume_name(self.uuid)
+        if volume_name not in [
+            'xcp-persistent-ha-statefile', 'xcp-persistent-redo-log'
+        ]:
+            if not self.path or not util.pathexists(self.path):
+                available = False
+                # Try to refresh symlink path...
+                try:
+                    self.path = self._linstor.get_device_path(vdi_uuid)
+                    available = util.pathexists(self.path)
+                except Exception:
+                    pass
+                if not available:
+                    raise xs_errors.XenError('VDIUnavailable')
+
+                resp['vdi_path'] = self.path
+        else:
+            # Axiom: DRBD device is present on at least one host.
+            resp['vdi_path'] = '/dev/http-nbd/' + volume_name
+
         config = xmlrpclib.dumps(tuple([resp]), 'vdi_attach_from_config')
         return xmlrpclib.dumps((config,), "", True)
 
@@ -2314,6 +2342,268 @@ class LinstorVDI(VDI.VDI):
 
         return ret_vdi.get_params()
 
+    @staticmethod
+    def _start_persistent_http_server(volume_name):
+        null = None
+        pid_path = None
+        http_server = None
+
+        try:
+            null = open(os.devnull, 'w')
+
+            if volume_name == 'xcp-persistent-ha-statefile':
+                port = '8076'
+            else:
+                port = '8077'
+
+            arguments = [
+                'http-disk-server',
+                '--disk',
+                '/dev/drbd/by-res/{}/0'.format(volume_name),
+                '--port',
+                port
+            ]
+
+            util.SMlog('Starting {} on port {}...'.format(arguments[0], port))
+            http_server = subprocess.Popen(
+                [FORK_LOG_DAEMON] + arguments,
+                stdout=null,
+                stderr=null,
+                # Ensure we use another group id to kill this process without
+                # touch the current one.
+                preexec_fn=os.setsid
+            )
+
+            pid_path = '/run/http-server-{}.pid'.format(volume_name)
+            with open(pid_path, 'w') as pid_file:
+                pid_file.write(str(http_server.pid))
+        except Exception as e:
+            if pid_path:
+                try:
+                    os.remove(pid_path)
+                except Exception:
+                    pass
+
+            if http_server:
+                # Kill process and children in this case...
+                os.killpg(os.getpgid(http_server.pid), signal.SIGTERM)
+
+            raise xs_errors.XenError(
+                'VDIUnavailable',
+                opterr='Failed to start http-server: {}'.format(e)
+            )
+        finally:
+            if null:
+                null.close()
+
+    def _start_persistent_nbd_server(self, volume_name):
+        null = None
+        pid_path = None
+        nbd_path = None
+        nbd_server = None
+
+        try:
+            null = open(os.devnull, 'w')
+
+            if volume_name == 'xcp-persistent-ha-statefile':
+                port = '8076'
+            else:
+                port = '8077'
+
+            arguments = [
+                'nbd-http-server',
+                '--socket-path',
+                '/run/{}.socket'.format(volume_name),
+                '--nbd-name',
+                volume_name,
+                '--urls',
+                ','.join(map(
+                    lambda host: "http://" + host + ':' + port,
+                    self.sr._hosts
+                ))
+            ]
+
+            util.SMlog('Starting {} using port {}...'.format(arguments[0], port))
+            nbd_server = subprocess.Popen(
+                [FORK_LOG_DAEMON] + arguments,
+                stdout=subprocess.PIPE,
+                stderr=subprocess.STDOUT,
+                # Ensure we use another group id to kill this process without
+                # touch the current one.
+                preexec_fn=os.setsid
+            )
+
+            reg_nbd_path = re.compile("^NBD `(/dev/nbd[0-9]+)` is now attached.$")
+            def get_nbd_path():
+                while nbd_server.poll() is None:
+                    line = nbd_server.stdout.readline()
+                    match = reg_nbd_path.match(line)
+                    if match:
+                        return match.group(1)
+            # Use a timeout to never block the smapi if there is a problem.
+            try:
+                nbd_path = util.timeout_call(10, get_nbd_path)
+                if nbd_path is None:
+                    raise Exception('Empty NBD path (NBD server is probably dead)')
+            except util.TimeoutException:
+                raise Exception('Unable to read NBD path')
+
+            pid_path = '/run/nbd-server-{}.pid'.format(volume_name)
+            with open(pid_path, 'w') as pid_file:
+                pid_file.write(str(nbd_server.pid))
+
+            util.SMlog('Create symlink: {} -> {}'.format(self.path, nbd_path))
+            os.symlink(nbd_path, self.path)
+        except Exception as e:
+            if pid_path:
+                try:
+                    os.remove(pid_path)
+                except Exception:
+                    pass
+
+            if nbd_path:
+                try:
+                    os.remove(nbd_path)
+                except Exception:
+                    pass
+
+            if nbd_server:
+                # Kill process and children in this case...
+                os.killpg(os.getpgid(nbd_server.pid), signal.SIGTERM)
+
+            raise xs_errors.XenError(
+                'VDIUnavailable',
+                opterr='Failed to start nbd-server: {}'.format(e)
+            )
+        finally:
+            if null:
+                null.close()
+
+    @classmethod
+    def _kill_persistent_server(self, type, volume_name, sig):
+        try:
+            path = '/run/{}-server-{}.pid'.format(type, volume_name)
+            if not os.path.exists(path):
+                return
+
+            pid = None
+            with open(path, 'r') as pid_file:
+                try:
+                    pid = int(pid_file.read())
+                except Exception:
+                    pass
+
+            if pid is not None and util.check_pid_exists(pid):
+                util.SMlog('Kill {} server {} (pid={})'.format(type, path, pid))
+                try:
+                    os.killpg(os.getpgid(pid), sig)
+                except Exception as e:
+                    util.SMlog('Failed to kill {} server: {}'.format(type, e))
+
+            os.remove(path)
+        except:
+            pass
+
+    @classmethod
+    def _kill_persistent_http_server(self, volume_name, sig=signal.SIGTERM):
+        return self._kill_persistent_server('nbd', volume_name, sig)
+
+    @classmethod
+    def _kill_persistent_nbd_server(self, volume_name, sig=signal.SIGTERM):
+        return self._kill_persistent_server('http', volume_name, sig)
+
+    def _check_http_nbd_volume_name(self):
+        volume_name = self.path[14:]
+        if volume_name not in [
+            'xcp-persistent-ha-statefile', 'xcp-persistent-redo-log'
+        ]:
+            raise xs_errors.XenError(
+                'VDIUnavailable',
+                opterr='Unsupported path: {}'.format(self.path)
+            )
+        return volume_name
+
+    def _attach_using_http_nbd(self):
+        volume_name = self._check_http_nbd_volume_name()
+
+        # Ensure there is no NBD and HTTP server running.
+        self._kill_persistent_nbd_server(volume_name)
+        self._kill_persistent_http_server(volume_name)
+
+        # 0. Fetch drbd path.
+        must_get_device_path = True
+        if not self.sr._is_master:
+            # We are on a slave, we must try to find a diskful locally.
+            try:
+                volume_info = self._linstor.get_volume_info(self.uuid)
+            except Exception as e:
+                raise xs_errors.XenError(
+                    'VDIUnavailable',
+                    opterr='Cannot get volume info of {}: {}'
+                    .format(self.uuid, e)
+                )
+
+            must_get_device_path = volume_info.is_diskful
+
+        drbd_path = None
+        if must_get_device_path or self.sr._is_master:
+            # If we are master, we must ensure we have a diskless
+            # or diskful available to init HA.
+            # It also avoid this error in xensource.log
+            # (/usr/libexec/xapi/cluster-stack/xhad/ha_set_pool_state):
+            # init exited with code 8 [stdout = ''; stderr = 'SF: failed to write in State-File \x10 (fd 4208696). (sys 28)\x0A']
+            # init returned MTC_EXIT_CAN_NOT_ACCESS_STATEFILE (State-File is inaccessible)
+            available = False
+            try:
+                drbd_path = self._linstor.get_device_path(self.uuid)
+                available = util.pathexists(drbd_path)
+            except Exception:
+                pass
+
+            if not available:
+                raise xs_errors.XenError(
+                    'VDIUnavailable',
+                    opterr='Cannot get device path of {}'.format(self.uuid)
+                )
+
+        # 1. Prepare http-nbd folder.
+        try:
+            if not os.path.exists('/dev/http-nbd/'):
+                os.makedirs('/dev/http-nbd/')
+            elif os.path.islink(self.path):
+                os.remove(self.path)
+        except OSError as e:
+            if e.errno != errno.EEXIST:
+                raise xs_errors.XenError(
+                    'VDIUnavailable',
+                    opterr='Cannot prepare http-nbd: {}'.format(e)
+                )
+
+        # 2. Start HTTP service if we have a diskful or if we are master.
+        http_service = None
+        if drbd_path:
+            assert(drbd_path in (
+                '/dev/drbd/by-res/xcp-persistent-ha-statefile/0',
+                '/dev/drbd/by-res/xcp-persistent-redo-log/0'
+            ))
+            self._start_persistent_http_server(volume_name)
+
+        # 3. Start NBD server in all cases.
+        try:
+            self._start_persistent_nbd_server(volume_name)
+        except Exception as e:
+            if drbd_path:
+                self._kill_persistent_http_server(volume_name)
+            raise
+
+        self.attached = True
+        return VDI.VDI.attach(self, self.sr.uuid, self.uuid)
+
+    def _detach_using_http_nbd(self):
+        volume_name = self._check_http_nbd_volume_name()
+        self._kill_persistent_nbd_server(volume_name)
+        self._kill_persistent_http_server(volume_name)
+
 # ------------------------------------------------------------------------------
 
 
diff --git a/drivers/linstor-manager b/drivers/linstor-manager
index af8d2b9e..30230adb 100755
--- a/drivers/linstor-manager
+++ b/drivers/linstor-manager
@@ -36,7 +36,7 @@ import vhdutil
 
 
 FIREWALL_PORT_SCRIPT = '/etc/xapi.d/plugins/firewall-port'
-LINSTOR_PORTS = [3366, 3370, 3376, 3377, '7000:8000']
+LINSTOR_PORTS = [3366, 3370, 3376, 3377, '7000:8000', 8076, 8077]
 
 
 def update_port(port, open):
@@ -56,39 +56,6 @@ def update_all_ports(open):
         update_port(port, open)
 
 
-def enable_and_start_service(name, start):
-    attempt = 0
-    while True:
-        attempt += 1
-        fn = 'enable' if start else 'disable'
-        args = ('systemctl', fn, '--now', name)
-        (ret, out, err) = util.doexec(args)
-        if ret == 0:
-            return
-        elif attempt >= 3:
-            raise Exception(
-                'Failed to {} {}: {} {}'.format(fn, name, out, err)
-            )
-        time.sleep(1)
-
-
-def restart_service(name):
-    attempt = 0
-    while True:
-        attempt += 1
-        util.SMlog('linstor-manager:restart service {} {}...'.format(name, attempt))
-        args = ('systemctl', 'restart', name)
-        (ret, out, err) = util.doexec(args)
-        if ret == 0:
-            return
-        elif attempt >= 3:
-            util.SMlog('linstor-manager:restart service FAILED {} {}'.format(name, attempt))
-            raise Exception(
-                'Failed to restart {}: {} {}'.format(name, out, err)
-            )
-        time.sleep(1)
-
-
 def stop_service(name):
     args = ('systemctl', 'stop', name)
     (ret, out, err) = util.doexec(args)
@@ -98,11 +65,11 @@ def stop_service(name):
 
 
 def update_linstor_satellite_service(start):
-    enable_and_start_service('linstor-satellite', start)
+    util.enable_and_start_service('linstor-satellite', start)
 
 
 def update_minidrbdcluster_service(start):
-    enable_and_start_service('minidrbdcluster', start)
+    util.enable_and_start_service('minidrbdcluster', start)
 
 
 def prepare_sr(session, args):
@@ -187,8 +154,8 @@ def destroy(session, args):
 
         # When destroy is called, there are no running minidrbdcluster daemons.
         # So the controllers are stopped too, we must start an instance.
-        restart_service('var-lib-linstor.service')
-        restart_service('linstor-controller')
+        util.restart_service('var-lib-linstor.service')
+        util.restart_service('linstor-controller')
 
         linstor = LinstorVolumeManager(
             'linstor://localhost',
diff --git a/drivers/linstorvhdutil.py b/drivers/linstorvhdutil.py
index ac858371..9ba0ac3b 100644
--- a/drivers/linstorvhdutil.py
+++ b/drivers/linstorvhdutil.py
@@ -42,7 +42,7 @@ def linstorhostcall(local_method, remote_method):
             # Try to read locally if the device is not in use or if the device
             # is up to date and not diskless.
             (node_names, in_use) = \
-                self._linstor.find_up_to_date_diskfull_nodes(vdi_uuid)
+                self._linstor.find_up_to_date_diskful_nodes(vdi_uuid)
 
             try:
                 if not in_use or socket.gethostname() in node_names:
@@ -217,7 +217,7 @@ class LinstorVhdUtil:
     def _get_readonly_host(self, vdi_uuid, device_path, node_names):
         """
         When vhd-util is called to fetch VDI info we must find a
-        diskfull DRBD disk to read the data. It's the goal of this function.
+        diskful DRBD disk to read the data. It's the goal of this function.
         Why? Because when a VHD is open in RO mode, the LVM layer is used
         directly to bypass DRBD verifications (we can have only one process
         that reads/writes to disk with DRBD devices).
@@ -226,7 +226,7 @@ class LinstorVhdUtil:
         if not node_names:
             raise xs_errors.XenError(
                 'VDIUnavailable',
-                opterr='Unable to find diskfull node: {} (path={})'
+                opterr='Unable to find diskful node: {} (path={})'
                 .format(vdi_uuid, device_path)
             )
 
diff --git a/drivers/linstorvolumemanager.py b/drivers/linstorvolumemanager.py
index e497afa6..da98e0b6 100755
--- a/drivers/linstorvolumemanager.py
+++ b/drivers/linstorvolumemanager.py
@@ -329,18 +329,21 @@ class LinstorVolumeManager(object):
         __slots__ = (
             'name',
             'allocated_size',  # Allocated size, place count is not used.
-            'virtual_size'    # Total virtual available size of this volume
-                              # (i.e. the user size at creation).
+            'virtual_size',    # Total virtual available size of this volume
+                               # (i.e. the user size at creation).
+            'is_diskful'
         )
 
         def __init__(self, name):
             self.name = name
             self.allocated_size = 0
             self.virtual_size = 0
+            self.is_diskful = False
 
         def __repr__(self):
-            return 'VolumeInfo("{}", {}, {})'.format(
-                self.name, self.allocated_size, self.virtual_size
+            return 'VolumeInfo("{}", {}, {}, {})'.format(
+                self.name, self.allocated_size, self.virtual_size,
+                'diskful' if self.is_diskful else 'diskless'
             )
 
     # --------------------------------------------------------------------------
@@ -1332,9 +1335,9 @@ class LinstorVolumeManager(object):
                 .format(e)
             )
 
-    def find_up_to_date_diskfull_nodes(self, volume_uuid):
+    def find_up_to_date_diskful_nodes(self, volume_uuid):
         """
-        Find all nodes that contain a specific volume using diskfull disks.
+        Find all nodes that contain a specific volume using diskful disks.
         The disk must be up to data to be used.
         :param str volume_uuid: The volume to use.
         :return: The available nodes.
@@ -1716,6 +1719,8 @@ class LinstorVolumeManager(object):
             else:
                 current = all_volume_info[resource.name]
 
+            current.is_diskful = linstor.consts.FLAG_DISKLESS not in resource.flags
+
             for volume in resource.volumes:
                 # We ignore diskless pools of the form "DfltDisklessStorPool".
                 if volume.storage_pool_name == self._group_name:
diff --git a/drivers/util.py b/drivers/util.py
index 7151f368..6a9fc1a0 100755
--- a/drivers/util.py
+++ b/drivers/util.py
@@ -1801,3 +1801,52 @@ def sessions_less_than_targets(other_config, device_config):
     else:
         return False
 
+
+def enable_and_start_service(name, start):
+    attempt = 0
+    while True:
+        attempt += 1
+        fn = 'enable' if start else 'disable'
+        args = ('systemctl', fn, '--now', name)
+        (ret, out, err) = doexec(args)
+        if ret == 0:
+            return
+        elif attempt >= 3:
+            raise Exception(
+                'Failed to {} {}: {} {}'.format(fn, name, out, err)
+            )
+        time.sleep(1)
+
+
+def stop_service(name):
+    args = ('systemctl', 'stop', name)
+    (ret, out, err) = doexec(args)
+    if ret == 0:
+        return
+    raise Exception('Failed to stop {}: {} {}'.format(name, out, err))
+
+
+def restart_service(name):
+    attempt = 0
+    while True:
+        attempt += 1
+        SMlog('Restarting service {} {}...'.format(name, attempt))
+        args = ('systemctl', 'restart', name)
+        (ret, out, err) = doexec(args)
+        if ret == 0:
+            return
+        elif attempt >= 3:
+            SMlog('Restart service FAILED {} {}'.format(name, attempt))
+            raise Exception(
+                'Failed to restart {}: {} {}'.format(name, out, err)
+            )
+        time.sleep(1)
+
+
+def check_pid_exists(pid):
+    try:
+        os.kill(pid, 0)
+    except OSError:
+        return False
+    else:
+        return True
diff --git a/scripts/fork-log-daemon b/scripts/fork-log-daemon
new file mode 100755
index 00000000..eb0f0b0f
--- /dev/null
+++ b/scripts/fork-log-daemon
@@ -0,0 +1,34 @@
+#!/usr/bin/env python
+
+import select
+import subprocess
+import sys
+import syslog
+
+def main():
+    process = subprocess.Popen(sys.argv[1:], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
+    write_to_stdout = True
+
+    while process.poll() is None:
+        while True:
+            output = process.stdout.readline()
+            if not output:
+                break
+
+            if write_to_stdout:
+                try:
+                    print(output)
+                    sys.stdout.flush()
+                except Exception:
+                    # Probably a broken pipe. So the process reading stdout is dead.
+                    write_to_stdout = False
+            syslog.syslog(output)
+
+if __name__ == "__main__":
+    syslog.openlog(ident=sys.argv[1], facility=syslog.LOG_DAEMON)
+    try:
+        main()
+    except Exception as e:
+        syslog.syslog(sys.argv[1] + ' terminated with exception: {}'.format(e))
+    finally:
+        syslog.syslog(sys.argv[1] + ' is now terminated!')
